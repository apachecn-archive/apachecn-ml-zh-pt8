# 九、构建深度学习流水线

到目前为止，对于我们讨论过的各种深度学习架构，我们假设输入数据是静态的。我们有固定的影评集、图像或文本要处理。

在现实世界中，无论您的组织或项目是否包含来自自驾汽车、物联网传感器、安全摄像头或客户产品使用的数据，您的数据通常会随着时间的推移而变化。因此，您需要一种集成这些新数据的方法，以便能够更新您的模型。数据的结构也可能发生变化，对于客户或受众数据，可能需要对数据进行新的转换。此外，可以添加或删除维度，以测试它们是否影响预测的质量、不再相关或违反隐私立法。在这些情况下我们该怎么办？

这就是像 Pachyderm 这样的工具很有用的地方。我们想知道我们拥有什么样的数据，我们在哪里拥有这些数据，以及我们如何确保这些数据能够提供给我们的模型。

现在，我们将研究如何使用 Pachyderm 工具来处理网络中的动态输入值。这将帮助我们为系统的实际使用和部署做好准备。

在本章结束时，您将了解以下内容：

*   探索厚皮动物
*   整合我们的 CNN

# 探索厚皮动物

本书的重点是在 Go 中开发深度学习系统。所以，自然地，现在我们正在讨论如何管理我们给网络提供的数据，让我们来看看一个工具，也就是写在 GO 中。

Pachydrm 是一个成熟的可扩展工具，提供容器化数据管道。在这些环境中，您可能需要的所有东西（从数据到工具）都集中在一个地方，在这里可以维护和管理部署，并对数据本身进行版本控制。Pachyderm 团队将他们的工具作为数据的**Git 出售，这是一个有用的类比。理想情况下，我们希望对整个管道进行版本化，以便我们知道使用了哪些数据进行训练，而这些数据反过来又为我们提供了对*X*的具体预测。**

Pachydrm 消除了管理这些管道的许多复杂性。Docker 和 Kubernetes 都在引擎盖下跑步。在下一章中，我们将更详细地探讨这些工具中的每一个，但现在，我们需要知道的是，它们对于实现可复制的构建以及模型的可扩展分布式培训至关重要。

# 安装和配置 Pachydrm

有很多关于厚皮动物的优秀文档可用，我们不会在这里重复所有这些。相反，我们将带您学习基础知识，并构建一个简单数据管道管理教程，以向 CNN 提供版本化的图像数据，我们在[第 6 章](06.html)、*卷积神经网络对象识别*中构建了 CNN。

首先，您需要安装 Docker Desktop 并为各自的操作系统启用 Kubernetes。在本例中，我们使用的是 macOS。

完整说明见[https://docs.docker.com/docker-for-mac/install/](https://docs.docker.com/docker-for-mac/install/) ，现在让我们简要回顾一下：

1.  下载 Docker`.dmg`文件
2.  安装或启动该文件
3.  启用 Kubernetes

To install and run Pachyderm, follow these steps:

1.  要启用 Kubernetes，请在启动 Docker 设置后选中相应的复选框，如下所示：

![](img/746cf29d-53a7-4ce6-b1fc-eee1b0b44189.png)

2.  确保有两个绿色斑点指示 Docker 和 Kubernetes 安装正在运行。如果是这样，我们可以通过进入终端并运行以下命令来确认引擎盖下的情况是否正常：

```go
# kubectl get all
NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE
service/kubernetes ClusterIP 10.96.0.1 <none> 443/TCP 7m
```

3.  在安装 Pachydrm 本身之前，请确保群集正在运行。我们使用自制软件通过以下命令安装 Pachydrm（请注意，您需要安装最新版本的 Xcode）：

```go
brew tap pachyderm/tap && brew install pachyderm/tap/pachctl@1.9
Updating Homebrew...
...
==> Tapping pachyderm/tap
Cloning into '/usr/local/Homebrew/Library/Taps/pachyderm/homebrew-tap'...
remote: Enumerating objects: 13, done.
remote: Counting objects: 100% (13/13), done.
remote: Compressing objects: 100% (12/12), done.
remote: Total 13 (delta 7), reused 2 (delta 0), pack-reused 0
Unpacking objects: 100% (13/13), done.
Tapped 7 formulae (47 files, 34.6KB).
==> Installing pachctl@1.9 from pachyderm/tap
...
==> Downloading https://github.com/pachyderm/pachyderm/releases/download/v1.9.0rc2/pachctl_1.9.0rc2_d
==> Downloading from https://github-production-release-asset-2e65be.s3.amazonaws.com/23653453/0d686a0
######################################################################## 100.0%
/usr/local/Cellar/pachctl@1.9/v1.9.0rc2: 3 files, 62.0MB, built in 26 seconds
```

4.  您现在应该能够启动 pachydrm 命令行工具了。首先，通过运行以下命令并观察输出，检查工具是否已成功安装：

```go
 pachctl help
Access the Pachyderm API.
..
Usage:
 pachctl [command]

Administration Commands:
..
```

5.  我们几乎完成了集群的设置，这样我们就可以专注于获取和存储数据。最后要做的是使用以下命令在 Kubernetes 上部署 Pachyderm：

```go
pachctl deploy local
no config detected at %q. Generating new config... 
/Users/xxx/.pachyderm/config.json
No UserID present in config. Generating new UserID and updating config at /Users/xxx/.pachyderm/config.json
serviceaccount "pachyderm" created
clusterrole.rbac.authorization.k8s.io "pachyderm" created
clusterrolebinding.rbac.authorization.k8s.io "pachyderm" created
deployment.apps "etcd" created
service "etcd" created
service "pachd" created
deployment.apps "pachd" created
service "dash" created
deployment.apps "dash" created
secret "pachyderm-storage-secret" created

Pachyderm is launching. Check its status with "kubectl get all"
Once launched, access the dashboard by running "pachctl port-forward"
```

6.  执行以下命令以检查集群的状态。如果在部署后立即运行该命令，则应看到正在创建的容器：

```go
kubectl get all
NAME READY STATUS RESTARTS AGE
pod/dash-8786f7984-tb5k9 0/2 ContainerCreating 0 8s
pod/etcd-b4d789754-x675p 0/1 ContainerCreating 0 9s
pod/pachd-fbbd6855b-jcf6c 0/1 ContainerCreating 0 9s
```

7.  然后转换到`Running`：

```go
kubectl get all
NAME READY STATUS RESTARTS AGE
pod/dash-8786f7984-tb5k9 2/2 Running 0 2m
pod/etcd-b4d789754-x675p 1/1 Running 0 2m
pod/pachd-fbbd6855b-jcf6c 1/1 Running 0 2m
```

下一节将介绍如何准备数据。

# 将数据导入厚皮数据库

让我们准备数据。在本例中，我们使用的是[第 6 章](06.html)、*卷积神经网络对象识别*中的 CIFAR-10 数据集。如果你需要复习，从多伦多大学的数据源中提取数据，比如：

```go
wget https://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz
...
cifar-10-binary.tar.gz 100%[==================================>] 162.17M 833KB/s in 2m 26s
```

将数据提取到临时目录，并在 Pachydrm 中创建`repo`：

```go
# pachctl create repo data
# pachctl list repo
NAME CREATED SIZE (MASTER)
data 8 seconds ago 0B
bash-3.2$
```

现在我们已经有了一个存储库，让我们用我们的 CIFAR-10 图像数据填充它。首先，让我们创建单独的目录并分解各种 CIFAR-10 文件，这样我们就可以转储整个文件目录（来自数据或训练集）。

现在我们可以执行以下命令，然后确认数据已成功到达`repo`：

```go
#pachctl put file -r data@master -f data/
#pachctl list repo
NAME CREATED SIZE (MASTER)
data 2 minutes ago 202.8MiB
```

我们可以深入到`repo`包含的文件的详细信息：

```go
pachctl list file data@master
COMMIT NAME TYPE COMMITTED SIZE
b22db05d23324ede839718bec5ff219c /data dir 6 minutes ago 202.8MiB
```

# 整合我们的 CNN

现在，我们将以前面章节中的 CNN 为例，进行一些必要的更新，以便使用 Pachydrm 提供的数据打包和部署网络。

# 创建我们 CNN 的 Docker 形象

厚皮动物数据管道依赖于预烘焙的 Docker 图像。互联网上充斥着 Docker 教程，因此我们将在这里保持简单，并讨论我们需要做什么来利用任何 Go 应用程序的简单部署步骤。

让我们看看我们的 DOCKFILE：

```go
FROM golang:1.12

ADD main.go /main.go

ADD cifar/ /cifar/

RUN export GOPATH=$HOME/go && cd / && go get -d -v .
```

就这样！我们只是从 Docker Hub 获取 Go 1.12 图像，并将我们的 CIFAR CNN 放入我们的构建中。Dockerfile 的最后一部分是设置`GOPATH`并满足依赖关系的命令（例如，安装 Gorgonia）。

执行以下命令建立 Docker 镜像并观察输出：`docker build -t cifarcnn`

```go
Sending build context to Docker daemon 212.6MB
Step 1/4 : FROM golang:1.12
 ---> 9fe4cdc1f173
Step 2/4 : ADD main.go /main.go
 ---> Using cache
 ---> 5edf0df312f4
Step 3/4 : ADD cifar/ /cifar/
 ---> Using cache
 ---> 6928f37167a8
Step 4/4 : RUN export GOPATH=$HOME/go && cd / && go get -d -v .
 ---> Running in 7ff14ada5e7c
Fetching https://gorgonia.org/tensor?go-get=1
Parsing meta tags from https://gorgonia.org/tensor?go-get=1 (status code 200)
get "gorgonia.org/tensor": found meta tag get.metaImport{Prefix:"gorgonia.org/tensor", VCS:"git", RepoRoot:"https://github.com/gorgonia/tensor"} at https://gorgonia.org/tensor?go-get=1

...

Fetching https://gorgonia.org/dawson?go-get=1
Parsing meta tags from https://gorgonia.org/dawson?go-get=1 (status code 200)
get "gorgonia.org/dawson": found meta tag get.metaImport{Prefix:"gorgonia.org/dawson", VCS:"git", RepoRoot:"https://github.com/gorgonia/dawson"} at https://gorgonia.org/dawson?go-get=1
gorgonia.org/dawson (download)
Removing intermediate container 7ff14ada5e7c
 ---> 3def2cada165
Successfully built 3def2cada165
Successfully tagged cifar_cnn:latest
```

Our container is now ready to be referenced in the Pachyderm data pipeline specification.

# 更新 CNN 以保存模型

我们需要在 CNN 示例中添加一个简单的函数，以确保生成的模型被保存，这样就可以通过 Pachydrm 将其作为对象进行管理。让我们在`main.go`中添加以下内容：

```go
func (m *convnet) savemodel() (err error) {
  learnables := m.learnables()
  var f io.WriteCloser
  if f, err = os.OpenFile("model.bin", os.O_CREATE|os.O_TRUNC|os.O_WRONLY, 0644); err != nil {
    return
  }
  defer f.Close()
  enc := json.NewEncoder(f)
  for _, l := range learnables {
    t := l.Value().(*tensor.Dense).Data() // []float32
    if err = enc.Encode(t); err != nil {
      return
    }
  }

  return nil
}
```

# 创建数据管道

现在我们需要在标准 JSON 中指定一个数据管道。在这里，我们将一个存储库映射到一个目录，并以训练或推理模式执行我们的网络。

让我们看看我们的`cifar_cnn.json`文件：

```go
{
 "pipeline": {
    "name": "cifarcnn"
  },
  "transform": {
    "image": "cifarcnn:latest",
    "cmd": [
  "go run main.go"
    ]
  },
  "enable_stats": true,
  "parallelism_spec": {
    "constant": "1"
  },
  "input": {
    "pfs": {
      "repo": "data",
      "glob": "/"
    }
  }
}
```

我们在这里选择的选项很简单，您可以看到对 Docker 映像、命令和开关的引用，以及我们指定的`repo`和装载点。需要注意的一点是`parallelism_spec`选项。将其设置为高于默认值`1`允许我们根据需要缩放特定的管道阶段；例如，在推理阶段。

现在，我们可以从前面的模板创建管道：

```go
pachctl create pipeline -f cifar_cnn.json
```

如果没有错误，则返回命令提示符。然后，您可以检查管道的状态：

```go
pachctl list pipeline 
NAME INPUT CREATED STATE / LAST JOB
cifarcnn data:/ 8 seconds ago running / running
```

我们可以动态更改*并行*的级别，并通过更新模板将配置推出到我们的集群：

```go
 "parallelism_spec": {
 "constant": "5"
 },
```

然后，我们可以更新我们的集群并检查我们的作业和`k8s`集群吊舱的状态：

```go
#pachctl update pipeline -f cifar_cnn.json
#pachctl list job 
ID PIPELINE STARTED DURATION RESTART PROGRESS DL UL STATE
9339d8d712d945d58322a5ac649d9239 cifarcnn 7 seconds ago - 0 0 + 0 / 1 0B 0B running

#kubectl get pods
NAME READY STATUS RESTARTS AGE
dash-5c54745d97-gs4j2 2/2 Running 2 29d
etcd-b4d789754-x675p 1/1 Running 1 35d
pachd-fbbd6855b-jcf6c 1/1 Running 1 35d
pipeline-cifarcnn-v1-bwfrq 2/2 Running 0 2m
```

After giving it some time to run (and using `pachctl logs` to inspect progress), we can see our successful job:

```go
#pachctl list job
ID OUTPUT COMMIT STARTED DURATION RESTART PROGRESS DL UL STATE
9339d8d712d945d58322a5ac649d9239 cifarcnn 2 minutes ago About a minute 0 1 + 0 / 1 4.444KiB 49.86KiB success
```

# 可互换模型

Pachyderm 管道的灵活性允许您通过简单的更新或推送我们之前使用的 JSON 管道，轻松地将一个模型替换为另一个模型。

用 JSON 指定管道有什么意义？这是为了让它可以重复！管道在每次更新数据时都会重新处理数据（在我们的例子中，是为了对标签类做出新的预测）。

在这里，我们更新了`cifa_cnn.json`中的`image`标志，以引用我们的集装箱 CNN 版本，无论出于何种原因，该版本不包含辍学：

```go
"image": "pachyderm/cifar_cnn_train:nodropout"
```

然后我们可以更新集群上的管道，如下所示：

```go
pachctl update pipeline -f cifar_cnn.json --reprocesses
```

# 将预测映射到模型

Pachyderm 的一个重要特性（尤其是对于企业用例）是能够对模型和预测进行版本化。假设您正在预测客户偿还贷款的机会，您会看到一批奇怪的预测。作为解决模型做出这些决定的原因的一部分，如果您在一个大型团队中培训多个模型，那么浏览电子邮件链和提交历史记录将是一个坏主意！

因此，从推断向后工作到模型，只需运行以下命令：

```go
#pachctl list job
```

然后，您可以获取相关的提交散列并将其提供给以下命令，同时观察输出的详细信息：

```go
#pachctl inspect job 9339d8d712d945d58322a5ac649d9239
...
Input:
{
 "pfs": {
 "name": "data",
 "repo": "data",
 "branch": "master",
 "commit": "b22db05d23324ede839718bec5ff219c",
 "glob": "/"
 }
}
...

#pachctl inspect commit data@b22db05d23324ede839718bec5ff219c
Commit: data@b22db05d23324ede839718bec5ff219c
Original Branch: master
Started: 11 minutes ago
Finished: 11 minutes ago
Size: 202.8MiB
```

您可以看到用于生成此预测的模型的确切提交、预测的来源，以及用于训练模型的数据：

```go
#pachctl list file data@adb293f8a4604ed7b081c1ff030c0480
COMMIT NAME TYPE COMMITTED SIZE
b22db05d23324ede839718bec5ff219c /data dir 11 minutes ago 202.8MiB
```

# 使用 Pachyderm 仪表板

从技术上讲，这是 Pachydrm**Enterprise**的一项功能，但由于我们希望在涉及您拥有的选项时尽可能做到包容，无论您的使用情况如何，我们将简要介绍*仪表板*工具。即使您不需要对管道和数据进行简单的可视化概述，也可以使用 14 天的试用期对功能集进行一些探索。

启动`http://localhost:30800`。您将看到一个基本屏幕，其中包括以下内容：

*   存储库（保存我们的 CIFAR-10 数据）
*   管道
*   作业或日志
*   设置

让我们看一下以下屏幕截图：

![](img/29c1d92a-a712-4bf2-91e5-3e7bb453cdbf.png)

您可能还记得，Pachydrm 希望您将数据存储库视为 Git 存储库。当您深入到下一个屏幕时，可以清楚地看到：

![](img/0bae38f6-ee99-4ef7-97ff-c3675859aad2.png)

仪表板为我们一直使用到现在的`pachctl`工具提供了一个熟悉的 GUI 界面。

# 总结

在本章中，我们已经变得实用，并研究了在开始增加模型的输入或输出组件时涉及到的内容，以及我们可以使用哪些工具以可维护和可跟踪的方式来实现这一点。在高层，我们了解了什么是数据管道以及为什么它很重要，如何在 Pachydrm 中构建/部署/维护管道，以及使用什么工具来可视化存储库和管道。

在下一章中，我们将介绍 Pachyderm 下面的一些技术，包括 Docker 和 Kubernetes，以及如何使用这些工具将堆栈部署到云基础设施。