# 二、什么是神经网络？如何训练神经网络？

While we've now discussed Go and the libraries available for it, we haven't yet discussed what constitutes a neural network. Toward the end of the previous chapter, we used Gorgonia to construct a graph that, when executed by an appropriate VM, performs several basic operations (specifically, addition and multiplication) on a series of matrices and vectors.

现在我们将讨论如何构建神经网络并使其工作。这将教你构建更高级的神经网络架构所需的组件，我们将在本书后面讨论。

This chapter will cover the following topics:

*   基本神经网络
*   激活函数
*   梯度下降和反向传播
*   高级梯度下降算法

# 基本神经网络

让我们首先构建一个简单的神经网络。该网络将使用加法和乘法的基本运算来获取 4 x 3 的整数矩阵，初始化由 3 x 1 列向量表示的权重系数，并逐渐调整这些权重，直到它们预测给定输入序列（以及应用 Sigmoid 非线性后），与验证数据集匹配的输出。

# 神经网络的结构

本示例的目的显然不是构建尖端的计算机视觉系统，而是演示如何在参数化函数的上下文中使用这些基本操作（以及 Gorgonia 如何处理这些操作），其中参数是随时间学习的。本节的主要目标是了解学习网络的概念。这种*学习*实际上只意味着持续、有意地重新参数化网络（更新权重）。这是通过一种优化方法来实现的，本质上，这是一种表示一些基本的本科微积分的少量代码。

The Sigmoid function (and activation functions more generally), **Stochastic Gradient Descent** (**SGD**), and backpropagation will each receive detailed treatment in later sections of this chapter. For now, we will talk about them in the context of the code; that is, where and how they are used and what their role is in the function we are computing.

当你读完这本书的时候，或者如果你是一个有经验的 ML 从业者，下面的内容看起来就像是进入神经网络架构世界的荒谬的简单的第一步。但如果这是你的第一次牛仔竞技，请密切关注。所有让魔法发生的基本原理都在这里。

网络是由什么组成的？以下是我们玩具示例神经网络的主要组件：

*   **I****nput 数据**：这是一个 4X3 矩阵。
*   **验证数据**：这是一个 1 x 4 列向量，或者实际上是一个有一列的四行矩阵。这在 Gorgonia 中表示为`WithShape(4,1)`。
*   **激活（Sigmoid）函数**：这将非线性引入我们的网络和我们正在学习的函数。
*   **突触：**这也称为**可训练重量**，这是我们将使用 SGD 优化的网络的关键参数。

在我们的计算图上，每个组件及其相关操作都表示为节点。当我们解释网络正在做什么时，我们将使用我们在[第 1 章](01.html)、*Go 深度学习导论*中学习的技术生成图形的可视化。

我们还将对我们的网络进行一点过度设计。这是什么意思？考虑下面的代码块：

```go
type nn struct {
    g *ExprGraph
    w0, w1 *Node

    pred *Node
}
```

我们正在将网络的关键组件嵌入名为`nn`的`struct`中。这不仅使我们的代码可读，而且当我们想要对深层（多层）网络的每一层的若干权重执行优化过程（SGD/反向传播）时，它可以很好地扩展。如您所见，除了每层的权重之外，我们还有一个节点，表示我们的网络所做的预测，以及`*ExprGraph`本身。

我们的网络有两层。这些是在我们的网络向前传递期间计算的。向前传递表示我们希望在计算图中的值节点上执行的所有数值变换。

具体而言，我们有以下几点：

*   `l0`：输入矩阵，我们的`X`
*   `w0`: The trainable parameter, our network weight that will be optimized by the SGD algorithm
*   `l1`：应用于`l0`和`w0`的点积的 Sigmoid 值
*   `pred`：表示网络*预测*的节点，反馈到`nn struct`中的相应字段

那么，我们的目标是什么？

我们想要构建一个系统，学习一个函数，该函数能够最好地模拟 0，0，1，1 的列序列。该潜水了！

# 你的第一个神经网络

让我们从基本的命名包和导入我们需要的包开始。此过程通过以下步骤执行：

1.  对于这个例子，我们将使用与 Gorgonia 相同的开发人员提供的`tensor`库。我们将其用于计算图中连接到各自节点的背衬张量：

```go
package main

import (
    "fmt"
    "io/ioutil"
    "log"

    . "gorgonia.org/gorgonia"
    "gorgonia.org/tensor"
)
```

2.  创建一个变量，用以下代码捕获错误：

```go
var err error
```

现在，我们可以定义用于嵌入神经网络图、权重和预测（输出）的主要`struct`。在更深层次的网络中，我们会有`w0`、`w1`、`w2`、`w3`等等，直到`wn`。我们可能会在`struct`中捕获更多的网络参数，我们将在后面的章节中详细介绍这些参数。例如，在一个**卷积神经网络**（**CNN**中），你也会有每层的退出概率，这有助于我们防止我们的网络*过度拟合*我们的训练数据。这里的要点是，无论架构多么先进或论文多么新颖，您都可以通过扩展以下`struct`来表达任何网络的属性：

```go
type nn struct {
    g *ExprGraph
    w0, w1 *Node

    pred *Node
}
```

现在，我们将考虑实例化一个新的方法的方法。这里，我们为我们的权重矩阵创建节点，或者在这个特定的情况下，为我们的行向量创建节点。这个过程推广到创建我们用*n*秩张量支持的任何节点。

以下方法返回`ExprGraph`并附加新节点：

```go
func newNN(g *ExprGraph) *nn {
    // Create node for w/weight (needs fixed values replaced with random values w/mean 0)
    wB := []float64{-0.167855599, 0.44064899, -0.99977125}
    wT := tensor.New(tensor.WithBacking(wB), tensor.WithShape(3, 1))
    w0 := NewMatrix(g,
        tensor.Float64,
        WithName("w"),
        WithShape(3, 1),
        WithValue(wT),
    )
    return nn{
        g: g,
        w0: w0,
    }
}
```

现在，我们已经向图中添加了一个节点，并用实值张量对其进行了支持，我们应该检查计算图以查看该权重是如何显示的，如下表所示：

![](img/b40810d3-64ad-402d-9611-a7da5ba9f6e8.png)

这里要注意的属性是类型（矩阵为`float64`）、`Shape`为`(3, 1)`，当然还有占据该向量的三个值。这不是一个很好的图表；的确，我们的节点是孤独的，但我们很快就会增加它。在更复杂的网络中，对于我们使用的每一层，都会有一个由权重矩阵支持的节点。

在此之前，我们必须添加另一个特性，使我们能够将代码扩展到这些更复杂的网络。这里，我们定义了网络的可学习性，这是计算梯度的关键。`Grad()`功能将在该节点列表上运行。以这种方式对这些节点进行分组，使我们能够在单个函数中计算网络*n*层的权重梯度。缩放这仅仅意味着添加`w1`、`w2`、`w3`和`wn`，如下代码所示：

```go
func (m *nn) learnables() Nodes {
    return Nodes{m.w0}
}
```

现在，我们进入网络的核心部分。以下函数*在执行*时，将使用表示输入层和隐藏层的操作和节点来扩展图形。需要注意的是，当然，这是一个将在我们网络的主要部分调用的函数；目前，我们正在预先定义它：

```go
func (m *nn) fwd(x *Node) (err error) {
    var l0, l1 *Node

    // Set first layer to be copy of input
    l0 = x

    // Dot product of l0 and w0, use as input for Sigmoid
    l0dot := Must(Mul(l0, m.w0))

    // Build hidden layer out of result
    l1 = Must(Sigmoid(l0dot))
    // fmt.Println("l1: \n", l1.Value())

    m.pred = l1
    return

}
```

We can see the application of the `Sigmoid` function on the hidden layer, `l1`, as we briefly discussed when elaborating the components of our network. We will cover it in detail in the next section of this chapter.

我们现在可以编写`main`函数，在这里我们将实例化我们的网络和前面描述的所有各种方法。让我们详细讨论一下。此过程的第一步显示在以下代码中：

```go
func main() {
    rand.Seed(31337)

    intercept Ctrl+C
    sigChan := make(chan os.Signal, 1)
    signal.Notify(sigChan, syscall.SIGINT, syscall.SIGTERM)
    doneChan := make(chan bool, 1)

    // Create graph and network
    g := NewGraph()
    m := newNN(g)
```

接下来，我们定义输入矩阵，如下所示：

```go
    // Set input x to network
    xB := []float64{0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1}
    xT := tensor.New(tensor.WithBacking(xB), tensor.WithShape(4, 3))
    x := NewMatrix(g,
        tensor.Float64,
        WithName("X"),
        WithShape(4, 3),
        WithValue(xT),
    )
```

然后，我们定义有效的验证数据集，如下所示：

```go
    // Define validation dataset
    yB := []float64{0, 0, 1, 1}
    yT := tensor.New(tensor.WithBacking(yB), tensor.WithShape(4, 1))
    y := NewMatrix(g,
        tensor.Float64,
        WithName("y"),
        WithShape(4, 1),
        WithValue(yT),
    )
```

让我们看看我们的图形现在看起来是什么样子，加上了 Tyt0 和 T1。

![](img/f92ec352-577d-4dfb-9f7f-ed8f73db9f7f.png)

我们可以看到各个节点，`w`、`X`和`y`。正如我们在查看`w`时所做的那样，请注意每种类型的`Shape`和`Value`。

现在我们调用我们`nn`的`fwd`方法，真正构建出我们的图，包括`X`、`y`和`w`之间的计算关系，如下代码所示：

```go
// Run forward pass
if err = m.fwd(x); err != nil {
    log.Fatalf("%+v", err)
}
```

这就是优化过程的开始。我们的网络已经做出了第一次预测，因此我们现在将定义并计算一个`cost`函数，该函数将允许我们确定权重的错误程度，以及稍后我们需要调整多少权重以使我们更接近目标`y`（我们的验证数据集）。在本例中，我们将重复此过程固定次数，以允许此相对简单的网络收敛。

下面的代码首先计算损失（即，*我们在*之前错过了多少）。然后，我们将`cost`作为验证数据的`Mean`：

```go
losses := Must(Sub(y, m.pred))
cost := Must(Mean(losses))
```

我们还要创建`var`来跟踪`cost`随时间的变化，如下所示：

```go
var costVal Value
Read(cost, costVal)
```

在我们继续计算网络中的梯度之前，让我们使用下面的代码行生成图形状态的可视化，现在看起来应该很熟悉了：

```go
ioutil.WriteFile("pregrad.dot", []byte(g.ToDot()), 0644)
```

Convert into PNG using the following line:

```go
dot -Tpng pregrad.dot  -O
```

现在，我们有了一个连接包含数据（输入、权重和验证）的节点以及我们将对其执行的操作的图。

图表变得太大，不能包含在一个页面中，所以我们现在只考虑这一步的重要部分。首先，请注意，我们的权重节点现在有一个`Grad`字段，该字段当前没有任何值（已运行正向传递，但我们尚未计算梯度），如下表所示：

![](img/e4f44f41-cab9-4749-a1f7-2a1c2b7ca779.png)

我们现在也有一些梯度运算；下图中有一段摘录：

![](img/63b1e8a5-c576-4740-a549-d813bd02c682.png)

现在，让我们计算梯度，即相对于权重的成本（表示为`m.learnables`。此步骤显示在以下代码中：

```go
  if _, err = Grad(cost, m.learnables()...); err != nil {
    log.Fatal(err)
  }
```

我们现在可以实例化将要处理图形的 VM。我们还选择了我们的`solver`，在本例中为香草 SGD，如下所示：

```go
// Instantiate VM and Solver
vm := NewTapeMachine(g, BindDualValues(m.learnables()...))
solver := NewVanillaSolver(WithLearnRate(0.001), WithClip(5))
// solver := NewRMSPropSolver()
```

我们为`vm`提供的一个新选项是`BindDualValues`。此选项确保我们计算的渐变绑定到包含要获取其导数的值的节点。这意味着，与节点说，*转到节点 x 以查找梯度*的值不同，该值可立即访问`vm`。这是图中权重节点的变化情况：

![](img/bae536f0-fde1-488e-b9ad-44ef29afab96.png)

`Value`字段现在包含输出相对于节点的偏导数。我们现在终于准备好进行完整的训练循环了。对于这样一个简单的例子，我们将运行循环任意次数，特别是`10000`循环，如下例所示：

```go
    for i := 0; i < 10000; i++ {
        if err = vm.RunAll(); err != nil {
            log.Fatalf("Failed at inter %d: %v", i, err)
        }
        solver.Step(NodesToValueGrads(m.learnables()))
        fmt.Println("\nState at iter", i)
        fmt.Println("Cost: \n", cost.Value())
        fmt.Println("Weights: \n", m.w0.Value())
        // vm.Set(m.w0, wUpd)
        // vm.Reset()
    }
    fmt.Println("Output after Training: \n", m.pred.Value())
}
```

虽然我们已经熟悉使用虚拟机来计算图形的想法，但我们在这里添加了调用`solver`的步骤，这是我们之前定义的。`Step`通过可训练节点序列（即我们的权重）工作，添加梯度并将其乘以我们之前指定的学习速率。

就这样！现在，我们运行我们的程序，期望培训后的输出为 0,0,1,1，如下代码所示：

```go
Output after Training:
C [[0.00966449][0.00786506][0.99358898][0.99211957]]
```

这已经足够接近我们的网络了！

# 激活函数

既然您已经知道了如何构建基本的神经网络，那么让我们来看一下模型中某些元素的用途。其中一个元素是*乙状结肠*，它是一种激活功能。有时这些也被称为**传递函数**。

正如您之前所了解的，给定层可以简单地定义为应用于输入的权重；添加一些偏差，然后决定是否激活。激活函数决定神经元是否被*激发*。我们还将其放入网络中，以帮助在输入和输出之间创建更复杂的关系。在这样做的同时，我们还需要它是一个与反向传播一起工作的函数，这样我们就可以通过优化方法（即梯度下降）轻松优化我们的权重。这意味着我们需要函数的输出是可微的。

当选择一个激活函数时，有一些事情需要考虑如下：

*   **Speed**: Simple activation functions are quicker to execute than more complex activation functions. This is important since, in deep learning, we tend to run the model through large amounts of data, and therefore, will be executing each function over a reasonably large dataset many times.
*   **可微性**：正如我们已经注意到的，在反向传播过程中，能够区分函数非常有用。有一个梯度可以让我们调整我们的权重，使我们的网络更接近收敛。简言之，它允许我们通过最小化成本函数来计算误差以改进我们的模型。
*   **连续性**：它应该在整个输入范围内返回一个值。
*   **单调性**：虽然这个特性不是严格必要的，但它有助于优化神经网络，因为它在梯度下降过程中收敛速度更快。使用非单调函数是可能的，但总的来说，我们可能会遇到更长的训练时间。

# 阶跃函数

当然，最基本的激活函数是阶跃函数。如果`x`的值大于固定值`a`，则`y`为`0`或`1`，如下代码所示：

```go
func step(x) {
    if x >= 0 {
        return 1
    } else {
        return 0
    }
}
```

如下图所示，`step`功能非常简单；它获取一个值，然后返回`0`或`1`：

![](img/44305818-e4dc-44ab-a004-cd15a4c79b90.png)

这是一个非常简单的函数，对于深度学习来说并不特别有用。这是因为这个函数的梯度是一个恒定的零，这意味着，当我们进行反向传播时，它将不断产生零，这在我们进行反向传播时几乎没有（如果有的话）改善。

# 线性函数

`step`函数的一个可能扩展可能是使用`linear`函数，如下代码所示：

```go
func linear(x){
   return 0.5 * x
}
```

这仍然非常简单，如果我们将其绘制出来，它将类似于下图：

![](img/c00a5095-3b10-473f-ae98-f457da43bc20.png)

然而，这个函数仍然不是很有用。如果我们看梯度，我们会看到，当我们微分这个函数时，我们得到的是一条等于`a`值的直线。这意味着它与`step`函数存在相同的问题；也就是说，我们不会看到反向传播有多大的改进。

另外，如果我们把它叠成几层，你会发现实际上我们得到的和只有一层没有太大区别。如果我们试图构建具有多个层的模型，尤其是非线性关系的模型，那么这是没有用的。

# 校正线性单位

**整流线性单元**（**ReLU**）是目前最常用的激活功能。在后面的章节中，我们将在许多高级架构中使用它作为主要激活功能。

可以这样描述：

```go
func relu(x){
   return Max(0,x)
}
```

如果我们把它画出来，它看起来像下图：

![](img/48a91226-96be-44e0-a206-f212c1d3cfae.png)

正如你所看到的，它与线性函数非常相似，只是它变为零（因此表明神经元没有被激活）。

ReLU 还有许多有用的特性，如下所示：

*   **它是非线性的**：因此，将其中的几层堆叠起来不一定会导致与一层相同
*   **它是可微的**：因此，它与反向传播一起工作
*   **很快**：计算速度很快，当我们在网络的各层或训练通道上多次运行此计算时，这一点很重要

如果输入为负，ReLU 变为零。这可能是有用的，因为这会导致更少的神经元被激活，因此，这可能会加速我们的计算。然而，由于它可以导致`0`，这可以非常迅速地导致神经元*死亡*，并且在给定特定输入的情况下不再激活。

# 漏泄雷卢

当输入为负时，我们可以修改 ReLU 函数，使其具有较小的梯度。这可以很快完成，如下所示：

```go
func leaky_relu(x) {
    if x >= 0 {
        return x
    } else {
        return 0.01 * x
    }
}
```

上述函数的图表如下所示：

![](img/408fb0c4-ef31-4cec-a20e-9c6011ff540c.png)

请注意，此图表已更改为强调，因此*y*相对于*x*的斜率实际上是`0.1`而不是`0.01`，这是典型的泄漏 ReLU。

因为它总是会产生一个小的梯度，这应该有助于防止神经元在更持久的基础上死亡，同时仍然给我们带来许多 ReLU 的好处。

# S 形函数

乙状结肠或逻辑函数也比较流行，如下所示：

```go
func sigmoid(x){
    return 1 / (1 + Exp(-x))
}
```

结果如下：

![](img/b641db4b-4acd-4996-8161-ea2354647b0a.png)

Sigmoid 有一个同样有用的属性：它可以将任何实数映射回`0`到`1`之间的范围。这对于生成倾向于输出在`0`和`1`之间的模型（例如，用于预测某物概率的模型）非常有用。

它还拥有我们正在寻找的大部分房产，如下所示：

*   它是**非线性**。因此，将这些材料的几层堆叠起来不一定会导致与一层相同。
*   它是**可微的**，因此，它与反向传播一起工作。
*   It is **monotonic**.

然而，一个缺点是，与 ReLU 相比，计算成本更高，因此，使用该方法训练模型的总体时间更长。

# 谭

在训练过程中有一个更陡的坡度也是有帮助的；因此，我们可以使用`tanh`函数代替`Sigmoid`函数，如下代码所示：

```go
func tanh(x){
  return 2 * (1 + Exp(-2*x)) - 1
}
```

我们得到以下输出：

![](img/e435f740-e8fa-42bf-bcbe-c6b245d05254.png)

`tanh`函数还有一个有用的性质：它的斜率比`Sigmoid`函数陡峭得多；这有助于具有`tanh`激活功能的网络在调整权重时更快地降低梯度。这两个函数的输出绘制在以下输出中：

![](img/8bf7e7eb-c7e7-4095-b8cc-98e3dc16daf1.png)

# 但是我们应该用哪一个呢？

这些激活函数中的每一个都是有用的；但是，由于 ReLU 具有所有激活函数中最有用的功能，并且易于计算，因此这应该是您大部分时间使用的函数。

如果您经常遇到卡住的渐变，那么切换到 leaky ReLU 可能是一个好主意。但是，您通常可以降低学习速率以帮助防止这种情况，或者在早期的层中使用它，而不是在所有层中使用它，以保持整个网络中激活次数较少的优势。

`Sigmoid`作为输出层最有价值，最好以概率作为输出。`tanh`函数也很有价值，例如，我们希望层不断地向上和向下调整值（而不是像 ReLU 和 Sigmoid 一样向上倾斜）。

因此，简单的回答是：这取决于您的网络和您期望的输出类型。

It should, however, be noted that while a number of activation functions have been presented here for you to consider, other activation functions have been proposed such as PReLU, softmax, and Swish, which can also be considered, depending on the task at hand. This is still an active area of research and is considered to be far from solved, so stay tuned!

# 梯度下降和反向传播

在本章的第一节中，我们在示例代码的上下文中讨论了反向传播和梯度下降，但是当 Gorgonia 为我们做很多繁重的工作时，很难真正理解其中的概念。所以，我们现在来看看实际的过程本身。

# 梯度下降

反向传播是我们真正训练模型的方式；这是一种通过调整模型权重来最小化预测误差的算法。我们通常通过一种称为**梯度下降**的方法来实现这一点。

让我们从一个基本的例子开始，假设我们想训练一个简单的神经网络，通过将一个数字乘以 0.5 来完成以下任务：

| **输入** | **目标** |
| 1. | 0.5 |
| 2. | 1 |
| 3. | 1.5 |
| 4. | 2.0 |

首先，我们有一个基本模型，如下所示：

*y=W*x*

那么，首先，让我们猜测*W*实际上是两个。下表显示了这些结果：

| **输入** | **目标** | **W*x** |
| 1. | 0.5 | 2. |
| 2. | 1 | 4. |
| 3. | 1.5 | 6. |
| 4. | 2 | 8 |

现在我们有了*猜测*的输出，我们可以将这个*猜测*与我们期望的答案进行比较，并计算相对误差。例如，在本表中，我们使用误差平方和：

| **输入** | **Target** | **W*x** | **绝对误差** | **平方误差** |
| 1. | 0.5 | 2. | -1.5 | 2.25 |
| 2. | 1 | 4. | -3.0 | 9 |
| 3. | 1.5 | 6 | -4.5 | 20.25 |
| 4. | 2 | 8. | -6.0 | 36 |

通过将前面表格最后一列中的值相加，我们现在得到了平方误差之和，总计 67.5。

我们当然可以强制所有从-10 到+10 的值来得到答案，但肯定有更好的方法吗？理想情况下，我们需要一种更有效的方法来扩展数据集，这些数据集不是具有四个输入的简单表。

更好的方法是检查导数（或梯度）。我们可以这样做的一种方法是再次进行同样的计算，但权重稍高一些；例如，让我们试试*W=2.01*。下表显示了这些结果：

| **输入** | **目标** | **W*x** | **绝对误差** | **平方误差** |
| 1. | 0.5 | 2.01 | -1.51 | 2.2801 |
| 2. | 1 | 4.02 | -3.02 | 9.1204 |
| 3. | 1.5 | 6.03 | -4.53 | 20.5209 |
| 4. | 2 | 8.04 | -6.04 | 36.4816 |

这给了我们 68.403 的平方误差之和；这个更高！这意味着，直觉上，如果我们增加重量，我们可能会看到误差增加。反之亦然；如果我们减少重量，我们可能会看到误差减小。比如我们试试*W=1.99*，如下表所示：

| **输入** | **目标** | **W*x** | **绝对误差** | **平方误差** |
| 0 | 0 | 0 | 0 | 0 |
| 4. | 2. | 4.04 | -1.996 | 3.984016 |
| 8. | 4. | 8.08 | -3.992 | 15.93606 |
| 16 | 8. | 15.84 | -7.984 | 63.74426 |

这使我们的误差降低到 83.66434。

如果我们在给定的*W*范围内绘制误差图，您可以看到存在一个自然的底部点。这就是我们如何在梯度上下降以最小化误差。

对于这个特定的例子，我们可以很容易地将误差绘制为权重的函数。

目标是沿着坡度到底部，误差为零：

![](img/1e475b0f-acd8-420e-a0ec-113854ab4e41.png)

让我们尝试将权重更新应用到示例中，以说明其工作原理。通常，我们遵循一种称为**增量学习规则**的规则，该规则基本上类似于以下内容：

*新\旧\埃塔*衍生品*

在这个公式中，*eta*是一个常数，有时也称为**学习率**。回想一下，当我们在 Gorgonia 调用`solver`时，我们将学习率作为选项之一，如下所示：

```go
solver := NewVanillaSolver(WithLearnRate(0.001), WithClip(5))
```

您还经常会看到在输出误差的导数中添加 0.5 项。这是因为，如果我们的误差函数是平方函数，导数将是 2，所以 0.5 项被放在那里以抵消它；然而，无论如何 T0 0ηT1 T1 是恒定的（因此，你也可以仅仅考虑它被吸收到 SoT T2ηηTy3 t3 项）中。

首先，我们需要计算出误差对输出的导数。

如果我们说我们的学习率为`0.001`，那么我们的新权重如下：

```go
new_W = 1.00 - 0.001 * 101.338
```

If we were to compute this, `new_W` would be `1.89866`. This is closer to our eventual target weight of 0.5, and, with enough repetition, we would eventually get there. You'll notice that our learning rate is small. If we set it too large (let's say, 1), we would've ended up adjusting our weight way too far into the negative instead, so we would end up going round and round our gradient, instead of descending it. Our choice of learning rate is important: too small and our model will take too long to converge, and too large and it may even diverge instead.

# 反向传播

这是一个简单的例子。对于跨多个层具有数千个甚至数百万个参数的复杂模型，存在卷积网络，我们需要更智能地了解如何通过网络传播这些更新。对于具有多个层的网络（相应地增加参数的数量），这是正确的，新的研究结果表明，在一个极端的例子中，包括 10000 层的 CNN。

那么，我们该怎么做呢？最简单的方法是用我们知道其导数的函数建立神经网络。我们可以象征性地或在更实际的基础上这样做；如果我们用我们知道如何应用函数和如何反向传播（通过知道如何为导数编写函数）的函数构建它，我们可以用这些函数构建神经网络。

当然，构建这些函数可能非常耗时。幸运的是，Gorgonia 已经拥有了所有这些，因此允许我们做我们称之为自动差异化的事情。如前所述，我们创建一个有向图用于计算；这样不仅可以向前传球，还可以向后传球！

例如，让我们考虑更多的层（尽管仍然很简单），如下所示，其中，To.T1。

![](img/d3f713e0-acf6-4fb8-b4dc-27ae1083482b.png)

首先，我们有一个错误，它是*o*的函数。我们把这个叫做*E*。

为了更新我们在*g*中的权重，我们需要知道误差对*g*输入的导数。

从处理衍生品时的链式规则中，我们知道这实际上等同于以下内容：

*dE_dg=dE_do*do_dg*dg_dw2*

That is to say, the derivative of the error with respect to the input of *g (dE_dg)* is actually equivalent to the derivative of the error with respect to the output, (*dE_do*), multiplied by the derivative of the output with respect to the function, *g (do_dg),* and then multiplied by the derivative of the function, *g*, with respect to *w2*.

这为我们提供了在*g*中更新权重所需的衍生利率。

我们现在需要对*f*进行同样的操作。怎样这是一个重复这个过程的问题。我们需要误差对*f*输入的导数。再次使用链式规则，我们知道以下是正确的：

*德福=德福*德福*德福*德福*德福 dw1*

你会注意到这里与前面的导数*dE_do*do_dg*有一些共同点。

这为我们提供了进一步优化的机会。我们不必每次都计算导数的整体；我们只需要知道反向传播层的导数和反向传播层的导数，这在整个网络中都是正确的。这被称为反向传播算法，它允许我们在整个网络中更新权重，而无需不断重新计算相对于我们从头开始确定的特定权重的误差导数，并且我们可以重用以前计算的结果。

# 随机梯度下降算法

We can further optimize the training process with a simple change. With basic (or batch) gradient descent, we calculate the adjustment by looking at the entire dataset. Therefore, the next obvious step for optimization is: can we calculate the adjustment by looking at less than the entire dataset?

事实证明，答案是肯定的！由于我们希望通过多次迭代来训练网络，我们可以利用这样一个事实，即我们希望通过计算较少的示例来多次更新梯度。我们甚至可以通过一个例子来计算它。通过对每次网络更新执行较少的计算，我们可以显著减少所需的计算量，这意味着更快的训练时间。这本质上是对梯度下降的一种随机近似，因此它得名。

# Advanced gradient descent algorithms

现在，我们已经了解了 SGD 和反向传播，让我们看看一些高级优化方法（基于 SGD），它们为我们提供了一些优势，通常是训练时间的改进（或将成本函数最小化到网络收敛点所需的时间）。

这些*改进的*方法包含了速度作为优化参数的一般概念。引用 Wibisono 和 Wilson 关于*优化*中*加速方法的论文的开头部分：*

“在凸优化中，存在一种加速现象，我们可以提高某些基于梯度的算法的收敛速度。”

简言之，许多先进的算法都依赖于一个相似的原理，即它们可以快速通过局部最优解，通过它们的*动量-*基本上是我们梯度的移动平均值。

# 推进力

当考虑梯度下降的优化时，我们当然可以利用现实生活中的直觉来帮助我们了解我们的方法。其中一个例子就是动量。如果我们想象到大多数误差梯度都像一个碗，中间的期望点，如果我们从碗的最高点开始，我们可能需要很长的时间才能到达碗底。

如果我们考虑一些现实生活中的物理现象，碗的一侧越陡，球在获得动量时沿着一侧下落的速度就越快。以此为灵感，我们可以得到 SGD 的动量变化；我们试图通过考虑，如果梯度继续沿着同一方向下降，我们会给它更多的动量，来帮助加速下降。或者，如果我们发现梯度在改变方向，我们会减少动量。

虽然我们不想陷入繁重的数学中，但有一个简单的公式可以计算*动量*。详情如下:

*V=动量*m-lr*g*

这里，*m*是之前的权重更新，*g*是相对于参数*p*的当前梯度，*lr*是我们解算器的学习速率，*动量*是常数。

因此，如果我们想准确了解如何更新网络参数，我们可以通过以下方式调整公式：

*P(new) = p + v = p + momentum * m - lr * g*

这在实践中意味着什么？让我们看一些代码。

首先，在 Gorgonia 中，所有优化方法或求解器的基本界面如下所示：

```go
type Solver interface {
                       Step([]ValueGrad) error
                      }
```

We then have the following function that provides construction options for a `Solver`:

```go
type SolverOpt func(s Solver)
```

当然，设定的主要选择是利用动量本身；此选项的`SolverOpt`选项为`WithMomentum`。应用的解算器选项包括`WithL1Reg`、`WithL2Reg`、`WithBatchSize`、`WithClip`和`WithLearnRate`。

让我们使用本章开头的代码示例，但是，我们不使用普通的 SGD，而是使用动量解算器的最基本形式，如下所示：

```go
vm := NewTapeMachine(g, BindDualValues(m.learnables()...))
solver := NewMomentum()
```

就这样！但这并没有告诉我们太多，只是 Gorgonia 和任何优秀的机器学习库一样，具有足够的灵活性和模块化，我们可以简单地交换我们的解算器（并测量相对性能！）。

So, let's take a look at the function we are calling, as shown in the following code:

```go
func NewMomentum(opts ...SolverOpt) *Momentum {
            s := Momentum{
            eta: 0.001,
            momentum: 0.9,
            }
 for _, opt := range opts {
            opt(s)
            }
            return s
 }
```

我们可以在这里看到我们在该方法的原始公式中引用的`momentum`常数，以及`eta`，这是我们的学习率。这就是我们需要做的一切；将动量解算器应用于我们的模型！

# 内斯特罗夫动量

在 Nesterov 动量中，我们改变了计算梯度的位置/时间。我们在先前累积的梯度方向上做了一个大跳跃。然后，我们在这个新位置测量梯度，并进行相应的校正/更新。

这种修正防止了普通动量算法更新过快，因此在梯度下降尝试收敛时产生较少的振荡。

# RMSprop

我们也可以用另一种方式来考虑优化：如果我们根据特征重要性调整学习率会怎么样？我们可以在更新常见特征的参数时降低学习率，然后在查看更不常见的特征时提高学习率。这也意味着我们可以花更少的时间优化学习速度。已经提出了这种想法的几种变体，但到目前为止最流行的是 RMSprop。

RMSprop 是 SGD 的一种改进形式，虽然尚未发表，但在 Geoffrey Hinton 的《机器学习神经网络》中进行了详细阐述。RMSprop 听起来很花哨，但它也可以很容易地被称为**自适应梯度下降**。基本思想是根据特定条件修改学习率。

这些条件可以简单地表述如下：

*   If the gradient of the function is small but consistent, then increase the learning rate
*   如果函数的梯度较大但不一致，则降低学习速率

RMSprop 的具体方法是将权重的学习率除以先前梯度的衰减平均值。

Gorgonia 在本地支持 RMSprop。与动量示例一样，您只需交换您的`solver`。以下是您如何定义它，以及您希望传入的一些`solveropts`：

```go
solver = NewRMSPropSolver(WithLearnRate(stepSize), WithL2Reg(l2Reg), WithClip(clip))
```

Inspecting the underlying function, we see the following options and their associated defaults for decay factor, smoothing factor, and learning rate, respectively:

```go
func NewRMSPropSolver(opts...SolverOpt) * RMSPropSolver {
    s: = RMSPropSolver {
        decay: 0.999,
        eps: 1e-8,
        eta: 0.001,
    }

        for _,
    opt: = range opts {
        opt(s)
    }
    return s
}
```

# 总结

在本章中，我们介绍了如何构建一个简单的神经网络，如何检查图形，以及许多常用的激活函数。然后，我们介绍了如何通过反向传播和梯度下降训练神经网络的基本知识。最后，我们讨论了梯度下降算法和神经网络优化的一些不同选项。

下一章将介绍构建实用的前馈神经网络和自编码器，以及**受限玻尔兹曼机器**（**RBMs**）。