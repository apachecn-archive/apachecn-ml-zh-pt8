# 六、基于卷积神经网络的目标识别

现在是时候讨论一些计算机视觉或图像分类问题了，这些问题比我们前面的 MNIST 手写示例更一般。很多相同的原理都适用，但我们将使用一些新类型的运算来构建**卷积神经网络****网络**（**CNN**。

本章将涵盖以下主题：

*   CNNs 简介
*   树立 CNN 的榜样
*   评估结果并作出改进

# CNNs 简介

CNN 是一类深度神经网络，它们非常适合于具有多个通道的数据，并且对输入网络中包含的信息的局部性非常敏感。这使得 CNN 非常适合于与计算机视觉相关的任务，如人脸识别、图像分类、场景标记等

# 什么是有线电视新闻网？

CNN，也称为**ConvNets**，是一类或一类通常被认为非常擅长图像分类的神经网络，也就是说，它们非常擅长区分猫与狗、汽车与飞机以及许多其他常见的分类任务。

CNN 通常由卷积层、激活层和池层组成。然而，它被专门构造为利用输入通常是图像这一事实，并且利用图像的某些部分很可能彼此相邻这一事实。

实际上，它们在实现方面与我们在前面章节中介绍的前馈网络非常相似。

# 正常前馈与 ConvNet

In general, a neural network receives a single vector as input (such as our MNIST example in [Chapter 3](03.html), *Beyond Basic Neural Networks – Autoencoders and RBMs*) and then goes through several hidden layers, before arriving at the end with our inference for the result. This is fine for images that aren't that big; when our images become larger, however, as they usually are in most real-life applications, we want to ensure that we aren't building immensely large hidden layers to process them correctly.

当然，在我们关于张量的想法中，一个方便的特点是，我们实际上不需要向模型中输入向量；我们可以提供一些更复杂、尺寸更大的东西。基本上，我们想用 CNN 做的是让神经元排列成三个维度：高度、宽度和深度我们这里所说的深度是我们颜色系统中颜色的数量，在我们的例子中是红色、绿色和蓝色。

我们不会试图将一层中的每个神经元连接在一起，而是尝试减少它，使其更易于管理，并且不太可能过度适合我们的样本大小，因为我们不会尝试训练输入的每个像素。

# 层

当然，CNN 使用层，我们需要更详细地讨论其中的一些层，因为我们还没有讨论它们；一般来说，CNN 中有三个主要层：卷积层、池层和完全连接层（这些是您已经看到的）。

# 卷积层

卷积层是这种神经网络名称的一部分，是神经网络架构中非常重要的一部分。它可以广义地解释为扫描图像以找到某些特征。我们创建一个小的过滤器，然后根据所需的步幅在整个图像上滑动。

因此，例如，通过查找我们的 3 x 3 滤波器的**点积**与我们的**图像**的左上角计算输出的第一个单元格，如下图所示：

![](img/c91d32a0-1c57-4c34-b655-ec010737ac00.png)

如果你的步幅是一，它会向右移动一列并继续，如下所示：

![](img/bc423070-20d8-4603-859f-3818d9aacb32.png)

这将一直持续到我们有了全部的产出。

# 池层

池层通常放在卷积层之间；它们旨在减少传递的数据量，从而减少参数数量，并减少网络所需的计算量。在这种情况下，我们通过在给定的数字区域上取最大值来将数字汇集在一起。

这些层的工作方式也类似于卷积层；它们在预定网格上应用并执行池操作。在这种情况下，它是最大操作，因此它将在网格中取最高值。

例如，在 2 x 2 网格上的最大池操作中，输出的第一个单元格将来自左上角，如下所示：

![](img/f819e869-6747-45e1-91de-27b878f7ef45.png)

步幅为 2 时，第二个将来自向右移动两行的网格，如下所示：

![](img/911e2c7d-0498-4763-9c0a-828918037283.png)

# Basic structure

现在您已经了解了层，让我们来谈谈 CNN 的基本结构。CNN 大致由以下几层组成：输入层，然后是几层卷积层、激活层和池层，最后是一个完全连接的层，以获得最终结果。

基本结构看起来有点像以下内容：

![](img/a840475f-4055-40b9-b2ef-34e9126359a8.png)

# 树立 CNN 的榜样

为了说明 CNN 在实践中是如何工作的，我们将建立一个模型来识别照片中的物体是否是猫。我们使用的数据集比这更深入，但要训练它正确地对所有内容进行分类需要相当长的时间。扩展示例对所有内容进行分类是相当简单的，但我们不希望在那里等待一周的模型训练。

对于我们的示例，我们将使用以下结构：

![](img/1773604f-ee5a-4e45-a98e-1931d0252d8f.png)

# CIFAR-10

这次我们使用 CIFAR-10 作为示例，而不是 MNIST。因此，我们无法方便地使用已经很方便的 MNIST 加载程序。让我们快速了解加载此新数据集所需的步骤！

我们将使用 CIFAR-10 的二进制格式，您可以在此处下载：[https://www.cs.toronto.edu/~kriz/cifar.html](https://www.cs.toronto.edu/~kriz/cifar.html)。

该数据集由 Alex Krizhevsky、Vinod Nair 和 Geoffrey Hinton 组合而成。它由 60000 个 32 像素高、32 像素宽的微小图像组成。CIFAR-10 的二进制格式如下所示：

```go
<1 x label><3072 x pixel>
<1 x label><3072 x pixel>
<1 x label><3072 x pixel>
<1 x label><3072 x pixel>
<1 x label><3072 x pixel>
<1 x label><3072 x pixel>
 ...
<1 x label><3072 x pixel>
```

应该注意的是，它没有分隔符，或者没有任何其他信息用于验证文件；因此，您应该确保下载的文件的 MD5 校验和与网站上的匹配。由于结构相对简单，我们可以直接将二进制文件拉入 Go 并相应地解析它。

3072 像素实际上是三层红色、绿色和蓝色的值，从 0 到 255，在一个 32 x 32 的网格上，按行的主要顺序排列，所以这给了我们图像数据。

标签是一个从**0**到**9**的数字，分别代表以下类别之一：

![](img/5dbee2fd-efdf-4ec2-815f-7db63d1ab4eb.png)

CIFAR-10 有六个文件，五个训练集文件（每个文件包含 10000 个图像）和一个测试集文件（每个文件包含 10000 个图像）：

```go
case "train":
    arrayFiles = []string{
        "data_batch_1.bin",
        "data_batch_2.bin",
        "data_batch_3.bin",
        "data_batch_4.bin",
        "data_batch_5.bin",
    }
case "test":
    arrayFiles = []string{
        "test_batch.bin",
    }
}
```

在 Go 中导入此文件很容易打开文件并读取原始字节。由于每个基础值都是一个字节内的 8 位整数，因此我们可以将其强制转换为我们想要的任何值。如果需要单个整数值，可以将它们全部转换为无符号 8 位整数；当您要将数据转换为图像时，这非常有用。但是，您会发现，我们在代码中做出了一些稍微不同的决定，如下所示：

```go
f, err := os.Open(filepath.Join(loc, targetFile))
if err != nil {
    log.Fatal(err)
}

defer f.Close()
cifar, err := ioutil.ReadAll(f)

if err != nil {
    log.Fatal(err)
}

for index, element := range cifar {
    if index%3073 == 0 {
        labelSlice = append(labelSlice, float64(element))
    } else {
        imageSlice = append(imageSlice, pixelWeight(element))
    }
}
```

由于我们有兴趣将这些数据用于我们的深度学习算法，因此谨慎的做法是不要偏离`0`和`1`之间的快乐媒介太远。我们重用 MNIST 示例中的像素权重，如下所示：

```go
func pixelWeight(px byte) float64 {
    retVal := float64(px)/pixelRange*0.9 + 0.1
    if retVal == 1.0 {
        return 0.999
    }
    return retVal
}
```

这将把从 0 到 255 的所有像素值转换为介于`0.1`和`1.0`之间的范围。

同样，对于我们的标签，我们将再次使用一个热编码，在`0.9`处编码所需标签，在`0.1`处编码所有其他内容，如下代码所示：

```go
labelBacking := make([]float64, len(labelSlice)*numLabels, len(labelSlice)*numLabels)
labelBacking = labelBacking[:0]
for i := 0; i < len(labelSlice); i++ {
    for j := 0; j < numLabels; j++ {
        if j == int(labelSlice[i]) {
            labelBacking = append(labelBacking, 0.9)
        } else {
            labelBacking = append(labelBacking, 0.1)
        }
    }
}
```

我们已经将其打包成一个方便的`Load`函数，以便我们可以从代码中调用它。它将返回两个形状方便的张量供我们使用。这为我们提供了一个可以导入列车和测试集的功能：

```go
func Load(typ, loc string) (inputs, targets tensor.Tensor, err error) {

    ...

    inputs = tensor.New(tensor.WithShape(len(labelSlice), 3, 32, 32),        tensor.WithBacking(imageSlice))
    targets = tensor.New(tensor.WithShape(len(labelSlice), numLabels), tensor.WithBacking(labelBacking))
    return
}
```

This allows us to load the data in my `main` by calling the following:

```go
if inputs, targets, err = cifar.Load("train", loc); err != nil {
    log.Fatal(err)
}
```

# 时代和批量大小

我们将为这个例子选择`10`时代，这样代码就可以在不到一小时的时间内进行训练。需要注意的是，10 个纪元只能使我们获得 20%左右的准确度，因此，如果您发现生成的模型看起来不准确，请不要惊慌；你需要训练更长的时间，甚至可能需要 1000 个纪元左右。在现代计算机上，一个纪元大约需要三分钟才能完成；为了不需要三天时间来完成此示例，我们选择缩短培训过程，并将其作为一个练习来评估更多时代的结果，如下所示：

```go
var (
    epochs = flag.Int("epochs", 10, "Number of epochs to train for")
    dataset = flag.String("dataset", "train", "Which dataset to train on? Valid options are \"train\" or \"test\"")
    dtype = flag.String("dtype", "float64", "Which dtype to use")
    batchsize = flag.Int("batchsize", 100, "Batch size")
    cpuprofile = flag.String("cpuprofile", "", "CPU profiling")
)
```

请注意，此模型将消耗相当大的内存量；`100`的`batchsize`仍然意味着您将需要大约 4GB 的内存。如果在不交换内存的情况下无法获得此数量的代码，则可能需要降低批处理大小，以使代码在计算机上的性能更好。

# 精确

由于这个模型需要更长的时间才能收敛，我们还应该添加一个基本的度量来跟踪我们的精度。为了做到这一点，我们必须首先从数据中提取我们的标签-我们可以按照以下步骤进行：

```go
 // get label
    yRowT, _ := yVal.Slice(sli{j, j + 1})
    yRow := yRowT.Data().([]float64)
    var rowLabel int
    var yRowHigh float64

    for k := 0; k < 10; k++ {
        if k == 0 {
            rowLabel = 0
            yRowHigh = yRow[k]
        } else if yRow[k] > yRowHigh {
            rowLabel = k
            yRowHigh = yRow[k]
        }
    }
```

然后，我们必须从输出数据中获得预测：

```go
yOutput2 := tensor.New(tensor.WithShape(bs, 10), tensor.WithBacking(arrayOutput2))

 // get prediction
    predRowT, _ := yOutput2.Slice(sli{j, j + 1})
    predRow := predRowT.Data().([]float64)
    var rowGuess int
    var predRowHigh float64

    // guess result
    for k := 0; k < 10; k++ {
        if k == 0 {
            rowGuess = 0
            predRowHigh = predRow[k]
        } else if predRow[k] > predRowHigh {
            rowGuess = k
            predRowHigh = predRow[k]
        }
    }
```

然后，我们可以使用它来更新精度度量。它的更新量根据示例的数量进行缩放，因此我们的输出将是一个百分比。

```go
if rowLabel == rowGuess {
    accuracyGuess += 1.0 / float64(numExamples)
}
```

这给了我们一个广泛的*准确度*指标，我们可以用来衡量我们的训练进度。

# 构建层

我们可以认为我们的层结构有四个部分。我们将有三个卷积层和一个完全连接层。我们的前两层非常相似-它们遵循我们前面描述的卷积 ReLU MaxPool dropout 结构：

```go
// Layer 0
if c0, err = gorgonia.Conv2d(x, m.w0, tensor.Shape{5, 5}, []int{1, 1}, []int{1, 1}, []int{1, 1}); err != nil {
    return errors.Wrap(err, "Layer 0 Convolution failed")
}
if a0, err = gorgonia.Rectify(c0); err != nil {
    return errors.Wrap(err, "Layer 0 activation failed")
}
if p0, err = gorgonia.MaxPool2D(a0, tensor.Shape{2, 2}, []int{0, 0}, []int{2, 2}); err != nil {
    return errors.Wrap(err, "Layer 0 Maxpooling failed")
}
if l0, err = gorgonia.Dropout(p0, m.d0); err != nil {
    return errors.Wrap(err, "Unable to apply a dropout")
}
```

我们的下一层是类似的-我们只需要将其连接到上一层的输出：

```go
// Layer 1
if c1, err = gorgonia.Conv2d(l0, m.w1, tensor.Shape{5, 5}, []int{1, 1}, []int{1, 1}, []int{1, 1}); err != nil {
    return errors.Wrap(err, "Layer 1 Convolution failed")
}
if a1, err = gorgonia.Rectify(c1); err != nil {
    return errors.Wrap(err, "Layer 1 activation failed")
}
if p1, err = gorgonia.MaxPool2D(a1, tensor.Shape{2, 2}, []int{0, 0}, []int{2, 2}); err != nil {
    return errors.Wrap(err, "Layer 1 Maxpooling failed")
}
if l1, err = gorgonia.Dropout(p1, m.d1); err != nil {
    return errors.Wrap(err, "Unable to apply a dropout to layer 1")
}
```

以下层基本相同，但有一个细微的变化，使其为完全连接层的变化做好准备：

```go
// Layer 2
if c2, err = gorgonia.Conv2d(l1, m.w2, tensor.Shape{5, 5}, []int{1, 1}, []int{1, 1}, []int{1, 1}); err != nil {
    return errors.Wrap(err, "Layer 2 Convolution failed")
}
if a2, err = gorgonia.Rectify(c2); err != nil {
    return errors.Wrap(err, "Layer 2 activation failed")
}
if p2, err = gorgonia.MaxPool2D(a2, tensor.Shape{2, 2}, []int{0, 0}, []int{2, 2}); err != nil {
    return errors.Wrap(err, "Layer 2 Maxpooling failed")
}

var r2 *gorgonia.Node
b, c, h, w := p2.Shape()[0], p2.Shape()[1], p2.Shape()[2], p2.Shape()[3]
if r2, err = gorgonia.Reshape(p2, tensor.Shape{b, c * h * w}); err != nil {
    return errors.Wrap(err, "Unable to reshape layer 2")
}
if l2, err = gorgonia.Dropout(r2, m.d2); err != nil {
    return errors.Wrap(err, "Unable to apply a dropout on layer 2")
}
```

`Layer 3`是我们已经非常熟悉的完全连接层，我们有一个相当简单的结构。我们当然可以向这一层添加更多的层（以前许多不同的架构也都这样做过，但成功的程度不同）。该层在以下代码中演示：

```go
// Layer 3
log.Printf("l2 shape %v", l2.Shape())
log.Printf("w3 shape %v", m.w3.Shape())
if fc, err = gorgonia.Mul(l2, m.w3); err != nil {
    return errors.Wrapf(err, "Unable to multiply l2 and w3")
}
if a3, err = gorgonia.Rectify(fc); err != nil {
    return errors.Wrapf(err, "Unable to activate fc")
}
if l3, err = gorgonia.Dropout(a3, m.d3); err != nil {
    return errors.Wrapf(err, "Unable to apply a dropout on layer 3")
}
```

# 损失函数及其求解

我们将在这里使用普通的交叉熵损失函数，其可实现如下：

```go
losses := gorgonia.Must(gorgonia.HadamardProd(gorgonia.Must(gorgonia.Log(m.out)), y))
cost := gorgonia.Must(gorgonia.Sum(losses))
cost = gorgonia.Must(gorgonia.Neg(cost))

if _, err = gorgonia.Grad(cost, m.learnables()...); err != nil {
    log.Fatal(err)
}
```

除此之外，我们还将使用 Gorgonia 磁带机和 RMSprop 解算器，如下所示：

```go
vm := gorgonia.NewTapeMachine(g, gorgonia.WithPrecompiled(prog, locMap), gorgonia.BindDualValues(m.learnables()...))
solver := gorgonia.NewRMSPropSolver(gorgonia.WithBatchSize(float64(bs)))
```

# Test set output

在培训结束时，我们应该将模型与测试集进行比较。

首先，我们应按如下方式导入测试数据：

```go
if inputs, targets, err = cifar.Load("test", loc); err != nil {
    log.Fatal(err)
}
```

然后，我们需要重新计算批次，因为测试集的大小与列车集的大小不同：

```go
batches = inputs.Shape()[0] / bs
bar = pb.New(batches)
bar.SetRefreshRate(time.Second)
bar.SetMaxWidth(80)
```

We then need to just add a quick way to track our results and output our results for later inspection by inserting the following code into the accuracy metric calculation code described earlier in the chapter:

```go
// slices to store our output
var testActual, testPred []int

// store our output into the slices within the loop
testActual = append(testActual, rowLabel)
testPred = append(testPred, rowGuess)
```

最后，在整个测试集的运行结束时，将数据写入文本文件：

```go
printIntSlice("testActual.txt", testActual)
printIntSlice("testPred.txt", testPred)
```

现在让我们评估一下结果。

# 评估结果

如前所述，经过 10 个时期训练的例子并不特别准确。你需要在许多时期对它进行训练，以获得更好的结果。如果您一直在关注模型的成本和精度，您会发现随着时间的推移，随着精度的增加，成本将保持相对平稳，如下图所示：

![](img/56e90fa4-1342-4b15-8d55-a1287eb2cba9.png)

It is still useful to explore the results to see how the model is performing; we'll specifically look at cats:

![](img/235068fc-b8a5-4209-aa8c-ebef1b32bb49.png)

正如我们所看到的，在非常特殊的位置上，猫的表现似乎要好得多。显然，我们需要找到一个解决方案来加快训练速度。

# GPU 加速

卷积及其相关运算在 GPU 加速方面往往表现良好。您在前面看到，我们的 GPU 加速的影响最小，但它对于构建 CNN 非常有用。我们需要做的就是添加神奇的`'cuda'`构建标签，如下所示：

```go
go build -tags='cuda'
```

由于我们倾向于在 GPU 上更多地限制内存，请注意，相同的批处理大小可能无法在您的 GPU 上工作。前面提到的模型使用了大约 4GB 的内存，因此，如果 GPU 内存小于 6GB，您可能会希望减少批处理大小（因为您的普通桌面大概将使用大约 1GB 的内存）。如果您的模型运行非常慢，或者 CUDA 版本的可执行文件失败，那么谨慎的做法是检查内存是否不足。你可以使用英伟达 SMI 实用程序，并让它每秒检查你的内存，如图所示：

```go
nvidia-smi -l 1
```

这将倾向于每秒生成以下报告；在代码运行时观察它将大致告诉您代码消耗了多少 GPU 内存：

![](img/4c24d016-134d-4fe8-b69c-397847f0af81.png)

让我们快速比较一下 CPU 和 GPU 版本代码之间的性能。CPU 版本每一历元大约需要三分钟，如下代码所示：

```go
2018/12/30 13:23:36 Batches 500
2018/12/30 13:26:23 Epoch 0 |
2018/12/30 13:29:15 Epoch 1 |
2018/12/30 13:32:01 Epoch 2 |
2018/12/30 13:34:47 Epoch 3 |
2018/12/30 13:37:33 Epoch 4 |
2018/12/30 13:40:19 Epoch 5 |
2018/12/30 13:43:05 Epoch 6 |
2018/12/30 13:45:50 Epoch 7 |
2018/12/30 13:48:36 Epoch 8 |
2018/12/30 13:51:22 Epoch 9 |
2018/12/30 13:51:55 Epoch Test |
```

GPU 版本每个历元大约需要 2 分 30 秒，如下代码所示：

```go
2018/12/30 12:57:56 Batches 500
2018/12/30 13:00:24 Epoch 0
2018/12/30 13:02:49 Epoch 1
2018/12/30 13:05:15 Epoch 2
2018/12/30 13:07:40 Epoch 3
2018/12/30 13:10:04 Epoch 4
2018/12/30 13:12:29 Epoch 5
2018/12/30 13:14:55 Epoch 6
2018/12/30 13:17:21 Epoch 7
2018/12/30 13:19:45 Epoch 8
2018/12/30 13:22:10 Epoch 9
2018/12/30 13:22:40 Epoch Test
```

Gorgonia 的未来版本还将包括对更好操作的支持；目前正在测试中，您可以通过导入`gorgonia.org/gorgonia/ops/nn`并用`nnops`版本替换来自 Gorgonia 版本的`Conv2d`、`Rectify`、`MaxPool2D`和`Dropout`调用来使用它，一个稍微不同的`Layer 0`示例如下：

```go
if c0, err = nnops.Conv2d(x, m.w0, tensor.Shape{3, 3}, []int{1, 1}, []int{1, 1}, []int{1, 1}); err != nil {
    return errors.Wrap(err, "Layer 0 Convolution failed")
}
if a0, err = nnops.Rectify(c0); err != nil {
    return errors.Wrap(err, "Layer 0 activation failed")
}
if p0, err = nnops.MaxPool2D(a0, tensor.Shape{2, 2}, []int{0, 0}, []int{2, 2}); err != nil {
    return errors.Wrap(err, "Layer 0 Maxpooling failed")
}
if l0, err = nnops.Dropout(p0, m.d0); err != nil {
    return errors.Wrap(err, "Unable to apply a dropout")
}
```

作为练习，替换所有必要的操作并运行它以查看其不同之处。

# 有线电视新闻网的弱点

CNN 实际上有一个相当大的弱点：它们不是方向不变的，这意味着如果你输入相同的图像，但是颠倒过来，网络可能根本无法识别它。我们可以确保情况并非如此的方法之一是以不同的旋转来训练模型；然而，有更好的架构可以解决这个问题，我们将在本书后面讨论。

它们也不是尺度不变的。将同一个图像输入到更小或更大的图像中，可能会导致失败。如果你回想一下为什么会出现这种情况，那是因为我们正在基于一组非常特定的像素构建一个非常特定大小的过滤器。

您还看到，该模型通常训练速度非常慢，尤其是在 CPU 上。我们可以通过使用 GPU 来解决这个问题，但总的来说，这是一个昂贵的过程，可能需要几天才能完成。

# 总结

现在，您已经学习了如何构建 CNN，以及如何调整一些超参数（例如历元数和批量大小），以获得所需的结果，并使其在不同的计算机上顺利运行。

As an exercise, you should try training this model to recognize MNIST digits, and even change around the structure of the convolutional layers; try Batch Normalization, and perhaps even more weights in the fully connected layer.

下一章将介绍强化学习和 Q-学习，以及如何构建 DQN 和解决迷宫

# 进一步阅读

*   *用于文本分类的字符级卷积网络*由*张翔、赵俊波*和*Yann LeCun*
*   *U-Net：由*Olaf Ronneberger*、*Philipp Fischer*和*Thomas Brox*制作的用于生物医学图像分割的卷积网络*
*   *更快的 R-CNN：通过*任少清*、*何开明*、*罗斯·吉尔希克*和*孙健*的区域建议网络*实现实时目标检测
*   *用于视觉识别和描述的长期递归卷积网络**杰夫·多纳休*、*丽莎·安妮·亨德里克斯*、*马库斯·罗巴赫*、*苏巴什尼·维努戈帕兰*、*塞尔吉奥·瓜达拉马*、*凯特·萨恩科*和*特雷弗·达雷尔*