# 六、关联规则算法

关联规则学习，或称关联规则挖掘，是一种相对现代的无监督学习技术，最初用于发现杂货店购买商品之间的关联。关联规则挖掘的目标是发现物品集之间有趣的关系，例如，发现准备飓风的购物者经常在购买瓶装水、电池和手电筒的同时购买馅饼。

在[第五章](05.html)、*分类算法*中，我们引入了条件概率的概念。在这一章中，我们将进一步探讨这个概念，并将条件概率应用于关联规则学习。回想一下，条件概率会问(并回答)这样一个问题:假设我们知道一些事情，那么其他事情发生的概率是多少？或者，假设有人也买了瓶装水和电池，那么他们买 Pop-Tarts 的概率有多大？概率很高，我们很快就会看到。

在关联规则学习中，我们的目标是查看事务或事件的数据库，并通过概率将最常见的子集相互关联。用一个例子可能更容易理解。假设你经营一家电子商务商店，你的任务是在主页上创建一个个性化的小部件，向购物者推荐产品。您拥有他们订单历史的完整数据库，并且您必须使用购物者的浏览历史来建议他们很有可能购买的商品。

自然，有几种方法可以解决这个问题。除了时间和复杂性，你没有理由不能在你的商店的整个订单历史上训练神经网络来建议新产品。在数百万笔交易上训练神经网络既耗时，又很难直观地检查和理解。另一方面，关联规则学习为我们提供了一个基于基本概率概念的简单快捷的工具。

假设你的电子商务商店是一个销售精品、精选家居装饰品和家具的直运企业。你的目标是确定最常一起购买的物品，例如:90%购买躺椅和茶几的人也购买了搁脚凳，80%购买巨型挂钟的人也购买了干墙安装锚定装置。

如果您有一种快速有效的方法来搜索数百万个以前的订单以找到这些关系，您可以将当前购物者的浏览历史与其他购物者的购买历史进行比较，并显示购物者最有可能购买的商品。

关联规则学习不仅限于电子商务。另一个明显的应用是实体店，比如你当地的超市。如果 90%买牛奶和鸡蛋的购物者也买面包，最好把面包放在附近，这样你的购物者就能更容易找到它。或者，你可能想把面包放在商店对面的*一侧，因为你知道购物者将不得不穿过一堆过道，可能会在路上拿更多的东西。如何使用这些数据由您决定，取决于您想要优化什么:购物者便利性或总购物篮价值。*

 *乍一看，这似乎是一个很容易编写的算法——毕竟，我们只是在计算概率。然而，由于有一个大型数据库和大量可能的项目可供选择，检查每个项目组合的频率变得非常耗时，因此我们需要比暴力、穷举搜索方法更复杂的东西。

在本章中，我们将讨论:

*   数学视角下的关联规则学习
*   对 Apriori 算法的描述
*   关联规则学习的各种应用
*   各种关联规则算法的工作示例

让我们从数学的角度来看关联规则学习。

# 数学视角

关联规则学习假设您有一个*事务数据库*可以学习。这并不涉及任何特定的技术，而是存储事务的数据库的概念——数据库可以是内存中的数组、Excel 文件或生产 MySQL 或 PostgreSQL 实例中的表。由于关联规则学习是为超市产品开发的，最初的交易数据库是每个购物者在给定购物行程中购买的物品列表，本质上是结账通道的收据档案。然而，事务数据库可以是在单个会话期间发生的项目或事件的任何列表，无论该会话是购物旅行、网站访问还是去看医生。目前，我们将考虑超市的例子。我们将在后面的部分讨论关联规则的其他用途。

事务性数据库是行是会话，列是*项*的数据库。请考虑以下几点:

| **收据** | **鸡蛋** | **牛奶** | **面包** | **奶酪** | **洗发水** |
| one | 是 | 是 | 不 | 是 | 不 |
| Two | 不 | 不 | 是 | 是 | 不 |
| three | 不 | 不 | 不 | 不 | 是 |
| four | 是 | 是 | 是 | 是 | 不 |
| five | 是 | 是 | 不 | 是 | 不 |

这样的表可以被视为事务性数据库。请注意，我们并没有记录每件物品的购买数量，只是记录了该物品是否被购买。这是大多数关联规则学习的情况:项目的数量和顺序通常都被忽略。

根据表格中的信息，我们可以把各种事件发生的概率放在一起。例如，购物者购买`Shampoo`或 *P(E <sub>洗发水</sub>)*的概率为 20%。购物者同时购买`Cheese`和`Bread`的概率为 40%，因为五个购物者中有两个同时购买了`Cheese`和`Bread`。

从数学上讲，*牛奶*和*面包*被称为**项目集**，通常被写成`{milk, bread}`。项目集类似于我们在[第五章](05.html)、*分类算法*中介绍的概率*事件*的概念，只是项目集专门用于这种情况，事件在概率上是一个更一般的概念。

在关联规则学习中，项目集作为事务的一部分出现的概率被称为该项目集的**支持**。刚才我们提到，有人同时买牛奶和面包的概率是 40%；这是对`{milk, bread}`项集的支持度为 40%的另一种说法。从数学上来说，我们可以写出`supp({milk, bread}) = 40%`。

然而，计算项目集的支持度并不能让我们完全了解关联规则学习。我们首先需要定义什么是关联规则。关联规则的形式为 X -> Y，其中 *X* 和 *Y* 都是项目集。完整地写出，一个示例关联规则可以是`{eggs, milk} -> {cheese}`，它将购买鸡蛋和牛奶与购买奶酪联系起来。关联规则几乎总是在右侧只有一个项目，尽管左侧可以有任意数量的项目。关联规则本身没有告诉我们任何关于关联的信息；我们还需要看各种指标，比如协会的*信心*和*提升*，才能了解协会有多强。

关联规则需要考虑的最重要的指标是其*置信度*，也就是规则被发现为真的频率。*置信度*也恰好是*P(E<sub>Y</sub>| E<sub>X</sub>)*的条件概率，或者是有人在`X`中购买了项目集`Y`中的项目的概率。

利用我们在第五章*分类算法*中的条件概率知识，以及关联规则学习中*支持*和*置信度*的新概念，我们来写几个等价式，帮助我们固化这些数学概念。

首先，假设项目集`X`是鸡蛋和牛奶，或者`X = {eggs, milk}`，以及`Y = {cheese}`。

`X`或`supp(X)`的支持，与交易中`X`找到物品的概率，或 *P(E <sub>X</sub> )* 相同。在这种情况下，鸡蛋和牛奶出现在五分之三的交易中，因此其支持度为 60%。同样`Y`(只是奶酪)的支持率也是 80%。

关联规则的置信度`X -> Y`定义为`conf(X -> Y) = supp(X ∪ Y) / supp(X)`。另一种说法是，规则的置信度是规则中所有项目的支持度除以左手边的支持度。∪符号在概率论中用来表示*并集—* 基本上是布尔或运算。因此，`X`和`Y`项目集的*联合是出现在 X 或 y 中的任何项目。在我们的例子中，联合是鸡蛋、牛奶和奶酪。*

如果`supp(X) = P(EX)`，那么`supp(X ∪ Y) = P(EX ∩ XY)`。回想一下∪是*交集*的符号，或者本质上是布尔 AND *。*这是一个项目集语义不同于概率事件语义的场景——两个项目集的*并集*与包含这些项目集的两个事件的*交集*相关。尽管符号有点混乱，但我们得到的是这样的:一旦我们开始将关联规则符号转换为标准概率符号，这个*置信度*公式就开始看起来完全像条件概率公式。

因为在条件概率中，*P(E<sub>Y</sub>| E<sub>X</sub>)= P(E<sub>X</sub>∪E<sub>Y</sub>)/P(E<sub>X</sub>)*关系定义了条件概率，我们知道`supp(X ∪ Y) = P(E<sub>X</sub> ∩ E<sub>Y</sub>)`，我们也知道*P(E<sub>X</sub>)= supp(X)*

回到我们的`{eggs, milk} ⇒ {cheese}`的示例规则，我们发现这个规则的置信度是 1.0。 *X* 和 *Y* (或`{eggs, milk, cheese}`)的并集出现在 5 笔交易中的 3 笔，支持度为 0.6。我们用左手边的支持来划分，或者仅仅是`supp ({eggs, milk})`，我们也可以在五个交易中的三个中找到。0.6 除以 0.6 得到 1.0，这是可能的最高置信值。每次购物者买鸡蛋和牛奶，他们也会买奶酪。或者，用条件概率来说，如果有人买了鸡蛋和牛奶，他买奶酪的概率是 100%。相比之下，有人买奶酪的概率只有 80%。很明显，鸡蛋、牛奶和奶酪之间有着积极的关系。

这种巧合的关系可以用一个叫做**抬** *的概念来进一步探究。*升力定义为组合项的支撑，除以左侧和右侧单独的支撑(即假设它们是独立的)。公式为`lift(X -> Y) = supp(X ∪ Y) / ( supp(X) * supp(Y) )`。这个公式本质上衡量了`X`和`Y`之间的依赖或独立程度。如果`X`和`Y`在一起的支撑与`X`和`Y`分开的支撑相同，则规则的提升为 1，`X`和`Y`可以认为是完全独立的。随着两个项目集的相互依赖性增加，*提升*的值也会增加。在我们的情况下，`{eggs, milk, cheese}`的支撑再次为 0.6，`{eggs, milk}`的支撑为 0.6，`{cheese}`的支撑为 0.8。将这些值与升力方程相结合，我们就得到`lift(X -> Y) = 0.6 / (0.6 * 0.8) = 1.25`。这个规律据说有 25%的升力，说明`{eggs, milk}`和`{cheese}`之间存在某种依赖关系。

研究人员在开发关联规则时还可以使用其他几个指标，尽管我们在示例中不会遇到这些指标。有*信念、* *杠杆、*和*集体力量*等指标，但在大多数情况下，熟悉的支持、信心和提升概念将是你所需要的。

如果你从这一部分拿走一件事，就这样吧:计算机科学和机器学习中的许多现代问题可以用几个世纪前的概率论来解决。关联规则学习发展于 20 世纪 90 年代，但其核心概念可以追溯到几百年前。正如我们在[第五章](05.html)、*分类算法*中看到的，我们可以利用概率论开发强大的**机器学习** ( **ML** )算法，而关联规则学习则是磨练你概率论知识的另一个论据。

现在让我们来看看分析事务数据库的挑战，以及关联规则算法可能如何工作。

# 算法视角

我们现在来看更困难的任务，即识别数据库中的频繁项目集。一旦我们知道要为哪些项目集和关联生成规则，计算规则的支持度和置信度就相当容易了。然而，困难在于从成千上万个可能的项目中自动发现包含数百万个事务的数据库中的频繁且有趣的项目集。

想象一下，你的电子商务商店只出售 100 种独特的商品。显然，您的客户可以在一次会话中购买任意数量的商品。假设一个购物者只购买两件商品——您的目录中有 4950 种不同的两种商品组合可供考虑。但你也必须考虑购买三种商品的购物者，其中有 161，700 种组合可供搜索。如果你的产品目录包含 1000 个项目，那么在搜索频繁项目集时，你将不得不考虑多达 1.66 亿个项目的组合。

显然，需要一种更进化的算法来搜索事务数据库中的频繁项目集。请注意，频繁项集搜索只是解决方案的一半；一旦找到频繁项集，仍然必须从中生成关联规则。然而，由于频繁项集的搜索比关联规则的生成困难得多，项集搜索成为大多数算法的重点。

在本节中，我们将描述一种原始的频繁项集搜索算法:Apriori 算法。我们这样做只是为了教育目的；您不太可能需要实现自己版本的 Apriori 算法，因为有更新更快的频繁项集搜索算法可用。然而，我认为研究和理解这些经典算法很重要，尤其是那些处理非常大的搜索空间的算法。大多数搜索非常大的空间的算法都使用某种公理化或启发式的技巧来大幅减少搜索空间，Apriori 也不例外。

Apriori 算法从扫描交易数据库和记录每个单独项目的支持(或频率)开始。这样做的结果是一个物品列表或散列表，比如鸡蛋= 0.6，牛奶= 0.6，洗发水= 0.2。

下一步是找到两个项目的组合，并确定它们在数据库中的支持度(或频率)。这一步的结果类似于`{eggs, milk} = 0.6`、`{eggs, bread} = 0.2`、`{eggs, cheese} = 0.6`、`{eggs, shampoo} = 0.0`等等。暴力彻底搜索方法的问题就从这一步开始。如果您的目录中有 100 个项目，您需要计算 4950 对的支持。如果您的目录中有 1，000 个项目，则必须计算近 500，000 对的支持。我不知道亚马逊([https://www.amazon.com/](https://www.amazon.com/))卖了多少产品(2017 年 1 月的最新报告称 3.68 亿)，但假设他们现在有 4 亿个产品，有 8×10<sup>16</sup>对的商品要考虑(那是 8000 亿对商品)。而那只是*对*的物品。我们还需要查看每三个项目，每四个项目，等等。

Apriori 用来减少搜索空间的聪明技巧是通过最小支持度或最小感兴趣频率来过滤唯一产品列表。例如，如果我们将最小支持度设置为 0.25，我们会发现`{shampoo}`不能进行切割，洗发水永远不能成为我们频繁项目集分析的一部分，因为它的购买频率不够高。

如果洗发水本身的购买频率不足以被认为是频繁的，那么任何一对含有洗发水的物品也会*也*不足以被认为是频繁的。如果洗发水出现在 20%的购买量中，那么`{eggs, shampoo}`对出现的频率必须低于(或等于)20%的购买量。我们不仅可以从搜索中剔除洗发水，还可以从考虑中剔除*任何含有洗发水的*套装。如果洗发水本身很少，我们可以忽略它，那么`{eggs, shampoo}`、`{bread, shampoo}`和`{eggs, bread, shampoo}`也会很少，我们可以忽略它们。这大大减少了我们的搜索空间*。*

 *当我们检查更大的项目组合时，我们可以将这种方法更进一步。在我们的示例中，`{eggs}`的支持率为 60%，`{bread}`的支持率为 40%。如果我们已经将最低支持设置为 25%，这两个项目将分别进行切割，并且应该在我们频繁的数据集分析中加以考虑。但是`{eggs, bread}`的组合支持率只有 20%，可以舍弃。同样，我们能够从二级搜索中排除任何包含`{shampoo}`的组合，现在我们可以从三级搜索中排除任何包含`{eggs, bread}`的组合。因为鸡蛋和面包放在一起很少见，所以任何三种或三种以上同时含有鸡蛋和面包的物品的组合也必须很少见。因此，我们可以从考虑中排除`{eggs, bread, cheese}`、`{eggs, bread, milk}`、`{eggs, bread, shampoo}`等组合，因为它们都包含`eggs`和`bread`的罕见组合。

虽然这种方法大大减少了查找频繁项目集所需的时间，但您应该谨慎使用这种方法，因为它可能会意外跳过有趣但有些罕见的组合。大多数 Apriori 实现将允许您为结果关联规则设置最小支持度和最小置信度。如果将最小支持设置为较高的值，您的搜索将会更快，但您可能会获得更明显或不太有趣的结果；如果您将支持设置得更低，您将面临等待很长时间才能完成搜索的危险。通常，关联规则是在找到频繁项目集后生成的，因此您设置的任何最小置信度都不会对搜索时间产生影响，只有最小支持变量会对搜索时间产生显著影响。

还应该注意的是，对于频繁项集搜索，有更先进、更快速的算法。特别是，我们将在本章的后面实验 FP-Growth 算法。然而，Apriori 算法是理解频繁项集搜索在实践中如何工作的一个很好的起点。

在实现库之前，让我们看一下关联规则可能有帮助的几种情况。

# 关联规则应用

关联规则算法最初的用途是用于菜篮子分析，比如我们在本章中一直使用的杂货店例子。这是关联规则挖掘的一个清晰的应用。市场购物篮分析既可用于实体店，也可用于电商店，一周中不同的日子、季节，甚至特定的罕见事件，如即将到来的音乐会或飓风，都可以维护不同的模型。

事实上，在 2004 年，《纽约时报》(和其他报纸)报道称，沃尔玛使用关联规则挖掘来找出如何在飓风到来之前储备库存。沃尔玛发现，飓风前电梯最高的不是瓶装水或手电筒，而是草莓馅饼。另一个高自信的联想是啤酒。我对啤酒并不太惊讶，但是草莓馅饼是那种你只能从 ML 中获得的洞察力！

假设你在 2004 年是沃尔玛的数据科学家。很容易就能查到不同时期各种产品的单个销售量。草莓馅饼作为一种小商品，可能在飓风期间的相对销量中只显示出非常小的百分比变化。这种数据点你可能会自然而然地忽略掉，因为它微不足道。蛋挞有轻微的隆起，那又怎样？但是如果你去挖掘频繁项目集和关联规则的数据，你可能会发现`{bottled water, batteries} -> {Strawberry Pop-Tarts}`规则出现的时候有着异常强大的信心，在飓风来临前的几天提升了 8.0 左右(提升值非常高)。在飓风季节之外，这种联系可能不存在，或者太弱而无法实现。但是当飓风即将来袭时，草莓馅饼几乎肯定会成为飓风的必需品，这是因为它们的保质期长，能够让儿童和成年人都开心。看到这种联系，你会告诉商店储备草莓馅饼，把它们放在商店的正前方——瓶装水和电池旁边——然后大赚一笔。

虽然这种类型的场景是关联规则的设计目的，但是您可以将频繁项集挖掘和关联规则应用于任何事务性数据库。如果你认为一个网站会话是一个交易，如果你能把所采取的行动(比如登录*、 *wishlisted item* 、*下载的案例分析*)作为你的项目，你就能把同样的算法和关联规则挖掘应用到网站访问者的行为中。您可以开发关联规则，如`{downloaded case study, viewed pricing page} -> {entered credit card}`，来模拟您的访问者行为，并优化您的网站布局和功能，以鼓励您想要的行为。*

请记住，关联规则不仅在积极的时候有价值。当他们消极时，他们也是有价值的。通常，你需要冷静、确凿的事实来改变你对之前所持的一种固执信念的看法。在数据集上执行关联规则挖掘，并且*而不是*看到您期望看到的关联，就像发现意外关联一样强大。看到你直觉上认为是强关联的规则的信心实际上非常低，或者低于你的临界值，可以帮助你放下可能阻碍你或你的产品的过时想法。

关联规则挖掘在许多不同的领域都有应用。是的，关联规则可以用来在飓风之前最大化 Pop-Tarts 利润，但是关联规则也可以用来根据飓风的特征和功率输出来表征飓风本身。尽管关联规则学习是为市场篮子分析而开发的，但它在条件概率方面的基础使其适用于几乎任何可以用项目和交易来表示的统计系统。

例如，考虑一下医学诊断。如果医生的每个诊断都被认为是一个事务，每个医疗条件或环境因素都是一个项目，我们可以应用关联规则挖掘来发现预先存在的条件、环境因素和新诊断之间令人惊讶的关联。你可能会发现`{poor air quality, poor diet} -> {asthma}`规则有很高的可信度或提升度，这可以为研究人员和医生治疗哮喘的方式提供信息，也许可以通过仔细观察饮食来实现。

关联规则可以用于许多其他领域，如遗传学、生物信息学和信息技术安全。因为这些方法可以广泛使用，所以通常很难识别何时应该应用关联规则。一个很好的经验法则是这样的:如果您的数据集包含事务，或者您可以看到自己在为许多事件组合计算条件概率，那么您可能需要考虑关联规则挖掘。

让我们看一下用于关联规则挖掘的几个 JavaScript 库。

# 示例–零售数据

在这个例子中，我们将使用 Apriori 算法来分析零售数据集。首先为此项目创建一个名为`Ch6-Apriori`的新文件夹，并添加以下`package.json`文件:

```js
{
  "name": "Ch6-Apriori",
  "version": "1.0.0",
  "description": "ML in JS Example for Chapter 6 - Association Rules",
  "main": "src/index.js",
  "author": "Burak Kanber",
  "license": "MIT",
  "scripts": {
    "build-web": "browserify src/index.js -o dist/index.js -t [ babelify --presets [ env ] ]",
    "build-cli": "browserify src/index.js --node -o dist/index.js -t [ babelify --presets [ env ] ]",
    "start": "yarn build-cli && node dist/index.js"
  },
  "dependencies": {
    "apriori": "^1.0.7",
    "babel-core": "^6.26.0",
    "babel-plugin-transform-object-rest-spread": "^6.26.0",
    "babel-preset-env": "^1.6.1",
    "babelify": "^8.0.0",
    "browserify": "^15.1.0",
    "node-fpgrowth": "^1.0.0"
  }
}
```

添加`package.json`文件后，从命令行运行`yarn install`安装依赖项。

接下来，创建一个`src`目录，并从本书的 GitHub 资源库`retail-data.json`下载所需的数据文件到文件夹中。

现在向`src`文件夹添加一个`index.js`文件，并添加以下代码:

```js
import receipts from './retail-data.json';
import Apriori  from 'apriori';
import {FPGrowth} from 'node-fpgrowth';

const results = (new Apriori.Algorithm(0.02, 0.9, false))
    .analyze(receipts.slice(0, 1000));

console.log(results.associationRules
    .sort((a, b) => a.confidence > b.confidence ? -1 : 1));
```

前面的代码导入了数据和 Apriori 库。然后，它初始化一个新的 Apriori 求解器，最小支持度为`0.02` (2%)，最小规则置信度为 90%。我们也只分析了数据集中的前 1000 张收据；Apriori 算法本质上有点慢，所以您可能希望在最初实验时限制数据集。

用`yarn start`运行程序，应该会看到类似如下的输出。输出将比我在这里显示的更长；花一分钟探索您自己的控制台输出:

```js
[ a {
 lhs:
 [ 'KNITTED UNION FLAG HOT WATER BOTTLE',
 'RED WOOLLY HOTTIE WHITE HEART.',
 'SET 7 BABUSHKA NESTING BOXES' ],
 rhs: [ 'WHITE HANGING HEART T-LIGHT HOLDER' ],
 confidence: 1 },
 a {
 lhs:
 [ 'RETRO COFFEE MUGS ASSORTED',
 'SAVE THE PLANET MUG',
 'VINTAGE BILLBOARD DRINK ME MUG',
 'WHITE HANGING HEART T-LIGHT HOLDER' ],
 rhs: [ 'KNITTED UNION FLAG HOT WATER BOTTLE' ],
 confidence: 1 },
 a {
 lhs:
 [ 'RETRO COFFEE MUGS ASSORTED',
 'SAVE THE PLANET MUG',
 'VINTAGE BILLBOARD DRINK ME MUG' ],
 rhs: [ 'WHITE HANGING HEART T-LIGHT HOLDER' ],
 confidence: 1 },
```

这些关联规则的置信度均为 1.0，这意味着一笔交易中右侧(标注`rhs`)出现的次数是左侧出现次数的 100%。

再向下滚动查看结果，您可能会发现以下规则:

```js
 a {
 lhs: [ 'HAND WARMER BABUSHKA DESIGN', 'HAND WARMER RED RETROSPOT' ],
 rhs: [ 'HAND WARMER BIRD DESIGN' ],
 confidence: 0.9130434782608696 },
```

这条规则基本上告诉我们，当购物者购买 babushka 和红色 retrospot 设计的暖手宝时，他们有 91%的可能性也购买鸟类设计的暖手宝。你有没有想过，为什么在亚马逊购物时，你经常会看到类似于你刚刚购买或添加到购物车中的商品的建议？这就是为什么——显然，购物者购买相似物品的频率足够高，以至于关联规则通过了它需要通过的各种阈值，尽管事实上*普通*购物者不需要三个不同设计的暖手宝。但迎合普通购物者并不总是目标；你想迎合打算花更多钱的购物者，你可以用统计数据找到那个购物者。

尝试一下 Apriori 设置。如果你降低最低的信心会发生什么？如果增加最低支持会发生什么？

保持最小支持度不变，同时降低最小置信度，应该会得到更多的关联规则结果，而不会对执行时间产生实际影响。大部分执行时间都花在发现频繁项集上，这里的置信度还不是一个定义好的参数；置信度只在编写规则时起作用，不影响单个项目集。

提高最小支持度会加快算法的速度，但是，你会发现你得到的结果没那么有趣。当您提高最低支持时，您会发现规则的左侧变得更简单。以前您会在左侧看到三个和四个项目的规则，现在您将开始看到更简单的左侧项目集，只有一个或两个项目。具有多个项目的项目集自然倾向于具有较低的支持值，因此当您提高最小支持时，您将获得更简单的关联。

另一方面，降低最低支持度将大幅增加执行时间，但也会产生更有趣的结果。请注意，可能会有支持度一般较低但信心非常高的规则；这些规则通常被认为是正确的，但很少出现。当您降低最低支持时，您会发现出现的新规则平均分布在一系列置信度值中。

也可以尝试增加`receipts.slice`的上限。如果保持最小支持参数不变，不仅程序会变得更慢，而且输出中的*规则也会更少。原因是支持值取决于数据集的大小。出现在 1，000 个事务中的 2%的项目集*可能会出现在 2，000 个事务中的 1%中*，这取决于项目的分布。如果你的物品选择非常多，或者你的物品分布是指数衰减的(即*长尾分布*，你会发现当你缩放考虑的物品数量时，你需要缩放最小支持值。*

 *为了证明这一点，我从 0.02 的最小支持度、0.9 的最小置信度和收据变量的 1000 个项目的限制开始。利用这些参数，Apriori 算法找到了 67 条关联规则。当我将限制从 1，000 更新为 2，000 时，算法会找到零个规则。前 1000 个事务中的频繁项集与后 1000 个事务中的项集有很大的不同，当我增加限制时，大多数项集的支持值都降低了。

为了找到更多的结果，我必须减少最低支持。我首先尝试将最低支持设置为 0.01，然而，在等待程序完成两个小时后，我不得不取消这一尝试。我在 0.015 再次尝试。这一次，程序在 70 秒内完成，给了我 12 个结果。在 0.010 到 0.015 之间的某个点上，项目集的数量会急剧增加——事实上，该程序找到了 584 条规则，最低支持度为 0.0125。

项目集的支持只是它在所有事务中的出现频率。我们可以根据频率重新构建与支持相关的一切。如果我们考虑 2000 个事务，0.0125 的支持对应于 25 个事件。换句话说，我刚才生成的 584 条规则的列表只包括在我的 2000 笔交易数据集中至少购买了 25 次的项目。为了为仅购买 5 次或更多次的产品生成规则，我需要设置 0.0025 的最低支持，我非常确定这个值会让我的笔记本电脑着火。

在这里，对比 Apriori 更精细的算法的需求变得显而易见。不幸的是，这个部门仍然缺乏 JavaScript 生态系统。另一种流行的频繁项集挖掘算法 ECLAT 似乎没有任何 JavaScript 实现。

还有另一种频繁项集挖掘算法:FP-Growth 算法。该算法应该能够很容易地处理我们的任务，然而，我们可用的库只进行频繁项集搜索，而不生成关联规则。一旦频繁项集被发现，生成关联规则就容易得多，但是，我将把这个练习留给读者。现在，让我们来看看 FP-Growth 库。

在`index.js`文件中，您可以注释掉与 Apriori 求解器相关的现有行，并添加以下代码:

```js
const fpgrowth = new FPGrowth(0.01);
fpgrowth.exec(receipts)
    .then(result => {
        console.log(result.itemsets);
        console.log("Completed in " + result.executionTime + "ms.");
    });
```

FP-Growth 实现不生成关联规则，因此它所采用的唯一参数是最小支持值。在这个例子中，我们没有截断`receipts`事务数据库，因为算法应该能够处理更大的数据集。整个交易数据库大约有 26，000 条记录，因此`0.01`的最低支持对应于购买`260`次或更多次的产品。

从命令行运行`yarn start`，您应该会看到类似如下的输出:

```js
[ { items: [ 'DECORATIVE WICKER HEART LARGE' ], support: 260 },
 { items: [ 'MINIATURE ANTIQUE ROSE HOOK IVORY' ], support: 260 },
 { items: [ 'PINK HEART SHAPE EGG FRYING PAN' ], support: 260 },
 ... 965 more items ]
 Completed in 14659ms.
```

请注意，支持值是以绝对值给出的，即在数据库中找到项目的次数。虽然这些只是频繁项集，而不是关联规则，但它们仍然有用。如果您看到类似以下的频繁项目集，您可能希望在用户浏览糖碗页面时向他们显示玫瑰茶壶:

```js
{ items: [ 'REGENCY SUGAR BOWL GREEN', 'REGENCY TEAPOT ROSES ' ],
 support: 247 }
```

虽然我认为在 JavaScript 生态系统中的关联规则学习方面还有一些工作要做，但是 Apriori 和 FP-Growth 算法都是可用且有用的。Apriori 实现在大多数实际用例中特别有用，这些用例通常包含更少的事务和更小的项目目录。虽然 FP-Growth 实现不需要生成关联规则，但是仍然有很多事情可以通过查找项目经常出现的集合来完成。

# 摘要

在这一章中，我们讨论了关联规则学习，即在事务数据库中找到频繁项集并通过概率将它们相互关联的方法。我们了解到，关联规则学习是为市场篮子分析而发明的，但在许多领域都有应用，因为基础概率论和事务数据库的概念都广泛适用。

然后，我们深入讨论了关联规则学习的数学原理，并探索了挖掘频繁项集的典型算法:Apriori 算法。在零售数据集上试用我们自己的示例之前，我们研究了关联规则学习的其他可能应用。***