# 三、机器学习算法之旅

在本章中，我们将探索不同的方法来对**机器学习** ( **ML** )可以完成的任务类型进行分类，并对 ML 算法本身进行分类。有许多不同的方式来组织 ML 景观；我们可以根据我们给算法的训练数据的类型对算法进行分类，我们可以根据我们期望从算法中得到的输出类型进行分类，我们可以根据算法的特定方法和策略对算法进行分类，我们可以根据它们所处理的数据的格式对它们进行分类，等等。

当我们在本章中讨论不同类型和类别的 ML 任务和算法时，我们还将介绍您在本书中会遇到的许多算法。本章只讨论算法的高级概念，允许我们在后面的章节中详细讨论。我们将在本章中讨论的主题如下:

*   机器学习导论
*   学习类型—无监督学习、有监督学习和强化学习
*   算法的类别—聚类、分类、回归、降维、优化、自然语言处理和图像处理

在本章的最后，你应该对监督学习和非监督学习有所了解，并且应该理解我们将在本书中应用的算法的整体情况。

# 机器学习导论

总的来说，ML 是我们给让计算机学习而不需要对算法进行明确编程的实践起的名字。相反的做法——也就是用一组可以应用于数据集的指令来编程一个算法——通常被称为**试探法**。这是我们对算法的第一个分类:机器学习和启发式算法。如果您正在管理防火墙，并且手动维护要阻止的 IP 地址范围黑名单，可以说您已经为您的防火墙开发了一种启发式方法。另一方面，如果你开发了一种算法来分析网络流量中的模式，从这些模式中进行推断，并自动维护你的黑名单，可以说你已经开发了一种针对防火墙的 ML 方法。

当然，我们可以进一步细分我们的 ML 防火墙方法。如果你的算法是在没有*先验*知识(事前知识)的情况下设计的，也就是说，如果算法*是从零开始*，那么它可以称为一个**无监督学习**算法。另一方面，如果通过向算法显示来自应该被阻止的源的请求的例子来训练算法，并期望它通过例子来学习，那么该算法可以被称为**监督学习**算法。

您实现的特定算法也可能属于另一个子类。您的算法可能依赖于*聚类*相似的请求，以确定给定请求可能属于哪个聚类，或者您的算法可能使用贝叶斯统计来确定请求应该被*分类为好的或坏的*的概率，或者您的算法可能使用聚类、分类和启发式等技术的组合！像许多其他分类系统一样，在对特殊情况进行分类时经常会出现歧义，但在大多数情况下，算法可以分为不同的类别。

# 学习类型

所有的最大似然算法都将数据作为输入，并期望生成洞察、预测、分类或分析作为输出。一些算法有一个额外的*训练*步骤，在该步骤中，算法在一些数据上被训练，被测试以确保它们已经从训练数据中学习到，并且在未来的某一天给定一个新的数据点或一组数据，您希望对其有所了解。

所有使用训练数据的 ML 算法都期望数据被*标记为*，或者以某种方式标记为该数据的期望结果。例如，在构建垃圾邮件过滤器时，您必须首先教授或训练算法，让其了解垃圾邮件与普通邮件(称为**火腿**)相比是什么样的。您必须首先在大量邮件上训练垃圾邮件过滤器，每封邮件都标有*垃圾邮件*或*火腿*，这样算法才能学会区分这两者。一旦算法被训练好，你就可以给它呈现一条新的、前所未见的消息，并期望它能猜出这条消息是火腿还是垃圾邮件。在这个例子中，你用来训练算法的消息集合叫做**训练数据**或者**训练集合**，使用的标签是*垃圾邮件*和 *ham* ，算法执行的猜测叫做**推理**。这种在一组预先标记的训练数据上训练算法的实践被称为**监督学习**。

其他算法不需要训练，或者可以在没有任何标签的情况下检查数据集，并直接从数据中获得见解。这叫**无监督学习**，这种分类是以数据上缺少标签为标志的。如果你在科学实验室工作，并且正在开发一种图像处理算法来检查培养皿中细菌培养物的图片，该算法的目标是告诉你在照片中可以看到多少不同的细菌菌落，那么你已经开发了一种无监督的学习算法。在这种情况下，您不需要使用预先标记了菌落数量的训练数据来训练算法；该算法有望从头开始寻找数据中的模式和结构。输入和输出类似于监督学习示例，因为您将数据提供给算法并期望接收洞察作为输出，但是这些输入和输出的不同之处在于没有训练步骤或算法所需的 *a* *先验*知识。

还有一些分类属于监督学习和非监督学习的范畴。例如，在*半监督*学习中，算法接收预先标记的训练集，但不是每个标签都由训练数据表示。在这种情况下，该算法被期望在适用的情况下将示例拟合到训练好的标签，但是也期望在适当的时候生成新的标签。

另一种学习模式是**强化学习**。强化学习在各种方面都类似于监督学习和非监督学习。在强化学习中，训练数据没有明确的标签，但算法生成的结果可能与某种惩罚或奖励相关联；该算法的目标是最终优化其结果，以使损失最小化。强化学习经常与监督学习结合使用。一个算法可能最初是在一些标记的训练数据上训练的，但是随后被期望基于关于它已经做出的决定的反馈来更新它的模型。

在很大程度上，你会发现有监督和无监督学习是算法的两个主要类别。

# 无监督学习

在无监督学习中，目标是从数据中推断结构或模式，而不需要对数据进行任何预先标记。因为数据没有标记，所以通常没有办法评估学习算法的准确性，这是与监督学习的主要区别。无监督学习算法通常不被给予任何数据的**先验*知识，除了可能通过给算法本身的调整参数间接给予。*

 *无监督学习通常用于解决一些问题，如果数据只有很少的维度，这些问题可以用肉眼解决，但是数据的大维度使得人类无法或很难进行推断。无监督学习也可以用于人类可以直观解决的低维问题，但是在有大量数据需要处理的地方，手动进行是不合理的。

想象一下，你正在编写一个算法，该算法查看卫星图像数据，任务是识别建筑物并将它们聚集到地理上分开的街区。如果你只有一张图片，或者几张图片，这很容易用手完成。研究人员会在一张照片上标记所有的建筑，并对照片进行视觉检查，以确定建筑群。然后，研究人员记录下邻居中心的纬度和经度，并将结果放入电子表格中。首席科学家说，太好了，只剩下 300 万张图片了！这是一个低维问题的例子(只有两个维度，*纬度*和*经度*，可以考虑)，这个问题由于任务量的巨大而变得难以置信。显然需要一个更复杂的解决方案。

为了开发一种无监督的学习方法来解决这个问题，研究人员可以将问题分为两个阶段:**预处理**和**分析**。在预处理步骤中，应该通过一种算法来运行每幅图像，该算法检测照片中的建筑物并返回它们的纬度/经度坐标。这个预处理步骤可以通过几种方式进行管理:一种方法是将图像发送给一组实习生进行手动标记；另一种方法可以是寻找矩形形状的非机器学习边缘检测算法；第三种方法是 T4 卷积神经网络，它被训练来识别建筑物的图像。

一旦预处理完成，并且手头有一个建筑物坐标列表，就可以通过无监督聚类算法来运行坐标，例如 k-means 算法，我们将在后面探讨。无监督算法不需要知道*建筑物*是什么，不需要知道任何现有的邻域或建筑物簇，也不需要任何其他*先验的*问题知识。该算法能够简单地读取数百万或数十亿个纬度/经度坐标的列表，并将它们分组到以地理为中心的集群中。

由于无监督算法无法判断其结果的准确性，因此无法保证该算法会生成与人口普查数据相匹配的邻域，也无法保证算法的*邻域*概念在语义上是正确的。例如，如果一条宽阔的公路将一个城镇或社区分成两半，那么这个城镇或社区就有可能被视为两个独立的社区。如果两个社区之间没有明确的分离，算法也有可能将居民认为不同的两个社区合并成一个集群。

在许多情况下，这种类型的语义错误是可以接受的；这种解决问题的方法的好处是，它可以快速处理数百万或数十亿个数据点，并且至少提供了一种逻辑意义上的聚类。无监督聚类的结果可以进一步进行后处理，或者通过另一种算法，或者手工检查，以向结果添加语义信息。

无监督算法还可以在高维数据集中找到人类无法直观可视化的模式。在建筑物聚类问题中，研究人员很容易直观地查看二维地图并通过眼睛识别聚类。现在假设您有一组数据点，每个数据点都存在于一个 100 维的空间中(也就是说，数据有 100 个不同的特征)。如果你拥有的数据量不是微不足道的，例如，超过 100 或 1000 个数据点，人类几乎不可能解释数据，因为特征之间的关系在 100 维空间中太难可视化了。

作为前面问题的一个人为例子，假设你是一名心理学家，你的任务是解释给参与者的一千个调查，这些调查问了 100 个不同的问题，每个问题的等级为 1-10。每个问题都是为了评价参与者性格的不同方面而设计的。你解释这些数据的目的是确定被调查者代表了多少不同的人格类型。

手工只处理 1000 个数据点当然是可以实现的，也是很多领域的通用做法。然而，在这种情况下，数据的高维数使得发现模式非常困难。两位受访者可能回答了一些非常相似的问题，但回答其他问题的方式不同；这两位受访者是否足够相似，可以被认为是同一种性格类型？那种性格类型和其他性格类型有多相似呢？我们以前用于检测建筑物集群的相同算法可以应用于这个问题，以便检测回答者集群及其性格类型(我向阅读这篇文章的任何实际心理学家道歉；我知道我把问题过分简单化了！).

在这种情况下，无监督聚类算法对涉及的 100 个维度进行*可视化*没有任何困难，并且将执行与二维邻域聚类问题类似的操作。同样的警告也适用:不能保证算法检测到的聚类在心理上是正确的，也不能保证问题本身被正确设计来恰当地捕捉所有不同的人格类型。该算法唯一的承诺是它将识别相似数据点的集群。

在[第 2 章](02.html)、*数据探索、*中，我们讨论了在将数据交给 ML 算法之前对其进行预处理的重要性。我们现在开始理解后处理和解释结果的重要性，尤其是在研究无监督算法时。由于无监督算法只能判断它们的整体统计分布(即本例中任意点到其聚类中心的平均距离)，而不能判断它们的语义错误(即有多少数据点实际上是**正确的**)，因此算法不能对其语义正确性做出任何断言。查看均方根误差或标准偏差等指标可能会提示您算法如何执行，但这不能用作对算法准确性的判断，只能用于描述数据集的统计属性。查看这些指标不会告诉你结果是否正确，只会告诉你数据有多聚类或不聚类(一些邻域稀疏，其他邻域密集，等等)。

到目前为止，我们已经在聚类算法的背景下考虑了无监督学习，这确实是无监督学习算法的一个主要家族，但是也有许多其他的。例如，我们在[第 2 章](02.html)、*数据探索*中对离群点检测的讨论属于无监督学习的范畴；我们正在寻找没有先验知识的无标签数据，并试图从这些数据中收集见解。

另一个流行的无监督学习技术的例子是**主成分分析** ( **主成分分析**，我们在[第二章](02.html)、*数据探索*中简单介绍过。主成分分析是一种无监督学习算法，常用于预处理过程中的特征检测和降维，该算法适合解释高维数据的用例。与聚类算法不同，聚类算法旨在告诉您数据集中存在多少数据点的逻辑聚类，而主成分分析旨在告诉您数据集的哪些特征或维度可以巧妙地组合成具有统计意义的派生特征。从某种意义上说，主成分分析可以被认为是特征或维度的聚类，而不是数据点的聚类。

像主成分分析这样的算法不一定需要专门用于预处理，实际上可以用作您想要从中获得洞察力的主要最大似然算法。

让我们回到心理调查的例子。我们可能希望用主成分分析来分析问题本身，而不是将调查受访者聚集在一起。算法的结果会告诉你哪些调查问题彼此之间的相关性最大，这种洞察力可以帮助你重写实际的调查问题，以便它们更好地针对你希望研究的个性特征。此外，主成分分析提供的降维可以帮助研究人员可视化问题、受访者和结果之间的关系。该算法将把你无法可视化的 100 维、高度互联的特征空间转换成清晰的、更低维的空间，这些空间实际上可以被图形化和可视化。

与所有无监督学习算法一样，不能保证主成分算法在语义上是正确的，只能保证算法能够统计地确定特征之间的关系。这意味着一些结果可能看起来荒谬或不直观；该算法可能会组合一些在组合时似乎没有直观意义的问题。在这种情况下，由研究人员对分析结果进行后处理和解释，可能会修改问题或改变他们在下一轮调查中的方法。

还有许多其他无监督学习算法的例子，包括自动编码器神经网络，我们将在后面的章节中讨论。无监督学习算法最重要的特征是其输入数据中缺少标签，这导致无法确定其结果的语义正确性。然而，不要错误地认为无监督学习算法的*比其他算法的*小，因为它们在数据预处理和许多其他类型的数据探索任务中非常重要。正如扳手和螺丝刀一样，在 ML 的世界里，每个工具都有它的位置和用途。

# 监督学习

像无监督学习一样，有监督学习算法的目标是解释输入数据并生成见解作为其输出。与无监督学习不同，有监督学习算法首先在有标签的训练示例上进行训练。算法使用训练示例来构建*模型*，或者数据属性与其标签之间关系的内部表示，然后将该模型应用于您希望从中获得洞察力的新的、未标记的数据点。

监督学习对 ML 学生来说通常更令人兴奋，因为这类算法旨在提供语义正确的结果。当一个有监督的学习算法运行良好时，结果看起来几乎是神奇的！您可以在 1000 个预先标记的数据点上训练算法，然后使用该模型处理数百万个未来的数据点，并对结果的语义准确性有所预期。

因为监督学习算法的目标是语义正确，我们必须首先讨论如何衡量这种正确性。首先，我们必须介绍*真阳性*、*假阳性*、*真阴性*、*假阴性*的概念，然后我们将介绍准确度、精密度和召回率的概念。

# 计量精度

假设你正在为你的博客开发的评论系统开发一个垃圾邮件过滤器。垃圾邮件过滤器是一种有监督的学习算法，因为算法必须首先被告知什么构成垃圾邮件与 ham。你训练你的垃圾邮件系统在许多火腿和垃圾邮件的例子，然后发布到生产，并允许它分类所有新的评论，自动阻止垃圾邮件，让真正的火腿消息通过。

让我们将*肯定的*看作是算法识别为垃圾邮件的评论(我们称之为*肯定的*，因为我们称该算法为垃圾邮件过滤器；这只是一个语义上的区别，因为我们可以将过滤器称为一个*火腿过滤器*，而代之以使用*肯定的*来表示可疑的火腿消息。让我们将*否定*视为被识别为真实(火腿)评论的评论。

如果您的算法将评论归类为垃圾邮件(肯定的)，并且语义正确(也就是说，当您阅读邮件时，您也确定它是垃圾邮件)，则该算法生成了一个*真肯定*，或者一个确实正确的肯定结果。另一方面，如果真正的评论被错误地识别为垃圾邮件并被阻止，这被认为是*假阳性*，或者实际上不是阳性的阳性结果。类似地，被识别为火腿的真火腿消息是*真阴性*，被识别为火腿并被允许通过的垃圾评论被认为是*假阴性*。期望一个算法能提供 100%正确的结果是不合理的，所以在实践中总会有一定量的误报和漏报。

如果我们将结果准确性分为四个分类，我们可以计算每个分类的实例数量，并为每个分类确定一个比率:我们可以轻松计算假阳性率、真阳性率、假阴性率和真阴性率。然而，如果我们单独对待这四个比率，讨论起来可能会很笨拙，因此我们也可以将这些比率合并到其他类别中。

例如，算法的*回忆*或*敏感度*是其真实阳性率，或阳性分类为真实阳性的次数百分比。在我们的垃圾邮件示例中，召回指的是从所有实际垃圾邮件中正确识别出的垃圾邮件的百分比。这可以计算为*真阳性除以实际阳性*，或者*真阳性除以真阳性加上假阴性*(回想一下，假阴性是实际上是垃圾邮件的评论，但被错误地识别为 ham)。回想一下，在这种情况下，指的是算法正确检测一条垃圾评论的能力，或者简单地说，*在所有实际存在的垃圾消息中，我们识别出了多少条？*

特异性类似于召回，除了它代表算法的真实阴性率。特异性问问题*在所有真实的火腿信息中，我们正确识别了多少？*

另一方面，精度定义为真阳性数除以真阳性和假阳性之和。就我们的垃圾邮件示例而言，precision 回答了问题*在所有我们认为是垃圾邮件的邮件中，我们得到了多少正确的猜测？*这两个指标的区别在于我们是考虑所有*实际的*垃圾邮件，还是考虑我们*认为*是垃圾邮件的邮件。

准确性不同于精确性和召回率，它关注的是整体正确的结果。它被定义为真阳性和真阴性的比率除以试验总数(也就是说，总体上有多少猜测是正确的)。ML 的学生经常犯的一个常见错误是只关注准确性，因为直观上更容易理解，但在评估一个算法的性能时，准确性往往不够。

为了证明这一点，我们必须考虑垃圾邮件过滤器的性能对现实结果的影响。在某些情况下，您希望垃圾邮件过滤器永远不会让一封垃圾邮件通过，即使这意味着错误地阻止了一些 ham 邮件。在其他情况下，最好确保所有的 ham 消息都被允许，即使有一些垃圾邮件躲过了您的过滤器。两个不同的垃圾邮件过滤器有可能具有完全相同的*精确度*、*T3】，但是精确度和召回率的特征完全不同。因此，准确性(虽然非常有用)并不总是您考虑的唯一性能指标。*

因为之前的数学定义可能有点难以内化，我们就把数字放到例子中。考虑 100 条消息，其中 70 条是真正的火腿，30 条是真正的垃圾邮件:

|  | **30** 实际垃圾邮件(阳性) | **70** 实际火腿(阴性) |
| **26** 猜到垃圾邮件 | 22(真阳性) | 4(假阳性) |
| **74** 猜火腿 | 8(假阴性) | 66(真阴性) |

为了计算算法的准确性，我们将正确的猜测相加:`22`真阳性和`66`真阴性，总共等于 88 个正确的猜测。因此，我们的准确率为 88%。

As an aside: 88% accuracy would be considered very good for advanced algorithms on difficult problems, but a little poor for a spam filter.

算法的召回率或敏感度就是*真阳性率*，或者说我们在看实际上是*垃圾邮件的例子时猜对的次数。这意味着我们只考虑前面表格中的左边一列。算法的召回率是实际阳性中的真阳性数，即真阳性数除以真阳性加上假阴性。在这种情况下，我们有 22 个真阳性和 30 个实际垃圾邮件，因此我们的算法的召回率是 22/30，即 73%。*

算法的精确度与*实际上是*垃圾邮件的消息无关，而是与我们*猜测*是垃圾邮件的消息有关。在这种情况下，我们只考虑顶行，或者真阳性除以真阳性和假阳性之和；也就是说，真阳性除以猜测阳性。在我们的例子中，有 22 个真阳性和 26 个总猜测阳性，因此我们的精度是 22/26，即 84%。

请注意，该算法比敏感算法更精确。这意味着当它猜测垃圾邮件时，它的垃圾邮件猜测是 84%正确*，但算法也有倾向于猜测火腿，错过了大量实际的垃圾邮件。还要注意的是，总准确率为 88%，但它的准确率和召回率都低于这个数字。*

直观地思考这些性能指标的另一种方式如下:精度是算法在猜测肯定时正确猜测的能力，但召回率是算法记住垃圾邮件是什么样子的能力。高精度和低召回率意味着算法在猜测邮件是垃圾邮件时非常有选择性；算法确实需要确信邮件是垃圾邮件，然后才能将其识别为垃圾邮件。

The algorithm is very *precise* about saying that a message is spam.

因此，它可能倾向于让 ham 消息通过，代价是意外地让一些垃圾邮件通过。另一方面，低精度、高召回率的算法会更积极地将邮件识别为垃圾邮件，然而，它也会错误地阻止大量 ham 邮件(该算法更好地*回忆*垃圾邮件的样子，它对垃圾邮件更*敏感*，因此它认为更多的邮件是垃圾邮件，并将相应地采取行动)。

当然，有些算法可以有很高的精度、精确度和召回率——但更现实的是，您训练算法的方式将涉及精度和召回率之间的权衡，您必须根据系统的预期目标来平衡这些权衡。

# 监督学习算法

既然我们已经了解了准确性、精确度和召回率，我们就可以继续手头的主题:监督学习算法。有监督和无监督学习算法之间的关键区别是存在预先标记的数据，通常是在算法的训练阶段引入的。监督学习算法应该能够从标记的训练数据中学习，然后分析新的、未标记的数据点，并猜测该数据的标签。

监督学习算法进一步分为两个子类别:**分类**和**回归**。如前所述，分类算法的目标是基于从训练数据中学习到的广义模式来预测看不见的数据点的标签。回归算法的目的是预测一个新点的值，同样是基于它在训练中学习的广义模式。虽然分类和回归在实践中感觉不同，但前面的描述暴露了这两个类别实际上有多相似；两者之间的主要区别是回归算法通常使用连续数据，例如时间序列或坐标数据。然而，在本节的其余部分，我们将只讨论分类任务。

因为该算法从标记数据构建模型，所以期望该算法能够生成语义上*正确的结果，而非无监督算法生成的统计上*正确的结果。语义正确的结果是经得起外部审查的结果，使用与标记训练数据相同的技术。在垃圾邮件过滤器中，语义正确的结果是算法做出的人类会同意的猜测。**

 **预标记的训练数据能够产生语义正确的结果。训练数据本身代表了问题的语义，是算法如何学习生成语义正确的结果。请注意，整个讨论——以及关于准确性、精确性和召回率的整个讨论——取决于将外部验证的信息引入模型的能力。只有当外部实体独立验证结果时，您才能知道单个猜测是否正确，并且只有当外部实体提供了足够多的带有正确标签的数据点来训练算法时，您才能教算法做出语义正确的猜测。您可以将监督学习算法的训练数据视为所有猜测的真实来源。

虽然当监督学习算法运行良好时，它们看起来确实像魔法一样，但也有许多潜在的陷阱。因为训练数据对算法至关重要，所以你的结果只会和你的训练数据和训练方法一样好。训练数据中的一些噪声通常是可以容忍的，但是如果训练数据中有系统误差的来源，那么你的结果中也会有系统误差。这些可能很难检测到，因为模型的验证通常使用您留出的训练数据的子集——具有系统错误的相同数据用于验证模型，因此您会认为模型运行良好！

另一个潜在的陷阱是没有足够的训练数据。如果你正在解决的问题是高维的，你将需要相应的大量训练数据；训练数据必须足以向机器学习算法实际呈现所有各种模式。你不会指望只在 10 封邮件上训练一个垃圾邮件过滤器，但也期待很好的结果。

这些因素通常会给监督学习带来一种启动成本。需要在采购或生成适当数量的培训范例以及分发培训范例方面进行一定的投资。训练数据通常(尽管不总是)需要由人类知识和评估生成。这可能是昂贵的，尤其是在图像处理和对象检测的情况下，这通常需要许多标记的训练示例。在一个 ML 算法变得越来越容易访问的世界里，真正的竞争在于拥有最好的数据。

就我们的垃圾邮件过滤器而言，对训练数据的需求意味着您不能简单地编写和启动垃圾邮件过滤器。您还需要花一些时间手动记录哪些电子邮件是垃圾邮件和垃圾邮件(或者让您的用户报告这一点)。在部署您的垃圾邮件过滤器之前，您应该确保您有足够的训练数据来训练和验证算法，这可能意味着您必须等到有数百或数千个由人类标记的垃圾邮件的例子。

假设你有适量的高质量训练数据，也有可能对训练过程管理不当，用好的数据造成不好的结果。ML 新手通常认为训练越多绝对越好，但事实并非如此。

这里引入两个新概念:**偏差**和**方差**。训练 ML 模型时，希望模型学习训练数据的*通用*属性，并能从那里进行外推。如果一个算法对数据的结构做出了明显不正确的假设，可以说它是高度偏差的，因此*欠配*。另一方面，模型可以表现出高方差，或者对训练数据中的小差异的高敏感性。这叫做**过拟合**，可以认为是识别单个例子的算法学习，或者是单个例子中的具体噪声，而不是数据的总趋势。

过度训练的模型很容易导致过度训练。想象一下，你 10 年来每天都在使用同一个键盘，但键盘实际上是一个奇怪的模型，布局奇怪，有很多怪癖。可以预料，这么长时间后，你会变得非常擅长在这样的键盘上打字。然后，出乎意料的是，键盘坏了，你得到了一个新的标准键盘，却发现你不知道如何在上面打字！你训练了十几年打字的肌肉记忆习惯了句号是*就这样*，字母 *o* 向右移一点，等等。使用新键盘时，你会发现没有错别字就打不出一个字。十年来在一个糟糕的键盘上过度训练，只教会了你如何在那个键盘上输入*，而你还不能将你的技能推广到其他键盘。过拟合一个模型是同一个概念:你的算法非常擅长识别你的训练数据*而不是别的。**

 *因此，训练模型并不像插入训练数据和让算法训练任意时间那么简单。这个过程中的一个关键步骤是将您的训练数据分成两部分:一部分用于训练算法，另一部分仅使用*来验证模型的结果。您不应该在您的验证数据上训练算法，因为您有风险在如何识别您的验证数据上训练模型，而不是训练它，然后使用验证数据来独立验证您的算法的准确性。对验证集的需求增加了生成训练数据的成本。如果您确定需要 1，000 个示例来训练您的算法，那么您可能实际上总共需要生成 1，500 个示例，以便有一个合理的验证集。*

 *验证数据不仅仅是用来测试算法的整体准确性。您还经常使用验证数据来确定何时*停止*训练。在训练过程中，您应该用验证数据定期测试算法。随着时间的推移，你会发现验证的准确性会像预期的那样提高，然后在某个点上，验证的准确性实际上可能会*降低。*这个方向的改变是你的模型开始过度拟合你的训练数据的点。当你用训练集中的一个例子(这些是它直接学习的例子)展示它时，算法总是会继续变得更精确，但是一旦模型开始过度训练训练数据，它将开始失去归纳的能力，从而用它没有训练过的数据表现得更差——而不是更好。因此，维护一组独立的验证数据至关重要。如果你曾经训练过一个算法，并且它在测试自己的训练数据时有 100%的准确性，那么很可能你已经过度训练了数据，并且它可能在看不见的数据上表现很差。该算法已经不再学习数据的一般趋势，而是开始记忆具体的例子，包括数据中的各种噪声。

除了维护一个验证集，对数据进行适当的预处理也可以防止过度拟合。我们在[第 2 章](02.html) *【数据探索】*中讨论的各种降噪、特征选择、特征提取和降维技术都有助于概括您的模型并避免过度拟合。

最后，因为你的算法推理的语义正确性只能由外部来源决定，所以通常不可能知道一个猜测是否真的是正确的(除非你收到用户对一个特定猜测的反馈)。充其量，您只能从您在训练和验证阶段计算的精度、召回率和准确度值中推断出算法的整体有效性。幸运的是，许多监督学习算法以概率的方式呈现它们的结果(例如，*我认为有 92%的概率这是垃圾邮件*)，因此您可以对算法在一个推理中的置信度有一些指示，但是，当您将这个置信度与模型的精度和召回率以及您的训练数据可能有系统错误的事实相结合时，即使伴随推理而来的置信度也是值得怀疑的。

尽管有这些潜在的陷阱，监督学习是一种非常强大的技术。仅从复杂问题领域的几千个训练示例中进行推断，并在数百万个看不见的数据点上快速做出推断的能力令人印象深刻，并且极具价值。

与无监督学习一样，有监督学习算法有多种类型，每种都有自己的优缺点。神经网络、贝叶斯分类器、k 近邻、决策树和随机森林都是监督学习技术的例子。

# 强化学习

虽然有监督和无监督学习是机器学习算法的两个主要子类，但它们实际上是一个光谱的一部分，还有其他学习模式。在本书的上下文中，下一个最重要的学习模式是强化学习，在某些方面，它可以被认为是有监督和无监督学习的混合；然而，大多数人会将强化学习归类为无监督学习算法。这是分类变得有点模糊的情况之一！

在无监督学习中，对要处理的数据几乎一无所知，算法必须从空白的石板中推断模式。在监督学习中，大量资源专用于在已知示例上训练算法。在强化学习中，*关于数据的一些东西*是已知的(或者可以是已知的)，但是数据的知识不是一个显式的标注或者一个分类。取而代之的是，*已知的(或可以知道的)事物*是基于对数据所做的决定而采取的行动的结果。强化学习被很多人认为是一种无监督的学习算法，因为算法*从零开始*，然而强化也*闭合回路*并基于自身的动作不断地重新训练自己，这与有监督学习中的训练有一些相似之处。

举一个荒谬而做作的例子，假设你正在编写一个算法，该算法本应取代政府的职能。该算法将接收国家当前事务的状态作为其输入，并且作为输出，必须开发新的政策和法律，以便在多个维度上优化国家:公民幸福、经济健康、低犯罪率等等。对这个问题的强化学习方法是从零开始的，不知道它的法律和政策将如何影响这个国家。然后，算法实现一个定律或一组定律；因为它刚刚开始，它实施的法律将是完全武断的。法律经过一段时间生效并对社会产生影响后，算法会再次读取国家的事态，可能会发现它把国家变成了一片混乱的荒地。算法从这个反馈中学习，自我调整，并实现一套新的法则。随着时间的推移，并使用它实现的初始定律作为实验，该算法将开始理解其策略的因果并开始优化。如果有足够的时间，这种方法可能会发展出一个近乎完美的社会——如果它没有意外地用最初失败的实验摧毁这个社会的话。

强化学习技术不同于有监督和无监督的算法，因为它们直接与环境交互，并监控决策的效果，以便更新模型。大多数强化学习的目的不是检测模式或对数据进行分类，而是优化环境中的一些成本或回报。所讨论的环境可以是真实世界的环境，这在控制系统领域中是常见的情况，也可以是虚拟环境，这与遗传算法的情况相同。无论是哪种情况，算法都必须有某种方式来表征总体*成本* / *惩罚*或*奖励*，并将努力优化该值。强化学习是一种重要的优化技术，尤其是在高维问题空间中，因为暴力试错法通常不可能在合理的时间内实现。

强化学习算法的例子包括遗传算法，我们将在后面的章节中深入讨论，蒙特卡罗方法和梯度下降(我们将与神经网络一起讨论)。

# 算法的类别

我们已经根据 ML 算法的学习模式对它们进行了分类，但这不是对算法进行分类的唯一方法。另一种方法是根据任务或功能对它们进行分类。在本节中，我们将简要介绍最大似然算法的基本功能，并给出一些示例算法。

# 使聚集

聚类算法旨在识别彼此相似的数据点组。*类似*的定义取决于数据类型、问题域和使用的算法。直观理解聚类算法最简单的方法是可视化 *x/y* 网格上的点。聚类算法的目标通常是围绕一组相似的点画圆；每组圆圈点被视为一个簇。聚类通常是事先不知道的，因此聚类算法通常被归类为无监督学习问题。

聚类算法的一些例子包括:

*   k 均值，以及诸如 k 中值的变体
*   高斯混合模型
*   均值漂移

# 分类

分类是监督学习算法的一个非常广泛(并且非常流行)的类别，目标是试图将数据点识别为属于某个分类(垃圾邮件或 ham 男性或女性；动物、矿物或植物等)。存在多种分类算法，包括:

*   k 近邻
*   逻辑回归
*   朴素贝叶斯分类器
*   支持向量机
*   (大多数)神经网络
*   决策树
*   随机森林

# 回归

回归算法旨在确定和表征变量之间的关系。在最简单的二维线性回归情况下，算法的目标是通过一组点来确定最接近的直线，然而，更高程度和更高维度的回归可以产生重要的见解，并对复杂数据进行预测。因为这些算法必然需要已知的数据点，所以被认为是监督学习算法。一些例子:

*   线性回归
*   多项式回归
*   贝叶斯线性回归
*   最小绝对偏差

# 降维

降维是一系列技术，其目的是将具有高维数的数据转换成具有低维数的数据。作为一个通用术语，这可能意味着要么完全丢弃维度(如特征选择)，要么创建同时表示多个原始维度的新的单个维度，但会损失一些分辨率(如特征提取)。

一些可用于降维的算法包括:

*   各种回归
*   污染控制局(Pollution Control Agency)
*   图像转换(例如，将图像转换为灰度)
*   词干和引理化(在自然语言处理中)

# 最佳化

优化算法的目标是选择一组参数或一组参数的值，使得系统的成本或误差最小化(或者，使得系统的回报最大化)。特征选择和特征提取实际上是一种优化形式；您修改参数的目的是在保留重要数据的同时降低维数。在最基本的优化技术，即强力搜索中，您只需尝试所有可能的参数组合，并选择具有最佳结果的组合。实际上，大多数问题都足够复杂，以至于强力搜索可能需要不合理的时间(也就是说，在现代计算机上需要数百万年)。一些优化技术包括:

*   强力搜索(也称为*彻底搜索*)
*   梯度下降
*   模拟退火
*   遗传算法

# 自然语言处理

**自然语言处理** ( **NLP** )本身就是一个完整的领域，包含了很多机器学习中没有考虑到的技术。然而，自然语言处理经常与最大似然算法一起使用，因为这两个领域的结合是实现广义人工智能所必需的。许多 ML 分类算法是对文本而不是数字进行操作的(比如我们的垃圾邮件过滤器)，在这些情况下，我们依赖于自然语言处理领域的技术:特别是词干是一种快速简单的文本分类器降维技术。一些与 ML 相关的自然语言处理技术包括:

*   标记化
*   字符串距离
*   词干或引理化
*   TF-以色列国防军

# 图像处理

像自然语言处理一样，图像处理是它自己的研究领域，与最大似然法重叠，但没有被最大似然法完全涵盖。与自然语言处理一样，在对图像应用最大似然算法之前，我们可能经常使用图像处理技术来降维。一些与机器学习相关的图像处理技术包括:

*   边缘检测
*   尺度不变变换
*   色彩空间转换
*   目标检测
*   递归神经网络

# 摘要

在这一章中，我们讨论了对机器学习技术进行分类的各种方法。特别是，我们讨论了无监督学习、有监督学习和强化学习之间的区别，并给出了每种学习的不同示例。

我们还讨论了判断机器学习算法准确性的不同方法，特别是适用于监督学习技术的准确性、精确性和召回率的概念。我们还讨论了训练步骤在监督学习算法中的重要性，并说明了偏差、方差、泛化和过拟合的概念。

最后，我们研究了机器学习算法如何分类，不是通过学习模式，而是通过任务或技术，并提出了一些算法，适合聚类，分类，回归，降维，自然语言处理和图像处理的类别。

在下一章中，我们将开始深入研究聚类算法。*****