<html><head/><body>
<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Implementing a Jokes Recommendation Engine</title>
    <meta content="urn:uuid:715f2a86-adaf-48a1-98a4-3c219c63f667" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">实现笑话推荐引擎</h1>
                
            
            
                
<p class="mce-root">我相信你也经历过这种事情:在亚马逊上购买手机时，你也会看到一些手机配件的产品推荐，如屏幕保护罩和手机壳。不足为奇的是，我们中的大多数人最终都会购买这些推荐中的一个或多个！电子商务网站中推荐引擎的主要目的是吸引买家从供应商那里购买更多的东西。当然，这与销售人员试图在实体店向客户追加销售或交叉销售没有什么不同。</p>
<p class="mce-root">你可能还记得买了这个商品的顾客也在亚马逊(或任何电子商务网站)上买了这个标题，那里有推荐。这些建议的目的是让你不仅仅购买一种产品，而是购买一种组合产品，从而推动销售收入上升。亚马逊上的推荐是如此成功，以至于麦肯锡估计亚马逊上35%的总销售额来自他们的推荐！</p>
<p class="mce-root">在这一章中，我们将学习推荐引擎的理论和实现，它向用户推荐笑话。为了做到这一点，我们使用了r的<kbd class="calibre11">recommenderlab</kbd>库中可用的Jester的笑话数据集。</p>
<ul class="calibre9">
<li class="calibre10">推荐引擎的基本方面</li>
<li class="calibre10">理解笑话推荐问题和数据集</li>
<li class="calibre10">使用基于项目的协同过滤技术的推荐系统</li>
<li class="calibre10">使用基于用户的协同过滤技术的推荐系统</li>
<li class="calibre10">使用关联规则挖掘技术的推荐系统</li>
<li class="calibre10">基于内容的推荐引擎</li>
<li class="calibre10">笑话推荐的混合推荐系统</li>
</ul>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Fundamental aspects of recommendation engines</title>
    <meta content="urn:uuid:715f2a86-adaf-48a1-98a4-3c219c63f667" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">推荐引擎的基本方面</h1>
                
            
            
                
<p class="mce-root">虽然展示推荐的基本目的是推动销售，但它们实际上不仅仅是更好的销售概念。高度个性化的内容是推荐引擎能够提供的。这实质上意味着亚马逊等零售平台上的推荐引擎能够通过正确的渠道在正确的时间向正确的客户提供正确的内容。提供个性化内容是有意义的；毕竟，向客户展示不相关的产品是没有意义的。此外，随着客户注意力的降低，企业希望能够通过展示合适的产品并鼓励他们购买合适的产品来最大限度地增加销售机会。在非常高的水平上，个性化内容推荐在AI中以几种方式实现:</p>
<ul class="calibre9">
<li class="calibre10"><strong class="calibre1">映射一起购买的类似商品</strong> : <strong class="calibre1"> </strong>让我们举一个网购者在某购物网站上搜索书包的例子。很有可能，购物者在购买书包时会对购买额外的学校相关物品感兴趣。因此，将书包与笔记本、铅笔、钢笔和铅笔盒放在一起展示，有助于增加销售。</li>
<li class="calibre10"><strong class="calibre1">基于客户人口统计数据的推荐</strong> : <strong class="calibre1"> </strong>向保守的中产阶级客户推荐高端手机和时尚的手机配件，他们通常会寻求便宜的交易，这可能不会使推荐产品的销量大幅上升。相反，这些客户可能会觉得这些不相关的推荐很烦人，从而影响他们的忠诚度。</li>
<li class="calibre10"><strong class="calibre1">基于客户相似性的推荐</strong> : <strong class="calibre1"> </strong>向客户推荐产品是基于其他相似客户购买或喜欢的产品。例如，向生活在城市地区的年轻女性推荐新上市的化妆品。在这种情况下，推荐不仅仅是因为客户的属性，还因为类似类型的其他客户已经购买了该产品。随着该商品在相似个体中受欢迎程度的增加，该商品被选为推荐商品。</li>
<li class="calibre10"><strong class="calibre1">基于产品相似性的推荐</strong> : <strong class="calibre1"> </strong>如果您搜索某个特定品牌的笔记本电脑背包，在搜索结果的同时，还会显示其他品牌的笔记本电脑背包作为推荐。这一建议纯粹是基于产品之间的相似性。</li>
</ul>
<ul class="calibre9">
<li class="calibre10"><strong class="calibre1">基于顾客的历史购买简档的推荐</strong> : <strong class="calibre1"> </strong>如果顾客总是购买特定品牌的牛仔裤，则向他们显示他们倾向于购买的特定品牌的较新品种的牛仔裤的推荐。这些建议纯粹基于客户的历史购买记录。</li>
<li class="calibre10"><strong class="calibre1">混合推荐</strong> : <strong class="calibre1"> </strong>可以将一种或多种推荐方法结合起来，为客户提供最佳推荐。例如，可以通过使用从历史数据以及从客户的人口统计信息推断的客户偏好来获得推荐列表。</li>
</ul>
<p class="mce-root">回购活动、时事通讯推荐、废弃购物车的重新绑定、定制折扣和优惠以及电子商务网站的平滑浏览体验是在线零售业中推荐系统的一些应用。</p>
<p class="mce-root">由于几个普遍的使用案例，推荐系统似乎只用于电子商务行业。然而，事实并非如此。以下是推荐系统在非电子商务领域的一些使用案例:</p>
<ul class="calibre9">
<li class="calibre10">在制药工业中，推荐系统被用于识别具有某些特征的药物患者，这些患者将对这些药物做出更好的反应</li>
<li class="calibre10">股票推荐是根据一群成功人士的选股结果进行的</li>
<li class="calibre10">YouTube和在线媒体使用推荐引擎来提供与用户当前正在观看的内容相似的内容</li>
<li class="calibre10">旅游推荐是基于用户或类似用户参观过的旅游景点</li>
<li class="calibre10">识别未来员工在各种角色中的技能和个性特征</li>
<li class="calibre10">在烹饪科学中，可以通过推荐系统的应用来探索搭配在一起的菜肴</li>
</ul>
<p class="mce-root">鉴于推荐系统的用例几乎存在于每个领域，这个列表可能会变得非常庞大。</p>
<p class="mce-root">既然我们已经对推荐系统的概念及其对商业的价值有了基本的理解，我们现在可以进入下一部分，在这里我们试图理解Jester的笑话推荐数据集以及可以通过构建推荐引擎来解决的问题。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Recommendation engine categories</title>
    <meta content="urn:uuid:715f2a86-adaf-48a1-98a4-3c219c63f667" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">推荐引擎类别</h1>
                
            
            
                
<p class="mce-root">在实现我们的第一个推荐系统之前，让我们详细探讨一下推荐系统的类型。下图显示了推荐系统的主要类别:</p>
<p class="CDPAlignCenter1"><img class="aligncenter20" src="img/1fadf08c-415c-415c-81d3-ef14bdba4077.png"/></p>
<p>推荐系统类别</p>
<p class="mce-root">图中所示的每种技术都可以用来建立一个推荐系统模型，该模型能够向用户建议笑话。让我们简单地探讨一下各种推荐引擎类别。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Content-based filtering</title>
    <meta content="urn:uuid:715f2a86-adaf-48a1-98a4-3c219c63f667" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">基于内容的过滤</h1>
                
            
            
                
<p class="mce-root">认知过滤，或基于内容的过滤，通过比较产品属性和客户档案属性来推荐商品。每个产品的属性都表示为一组标签或术语，通常是产品描述文档中出现的词语。客户简档用相同的术语表示，并通过分析客户看过或评价过的产品的内容来构建。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Collaborative filtering</title>
    <meta content="urn:uuid:715f2a86-adaf-48a1-98a4-3c219c63f667" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">协同过滤</h1>
                
            
            
                
<p class="mce-root">社交过滤，或协作过滤，通过使用其他人的推荐来过滤信息。协同过滤背后的原理是，过去欣赏过相同项目的客户在将来也很有可能表现出类似的兴趣。</p>
<p class="mce-root">我们通常会在看电影之前向朋友征求评论和推荐。朋友的推荐比别人的推荐更容易被接受，因为我们和朋友有共同的兴趣。这与协同过滤的工作原理相同。</p>
<p class="mce-root">协同过滤可以进一步分为基于记忆的和基于模型的，如下所示:</p>
<ul class="calibre9">
<li class="calibre10"><strong class="calibre1">基于记忆的</strong>:在这种方法中，用户评分信息用于计算用户或项目之间的相似度。这个计算出的相似度然后被用于提出推荐。</li>
<li class="calibre10"><strong class="calibre1">基于模型的</strong>:应用数据挖掘方法来识别数据中的模式，然后使用学习到的模式来生成建议。</li>
</ul>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Hybrid filtering</title>
    <meta content="urn:uuid:715f2a86-adaf-48a1-98a4-3c219c63f667" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">混合滤波</h1>
                
            
            
                
<p class="mce-root">在这类推荐系统中，我们结合多种类型的推荐系统来提出最终的推荐。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Getting started</title>
    <meta content="urn:uuid:715f2a86-adaf-48a1-98a4-3c219c63f667" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">入门指南</h1>
                
            
            
                
<p class="mce-root">要开始，您必须从GitHub链接下载支持文件。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Understanding the Jokes recommendation problem and the dataset</title>
    <meta content="urn:uuid:715f2a86-adaf-48a1-98a4-3c219c63f667" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">理解笑话推荐问题和数据集</h1>
                
            
            
                
<p class="mce-root">肯·戈德堡博士和他的同事Theresa Roeder、Dhruv Gupta和Chris Perkins通过他们的论文<em class="calibre15"> Eigentaste向世界介绍了一个数据集:一个常数时间协同过滤算法</em>，这在推荐系统领域非常受欢迎。该数据集被命名为小丑的笑话数据集。为了创建它，一些用户会看到几个笑话，并被要求对它们进行评分。用户对各种笑话的评分构成了数据集。该数据集中的数据收集于1999年4月至2003年5月之间。以下是数据集的属性:</p>
<p class="mce-root"/>
<ul class="calibre9">
<li class="calibre10">79，681名用户对150个笑话的评分超过11，000，000</li>
<li class="calibre10">每一行都是一个用户(第1行=用户#1)</li>
</ul>
<ul class="calibre9">
<li class="calibre10">每一列都是一个笑话(第1列=笑话#1)</li>
<li class="calibre10">等级是从-10.00到+10.00的真实值；-10是可能的最低评级，10是最高评级</li>
<li class="calibre10">99对应于零评级</li>
</ul>
<p class="mce-root">R中的<kbd class="calibre11">recommenderlab</kbd>包提供了肯·戈德堡博士团队提供的原始数据集的子集。我们将在本章的项目中使用这个子集。</p>
<p class="mce-root"><kbd class="calibre11">recommenderlab</kbd>库中提供的<kbd class="calibre11">Jester5k</kbd>数据集包含一个5,000 x 100的评分矩阵(5000个用户和100个笑话)，评分在-10.00和+10.00之间。所有选定的用户都给36个或更多的笑话评分。数据集采用<kbd class="calibre11">realRatingMatrix</kbd>格式。这是一种特殊的矩阵格式，<kbd class="calibre11">recommenderlab</kbd>希望数据采用这种格式，以应用库中打包的各种功能。</p>
<p class="mce-root">正如我们已经知道的，<strong class="calibre3">探索性数据分析</strong> ( <strong class="calibre3"> EDA </strong>)是任何数据科学项目的第一步。根据这一原则，让我们从读取数据开始，然后对数据集进行EDA步骤:</p>
<pre class="calibre16"># including the required libraries<br class="title-page-name"/>library(data.table)<br class="title-page-name"/>library(recommenderlab)<br class="title-page-name"/># setting the seed so as to reproduce the results<br class="title-page-name"/>set.seed(54)<br class="title-page-name"/># reading the data to a variable<br class="title-page-name"/>library(recommenderlab)<br class="title-page-name"/>data(Jester5k)<br class="title-page-name"/>str(Jester5k)</pre>
<p class="mce-root">这将导致以下输出:</p>
<pre class="calibre16">Formal class 'realRatingMatrix' [package "recommenderlab"] with 2 slots<br class="title-page-name"/>  ..@ data     :Formal class 'dgCMatrix' [package "Matrix"] with 6 slots<br class="title-page-name"/>  .. .. ..@ i       : int [1:362106] 0 1 2 3 4 5 6 7 8 9 ...<br class="title-page-name"/>  .. .. ..@ p       : int [1:101] 0 3314 6962 10300 13442 18440 22513 27512 32512 35685 ...<br class="title-page-name"/>  .. .. ..@ Dim     : int [1:2] 5000 100<br class="title-page-name"/>  .. .. ..@ Dimnames:List of 2<br class="title-page-name"/>  .. .. .. ..$ : chr [1:5000] "u2841" "u15547" "u15221" "u15573" ...<br class="title-page-name"/>  .. .. .. ..$ : chr [1:100] "j1" "j2" "j3" "j4" ...<br class="title-page-name"/>  .. .. ..@ x       : num [1:362106] 7.91 -3.2 -1.7 -7.38 0.1 0.83 2.91 -2.77 -3.35 -1.99 ...<br class="title-page-name"/>  .. .. ..@ factors : list()<br class="title-page-name"/>  ..@ normalize: NULL</pre>
<p class="mce-root">数据结构的输出是不言自明的，我们看到它为我们已经讨论过的细节提供了经验证据。让我们继续我们的EDA:</p>
<pre class="calibre16"># Viewing the first 5 records in the dataset<br class="title-page-name"/>head(getRatingMatrix(Jester5k),5)</pre>
<p class="mce-root">这将导致以下输出:</p>
<pre class="calibre16">2.5 x 100 sparse Matrix of class "dgCMatrix"<br class="title-page-name"/>   [[ suppressing 100 column names ‘j1’, ‘j2’, ‘j3’ ... ]]                                                                                                           <br class="title-page-name"/>u2841   7.91  9.17  5.34  8.16 -8.74  7.14  8.88 -8.25  5.87  6.21  7.72  6.12 -0.73  7.77 -5.83 -8.88  8.98<br class="title-page-name"/>u15547 -3.20 -3.50 -9.56 -8.74 -6.36 -3.30  0.78  2.18 -8.40 -8.79 -7.04 -6.02  3.35 -4.61  3.64 -6.41 -4.13<br class="title-page-name"/>u15221 -1.70  1.21  1.55  2.77  5.58  3.06  2.72 -4.66  4.51 -3.06  2.33  3.93  0.05  2.38 -3.64 -7.72  0.97<br class="title-page-name"/>u15573 -7.38 -8.93 -3.88 -7.23 -4.90  4.13  2.57  3.83  4.37  3.16 -4.90 -5.78 -5.83  2.52 -5.24  4.51  4.37<br class="title-page-name"/>u21505  0.10  4.17  4.90  1.55  5.53  1.50 -3.79  1.94  3.59  4.81 -0.68 -0.97 -6.46 -0.34 -2.14 -2.04 -2.57                                <br class="title-page-name"/>u2841  -9.32 -9.08 -9.13 7.77  8.59  5.29  8.25  6.02  5.24  7.82  7.96 -8.88  8.25  3.64 -0.73  8.25  5.34 -7.77<br class="title-page-name"/>u15547 -0.15 -1.84 -1.84 1.84 -1.21 -8.59 -5.19 -2.18  0.19  2.57 -5.78  1.07 -8.79  3.01  2.67 -9.22 -9.32  3.69<br class="title-page-name"/>u15221  2.04  1.94  4.42 1.17  0.10 -5.10 -3.25  3.35  3.30 -1.70  3.16 -0.29  1.36  3.54  6.17 -2.72  3.11  4.81<br class="title-page-name"/>u15573  4.95  5.49 -0.49 3.40 -2.14  5.29 -3.11 -4.56 -5.44 -6.89 -0.24 -5.15 -3.59 -8.20  2.18  0.39 -1.21 -2.62<br class="title-page-name"/>u21505 -0.15  2.43  3.16 1.50  4.37 -0.10 -2.14  3.98  2.38  6.84 -0.68  0.87  3.30  6.21  5.78 -6.21 -0.78 -1.36<br class="title-page-name"/>## number of ratings<br class="title-page-name"/>print(nratings(Jester5k))</pre>
<p class="mce-root">这将导致以下输出:</p>
<pre class="calibre16">362106## number of ratings per user</pre>
<p class="mce-root">我们将使用以下命令打印数据集的摘要:</p>
<pre class="calibre16">print(summary(rowCounts(Jester5k)))</pre>
<p class="mce-root">这将导致以下输出:</p>
<pre class="calibre16">   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.<br class="title-page-name"/>  36.00   53.00   72.00   72.42  100.00  100.00</pre>
<p class="mce-root">我们现在将绘制直方图:</p>
<pre class="calibre16">## rating distribution<br class="title-page-name"/>hist(getRatings(Jester5k), main="Distribution of ratings")</pre>
<p class="mce-root">这将导致以下输出:</p>
<p class="CDPAlignCenter1"><img class="aligncenter21" src="img/e25c8393-971a-4c48-8978-0889a87024b8.png"/></p>
<p class="mce-root">从输出中，我们看到了某种程度上的正态分布。也可以看出正面评价多于负面评价。</p>
<p class="mce-root"><kbd class="calibre11">Jester5K</kbd>数据集还提供了一个名为<kbd class="calibre11">JesterJokes</kbd>的字符向量。向量的长度为100。这些是真实的100个笑话，这些笑话被展示给用户以获得评分。我们可以用下面的命令检查笑话:</p>
<pre class="calibre16">head(JesterJokes,5)</pre>
<p class="mce-root">这将导致以下输出:</p>
<pre class="calibre16">j1 "A man visits the doctor. The doctor says \"I have bad news for you.You have cancer and Alzheimer's disease\". The man replies \"Well,thank God I don't have cancer!\""<br class="title-page-name"/>j2 "This couple had an excellent relationship going until one day he came home from work to find his girlfriend packing. He asked her why she was leaving him and she told him that she had heard awful things about him. \"What could they possibly have said to make you move out?\" \"They told me that you were a pedophile.\" He replied, \"That's an awfully big word for a ten year old.\""<br class="title-page-name"/>j3  "Q. What's 200 feet long and has 4 teeth? A. The front row at a Willie Nelson Concert."<br class="title-page-name"/>j4 "Q. What's the difference between a man and a toilet? A. A toilet doesn't follow you around after you use it."<br class="title-page-name"/>j5 "Q. What's O. J. Simpson's Internet address? A. Slash, slash, backslash, slash, slash, escape."</pre>
<p class="mce-root">基于我们拥有的5000个用户评级，我们可以执行额外的EDA来确定被用户评为最佳的笑话。这可以通过下面的代码来完成:</p>
<pre class="calibre16">## 'best' joke with highest average rating<br class="title-page-name"/>best &lt;- which.max(colMeans(Jester5k))<br class="title-page-name"/>cat(JesterJokes[best])</pre>
<p class="mce-root">这将导致以下输出:</p>
<pre class="calibre16">A guy goes into confession and says to the priest, "Father, I'm 80 years old, widower, with 11 grandchildren. Last night I met two beautiful flight attendants. They took me home and I made love to both of them. Twice." The priest said: "Well, my son, when was the last time you were in confession?" "Never Father, I'm Jewish." "So then, why are you telling me?" "I'm telling everybody."</pre>
<p class="mce-root">我们可以执行额外的EDA来可视化单变量和多变量分析。这种探索将帮助我们详细了解每个变量以及它们之间的关系。虽然我们不会深入研究这些方面，但这里有一些想法可以探讨:</p>
<ul class="calibre9">
<li class="calibre10">探索总是给大多数笑话提供高评级的用户</li>
<li class="calibre10">提供给笑话的等级之间的相关性</li>
<li class="calibre10">识别非常关键的用户</li>
<li class="calibre10">探索最受欢迎或最不受欢迎的笑话</li>
<li class="calibre10">识别具有最少评级的笑话并识别它们之间的关联</li>
</ul>
<p class="mce-root"> </p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Converting the DataFrame</title>
    <meta content="urn:uuid:715f2a86-adaf-48a1-98a4-3c219c63f667" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">转换数据帧</h1>
                
            
            
                
<p class="mce-root">在本章中，我们将使用名为<kbd class="calibre11">recommenderlab</kbd>的R库中的函数来构建推荐引擎项目。不考虑我们实现的推荐系统的类别，数据集需要满足一些先决条件才能应用<kbd class="calibre11">recommenderlab</kbd>函数。用于协同过滤的预建的<kbd class="calibre11">recommenderlab</kbd>函数期望<kbd class="calibre11">realRatingMatrix</kbd>作为输入被提供。在我们的例子中，<kbd class="calibre11">Jester5k</kbd>数据集已经是这种格式，因此，我们可以直接使用这个矩阵来应用<kbd class="calibre11">recommenderlab</kbd>函数。</p>
<p class="mce-root">如果我们的数据是R数据帧，如果我们打算转换成<kbd class="calibre11">realRatingMatrix</kbd>，可以执行以下步骤:</p>
<ol class="calibre12">
<li class="calibre10">将数据帧转换为R矩阵，如下所示:</li>
</ol>
<pre class="calibre26"># convert the df dataframe to a matrix<br class="title-page-name"/>r_mat &lt;- as.matrix(df)</pre>
<ol start="2" class="calibre12">
<li class="calibre10">借助<kbd class="calibre11">as()</kbd>函数，将结果矩阵转换为<kbd class="calibre11">realRatingMatrix</kbd>，如下所示:</li>
</ol>
<pre class="calibre26"># convert r_mat matrix to a recommenderlab realRatingMatrix<br class="title-page-name"/>r_real_mat &lt;- as(r_mat,"realRatingMatrix")</pre>
<p>这里，我们假设DataFrame的名称是<kbd class="calibre24">df</kbd>，代码将把它转换成一个<kbd class="calibre24">realRatingMatrix</kbd>，它可以用作<kbd class="calibre24">recommenderlab</kbd>函数的输入。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Dividing the DataFrame</title>
    <meta content="urn:uuid:715f2a86-adaf-48a1-98a4-3c219c63f667" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">分割数据帧</h1>
                
            
            
                
<p class="mce-root">另一个先决条件是将数据集分成训练和测试子集。这些子集将在后面的章节中用于实现我们的推荐系统和测量性能。<kbd class="calibre11">recommenderlab</kbd>库中的<kbd class="calibre11">evaluationScheme()</kbd>函数可用于将数据集分成训练和测试子集。许多用户指定的参数可以传递给这个函数。在下面的代码中，<kbd class="calibre11">realRatingMatrix</kbd>按照80/20的训练/测试分割，为每个用户推荐最多20个项目。此外，我们规定任何大于<kbd class="calibre11">0</kbd>的评级都将被视为正面评级，符合预定义的<kbd class="calibre11">[-10, 10]</kbd>评级标准。<kbd class="calibre11">Jester5k</kbd>数据集可分为训练数据集和测试数据集，代码如下:</p>
<pre class="calibre16"># split the data into the training and the test set<br class="title-page-name"/>Jester5k_es &lt;- evaluationScheme(Jester5k, method="split", train=0.8, given=20, goodRating=0)<br class="title-page-name"/># verifying if the train - test was done successfully<br class="title-page-name"/>print(Jester5k_es)</pre>
<p class="mce-root">这将导致以下输出:</p>
<pre class="calibre16">Evaluation scheme with 20 items given<br class="title-page-name"/>Method: ‘split’ with 1 run(s).<br class="title-page-name"/>Training set proportion: 0.800<br class="title-page-name"/>Good ratings: &gt;=0.000000<br class="title-page-name"/>Data set: 5000 x 100 rating matrix of class ‘realRatingMatrix’ with 362106 ratings.</pre>
<p class="mce-root">从<kbd class="calibre11">evaluationScheme()</kbd>函数的输出中，我们可以观察到该函数产生了一个包含训练和测试子集的R对象。该对象将用于定义和评估各种推荐模型。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Building a recommendation system with an item-based collaborative filtering technique</title>
    <meta content="urn:uuid:715f2a86-adaf-48a1-98a4-3c219c63f667" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">利用基于项目的协同过滤技术构建推荐系统</h1>
                
            
            
                
<p class="mce-root">R的<kbd class="calibre11">recommenderlab</kbd>包提供了<strong class="calibre3">基于项目的协同过滤</strong> ( <strong class="calibre3"> ITCF </strong>)选项来构建推荐系统。这是一个非常简单的方法，只需要我们调用函数并为它提供必要的参数。一般来说，参数会对模型的性能产生很大的影响；因此，测试每个参数组合是获得最佳推荐模型的关键。以下是可以传递给<kbd class="calibre11">Recommender</kbd>功能的参数:</p>
<ul class="calibre9">
<li class="calibre10"><strong class="calibre1">数据标准化</strong>:标准化评分矩阵是为推荐引擎准备数据的关键步骤。标准化过程通过消除评等偏差来处理基准表中的评等。该参数的可能值为<kbd class="calibre11">NULL</kbd>、<kbd class="calibre11">Center</kbd>和<kbd class="calibre11">Z-Score</kbd>。</li>
<li class="calibre10"><strong class="calibre1"> Distance </strong>:表示模型中使用的相似性度量的类型。此参数的可能值为余弦相似性、欧几里德距离和皮尔逊相关。</li>
</ul>
<p class="mce-root">有了这些参数组合，我们可以构建和测试3×3的ITCF模型。ITCF背后的基本直觉是，如果一个人喜欢A项，那么只要A项和B项相似，他们很可能也会喜欢B项。可以理解，术语<em class="calibre15">相似</em>并不表示基于项目属性的项目之间的相似性，而是用户偏好的相似性，例如，喜欢项目A的一群人也喜欢项目b。下图显示了ITCF的工作原理:</p>
<p class="CDPAlignCenter1"><img class="aligncenter22" src="img/7c3012d9-a348-4945-b0e0-b9ac887cc18f.png"/></p>
<p>展示基于项目的协同过滤工作的示例</p>
<p class="mce-root">让我们更详细地研究一下这个图。在ITCF，西瓜和葡萄将形成相似物品邻域，这意味着不管用户是谁，等价的不同物品将形成一个邻域。所以当用户X喜欢西瓜时，来自相同邻域的另一个项目，即葡萄，将由基于项目的协同过滤的推荐系统推荐。</p>
<p class="mce-root">ITCF包括以下三个步骤:</p>
<ol class="calibre12">
<li class="calibre10"><strong class="calibre1">通过距离度量计算基于项目的相似性</strong>:这包括计算项目之间的距离。可以用许多距离度量中的一种来计算距离，例如余弦相似度、欧几里德距离、曼哈顿距离或雅克卡指数。该步骤的输出是获得相似性矩阵，其中每个单元对应于在单元的行上指定的项目和在单元的列上指定的项目的相似性。</li>
</ol>
<ol start="2" class="calibre12">
<li class="calibre10"><strong class="calibre1">预测特定用户的目标物品评分</strong>:通过计算与目标物品非常相似的物品的评分的加权和来得出评分。</li>
<li class="calibre10"><strong class="calibre1">推荐前N项</strong>:一旦所有项都被预测出来，我们就推荐前<em class="calibre22"> N项</em>。</li>
</ol>
<p class="mce-root">现在，让我们构建每个ITCF模型，并根据测试数据集测量性能。下面的代码为ITCF模型定型了几个参数组合:</p>
<pre class="calibre16">type = "IBCF"<br class="title-page-name"/>##train ITCF cosine similarity models<br class="title-page-name"/># non-normalized<br class="title-page-name"/>ITCF_N_C &lt;- Recommender(getData(Jester5k_es, "train"), type,<br class="title-page-name"/>                        param=list(normalize = NULL, method="Cosine"))<br class="title-page-name"/># centered<br class="title-page-name"/>ITCF_C_C &lt;- Recommender(getData(Jester5k_es, "train"), type,<br class="title-page-name"/>                        param=list(normalize = "center",method="Cosine"))<br class="title-page-name"/># Z-score normalization<br class="title-page-name"/>ITCF_Z_C &lt;- Recommender(getData(Jester5k_es, "train"), type,<br class="title-page-name"/>                        param=list(normalize = "Z-score",method="Cosine"))<br class="title-page-name"/>##train ITCF Euclidean Distance models<br class="title-page-name"/># non-normalized<br class="title-page-name"/>ITCF_N_E &lt;- Recommender(getData(Jester5k_es, "train"), type,<br class="title-page-name"/>                        param=list(normalize = NULL, method="Euclidean"))<br class="title-page-name"/># centered<br class="title-page-name"/>ITCF_C_E &lt;- Recommender(getData(Jester5k_es, "train"), type,<br class="title-page-name"/>                        param=list(normalize = "center",method="Euclidean"))<br class="title-page-name"/># Z-score normalization<br class="title-page-name"/>ITCF_Z_E &lt;- Recommender(getData(Jester5k_es, "train"), type,<br class="title-page-name"/>                        param=list(normalize = "Z-score",method="Euclidean"))<br class="title-page-name"/>#train ITCF pearson correlation models<br class="title-page-name"/># non-normalized<br class="title-page-name"/>ITCF_N_P &lt;- Recommender(getData(Jester5k_es, "train"), type,<br class="title-page-name"/>                        param=list(normalize = NULL, method="pearson"))<br class="title-page-name"/># centered<br class="title-page-name"/>ITCF_C_P &lt;- Recommender(getData(Jester5k_es, "train"), type,<br class="title-page-name"/>                        param=list(normalize = "center",method="pearson"))<br class="title-page-name"/># Z-score normalization<br class="title-page-name"/>ITCF_Z_P &lt;- Recommender(getData(Jester5k_es, "train"), type,<br class="title-page-name"/>                        param=list(normalize = "Z-score",method="pearson"))</pre>
<p class="mce-root">我们现在有了ITCF模型，所以让我们开始计算我们创建的每个模型在测试数据上的性能。目标是为该数据集确定性能最佳的ITCF模型。以下代码获取测试数据集上所有九个模型的性能测量值:</p>
<pre class="calibre16"># compute predicted ratings from each of the 9 models on the test dataset<br class="title-page-name"/>pred1 &lt;- predict(ITCF_N_C, getData(Jester5k_es, "known"), type="ratings")<br class="title-page-name"/>pred2 &lt;- predict(ITCF_C_C, getData(Jester5k_es, "known"), type="ratings")<br class="title-page-name"/>pred3 &lt;- predict(ITCF_Z_C, getData(Jester5k_es, "known"), type="ratings")<br class="title-page-name"/>pred4 &lt;- predict(ITCF_N_E, getData(Jester5k_es, "known"), type="ratings")<br class="title-page-name"/>pred5 &lt;- predict(ITCF_C_E, getData(Jester5k_es, "known"), type="ratings")<br class="title-page-name"/>pred6 &lt;- predict(ITCF_Z_E, getData(Jester5k_es, "known"), type="ratings")<br class="title-page-name"/>pred7 &lt;- predict(ITCF_N_P, getData(Jester5k_es, "known"), type="ratings")<br class="title-page-name"/>pred8 &lt;- predict(ITCF_C_P, getData(Jester5k_es, "known"), type="ratings")<br class="title-page-name"/>pred9 &lt;- predict(ITCF_Z_P, getData(Jester5k_es, "known"), type="ratings")<br class="title-page-name"/># set all predictions that fall outside the valid range to the boundary values<br class="title-page-name"/>pred1@data@x[pred1@data@x[] &lt; -10] &lt;- -10<br class="title-page-name"/>pred1@data@x[pred1@data@x[] &gt; 10] &lt;- 10<br class="title-page-name"/>pred2@data@x[pred2@data@x[] &lt; -10] &lt;- -10<br class="title-page-name"/>pred2@data@x[pred2@data@x[] &gt; 10] &lt;- 10<br class="title-page-name"/>pred3@data@x[pred3@data@x[] &lt; -10] &lt;- -10<br class="title-page-name"/>pred3@data@x[pred3@data@x[] &gt; 10] &lt;- 10<br class="title-page-name"/>pred4@data@x[pred4@data@x[] &lt; -10] &lt;- -10<br class="title-page-name"/>pred4@data@x[pred4@data@x[] &gt; 10] &lt;- 10<br class="title-page-name"/>pred5@data@x[pred5@data@x[] &lt; -10] &lt;- -10<br class="title-page-name"/>pred5@data@x[pred5@data@x[] &gt; 10] &lt;- 10<br class="title-page-name"/>pred6@data@x[pred6@data@x[] &lt; -10] &lt;- -10<br class="title-page-name"/>pred6@data@x[pred6@data@x[] &gt; 10] &lt;- 10<br class="title-page-name"/>pred7@data@x[pred7@data@x[] &lt; -10] &lt;- -10<br class="title-page-name"/>pred7@data@x[pred7@data@x[] &gt; 10] &lt;- 10<br class="title-page-name"/>pred8@data@x[pred8@data@x[] &lt; -10] &lt;- -10<br class="title-page-name"/>pred8@data@x[pred8@data@x[] &gt; 10] &lt;- 10<br class="title-page-name"/>pred9@data@x[pred9@data@x[] &lt; -10] &lt;- -10<br class="title-page-name"/>pred9@data@x[pred9@data@x[] &gt; 10] &lt;- 10<br class="title-page-name"/># aggregate the performance measurements obtained from all the models<br class="title-page-name"/>error_ITCF &lt;- rbind(<br class="title-page-name"/>  ITCF_N_C = calcPredictionAccuracy(pred1, getData(Jester5k_es, "unknown")),<br class="title-page-name"/>  ITCF_C_C = calcPredictionAccuracy(pred2, getData(Jester5k_es, "unknown")),<br class="title-page-name"/>  ITCF_Z_C = calcPredictionAccuracy(pred3, getData(Jester5k_es, "unknown")),<br class="title-page-name"/>  ITCF_N_E = calcPredictionAccuracy(pred4, getData(Jester5k_es, "unknown")),<br class="title-page-name"/>  ITCF_C_E = calcPredictionAccuracy(pred5, getData(Jester5k_es, "unknown")),<br class="title-page-name"/>  ITCF_Z_E = calcPredictionAccuracy(pred6, getData(Jester5k_es, "unknown")),<br class="title-page-name"/>  ITCF_N_P = calcPredictionAccuracy(pred7, getData(Jester5k_es, "unknown")),<br class="title-page-name"/>  ITCF_C_P = calcPredictionAccuracy(pred8, getData(Jester5k_es, "unknown")),<br class="title-page-name"/>  ITCF_Z_P = calcPredictionAccuracy(pred9, getData(Jester5k_es, "unknown"))<br class="title-page-name"/>)<br class="title-page-name"/>library(knitr)<br class="title-page-name"/>kable(error_ITCF)</pre>
<p class="mce-root">这将导致以下输出:</p>
<pre class="calibre16">|         |     RMSE|      MSE|      MAE|<br class="title-page-name"/>|:--------|--------:|--------:|--------:|<br class="title-page-name"/>|ITCF_N_C | 4.533455| 20.55221| 3.460860|<br class="title-page-name"/>|ITCF_C_C | 5.082643| 25.83326| 4.012391|<br class="title-page-name"/>|ITCF_Z_C | 5.089552| 25.90354| 4.021435|<br class="title-page-name"/>|ITCF_N_E | 4.520893| 20.43848| 3.462490|<br class="title-page-name"/>|ITCF_C_E | 4.519783| 20.42844| 3.462271|<br class="title-page-name"/>|ITCF_Z_E | 4.527953| 20.50236| 3.472080|<br class="title-page-name"/>|ITCF_N_P | 4.582121| 20.99583| 3.522113|<br class="title-page-name"/>|ITCF_C_P | 4.545966| 20.66581| 3.510830|<br class="title-page-name"/>|ITCF_Z_P | 4.569294| 20.87845| 3.536400|</pre>
<p class="mce-root">我们看到，ITCF推荐应用于具有欧几里德距离的数据产生了最佳性能测量的输出。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Building a recommendation system with a user-based collaborative filtering technique</title>
    <meta content="urn:uuid:715f2a86-adaf-48a1-98a4-3c219c63f667" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">利用基于用户的协同过滤技术构建推荐系统</h1>
                
            
            
                
<p class="mce-root">我们之前构建的笑话推荐系统，基于条目的过滤，使用了r中可用的强大的<kbd class="calibre11">recommenderlab</kbd>库。在这个基于<strong class="calibre3">用户的协作过滤</strong> ( <strong class="calibre3"> UBCF </strong>)方法的实现中，我们使用了同一个库。</p>
<p class="mce-root">下图显示了UBCF的工作原理:</p>
<p class="CDPAlignCenter1"><img class="aligncenter23" src="img/d22941f0-29d2-4c0e-8a79-5f065e5f527e.png"/></p>
<p>描述基于用户的协作过滤器的工作原理的例子</p>
<p class="mce-root">为了更好地理解这个概念，让我们详细讨论前面的图表。假设有三个用户:X、Y和Z。在UBCF，用户X和Z非常相似，因为他们都喜欢草莓和西瓜。用户X也喜欢葡萄和橘子。于是一个基于用户的协同过滤器向用户z推荐葡萄和橙子，这个想法就是相似的人往往喜欢相似的东西。</p>
<p class="mce-root">基于用户的协作过滤器和基于项目的协作过滤器之间的主要区别由在线零售网站中常见的以下推荐标题来证明:</p>
<ul class="calibre9">
<li class="calibre10"><strong class="calibre1"> ITCF </strong>:买了这件商品的顾客也买了</li>
<li class="calibre10"><strong class="calibre1"> UBCF </strong>:和你差不多的客户买了</li>
</ul>
<p class="mce-root">基于用户的协作过滤器建立在以下三个关键步骤之上:</p>
<ol class="calibre12">
<li class="calibre10">找到用户<em class="calibre22"> x </em>的<strong class="calibre1"> k个最近邻居</strong> ( <strong class="calibre1"> KNN </strong>)，使用相似度函数<em class="calibre22"> w </em>，测量每对用户之间的距离:</li>
</ol>
<p class="CDPAlignCenter1"><img class="fm-editor-equation2" src="img/0052a429-61c2-4996-afe6-b51671d3ac79.png"/></p>
<ol start="2" class="calibre12">
<li class="calibre10">预测用户<em class="calibre22"> x </em>将对KNN已评分但<em class="calibre22"> x </em>未评分的所有项目提供的评分。</li>
<li class="calibre10">向用户推荐的第<em class="calibre22"> N </em>个项目<em class="calibre22"> x </em>是具有最佳预测评级的前<em class="calibre22"> N </em>个项目。</li>
</ol>
<p class="mce-root">简而言之，在UBCF过程中构建用户-项目矩阵，并基于相似的用户，预测用户的未观看项目的评级。在预测中获得最高评级的项目构成了最终的推荐列表。</p>
<p class="mce-root">这个项目的实施非常类似于ITCF，因为我们使用同一个库。代码中唯一需要的更改是将IBCF方法改为使用UBCF。以下代码块是UBCF项目实施的完整代码:</p>
<pre class="calibre16">library(recommenderlab)<br class="title-page-name"/>data(Jester5k)<br class="title-page-name"/># split the data into the training and the test set<br class="title-page-name"/>Jester5k_es &lt;- evaluationScheme(Jester5k, method="split", train=0.8, given=20, goodRating=0)<br class="title-page-name"/>print(Jester5k_es)<br class="title-page-name"/>type = "UBCF"<br class="title-page-name"/>#train UBCF cosine similarity models<br class="title-page-name"/># non-normalized<br class="title-page-name"/>UBCF_N_C &lt;- Recommender(getData(Jester5k_es, "train"), type,<br class="title-page-name"/>                        param=list(normalize = NULL, method="Cosine"))<br class="title-page-name"/># centered<br class="title-page-name"/>UBCF_C_C &lt;- Recommender(getData(Jester5k_es, "train"), type,<br class="title-page-name"/>                        param=list(normalize = "center",method="Cosine"))<br class="title-page-name"/># Z-score normalization<br class="title-page-name"/>UBCF_Z_C &lt;- Recommender(getData(Jester5k_es, "train"), type,<br class="title-page-name"/>                        param=list(normalize = "Z-score",method="Cosine"))<br class="title-page-name"/>#train UBCF Euclidean Distance models<br class="title-page-name"/># non-normalized<br class="title-page-name"/>UBCF_N_E &lt;- Recommender(getData(Jester5k_es, "train"), type,<br class="title-page-name"/>                        param=list(normalize = NULL, method="Euclidean"))<br class="title-page-name"/># centered<br class="title-page-name"/>UBCF_C_E &lt;- Recommender(getData(Jester5k_es, "train"), type,<br class="title-page-name"/>                        param=list(normalize = "center",method="Euclidean"))<br class="title-page-name"/># Z-score normalization<br class="title-page-name"/>UBCF_Z_E &lt;- Recommender(getData(Jester5k_es, "train"), type,<br class="title-page-name"/>                        param=list(normalize = "Z-score",method="Euclidean"))<br class="title-page-name"/>#train UBCF pearson correlation models<br class="title-page-name"/># non-normalized<br class="title-page-name"/>UBCF_N_P &lt;- Recommender(getData(Jester5k_es, "train"), type,<br class="title-page-name"/>                        param=list(normalize = NULL, method="pearson"))<br class="title-page-name"/># centered<br class="title-page-name"/>UBCF_C_P &lt;- Recommender(getData(Jester5k_es, "train"), type,<br class="title-page-name"/>                        param=list(normalize = "center",method="pearson"))<br class="title-page-name"/># Z-score normalization<br class="title-page-name"/>UBCF_Z_P &lt;- Recommender(getData(Jester5k_es, "train"), type,<br class="title-page-name"/>                        param=list(normalize = "Z-score",method="pearson"))<br class="title-page-name"/># compute predicted ratings from each of the 9 models on the test dataset<br class="title-page-name"/>pred1 &lt;- predict(UBCF_N_C, getData(Jester5k_es, "known"), type="ratings")<br class="title-page-name"/>pred2 &lt;- predict(UBCF_C_C, getData(Jester5k_es, "known"), type="ratings")<br class="title-page-name"/>pred3 &lt;- predict(UBCF_Z_C, getData(Jester5k_es, "known"), type="ratings")<br class="title-page-name"/>pred4 &lt;- predict(UBCF_N_E, getData(Jester5k_es, "known"), type="ratings")<br class="title-page-name"/>pred5 &lt;- predict(UBCF_C_E, getData(Jester5k_es, "known"), type="ratings")<br class="title-page-name"/>pred6 &lt;- predict(UBCF_Z_E, getData(Jester5k_es, "known"), type="ratings")<br class="title-page-name"/>pred7 &lt;- predict(UBCF_N_P, getData(Jester5k_es, "known"), type="ratings")<br class="title-page-name"/>pred8 &lt;- predict(UBCF_C_P, getData(Jester5k_es, "known"), type="ratings")<br class="title-page-name"/>pred9 &lt;- predict(UBCF_Z_P, getData(Jester5k_es, "known"), type="ratings")<br class="title-page-name"/># set all predictions that fall outside the valid range to the boundary values<br class="title-page-name"/>pred1@data@x[pred1@data@x[] &lt; -10] &lt;- -10<br class="title-page-name"/>pred1@data@x[pred1@data@x[] &gt; 10] &lt;- 10<br class="title-page-name"/>pred2@data@x[pred2@data@x[] &lt; -10] &lt;- -10<br class="title-page-name"/>pred2@data@x[pred2@data@x[] &gt; 10] &lt;- 10<br class="title-page-name"/>pred3@data@x[pred3@data@x[] &lt; -10] &lt;- -10<br class="title-page-name"/>pred3@data@x[pred3@data@x[] &gt; 10] &lt;- 10<br class="title-page-name"/>pred4@data@x[pred4@data@x[] &lt; -10] &lt;- -10<br class="title-page-name"/>pred4@data@x[pred4@data@x[] &gt; 10] &lt;- 10<br class="title-page-name"/>pred5@data@x[pred5@data@x[] &lt; -10] &lt;- -10<br class="title-page-name"/>pred5@data@x[pred5@data@x[] &gt; 10] &lt;- 10<br class="title-page-name"/>pred6@data@x[pred6@data@x[] &lt; -10] &lt;- -10<br class="title-page-name"/>pred6@data@x[pred6@data@x[] &gt; 10] &lt;- 10<br class="title-page-name"/>pred7@data@x[pred7@data@x[] &lt; -10] &lt;- -10<br class="title-page-name"/>pred7@data@x[pred7@data@x[] &gt; 10] &lt;- 10<br class="title-page-name"/>pred8@data@x[pred8@data@x[] &lt; -10] &lt;- -10<br class="title-page-name"/>pred8@data@x[pred8@data@x[] &gt; 10] &lt;- 10<br class="title-page-name"/>pred9@data@x[pred9@data@x[] &lt; -10] &lt;- -10<br class="title-page-name"/>pred9@data@x[pred9@data@x[] &gt; 10] &lt;- 10<br class="title-page-name"/># aggregate the performance statistics<br class="title-page-name"/>error_UBCF &lt;- rbind(<br class="title-page-name"/>  UBCF_N_C = calcPredictionAccuracy(pred1, getData(Jester5k_es, "unknown")),<br class="title-page-name"/>  UBCF_C_C = calcPredictionAccuracy(pred2, getData(Jester5k_es, "unknown")),<br class="title-page-name"/>  UBCF_Z_C = calcPredictionAccuracy(pred3, getData(Jester5k_es, "unknown")),<br class="title-page-name"/>  UBCF_N_E = calcPredictionAccuracy(pred4, getData(Jester5k_es, "unknown")),<br class="title-page-name"/>  UBCF_C_E = calcPredictionAccuracy(pred5, getData(Jester5k_es, "unknown")),<br class="title-page-name"/>  UBCF_Z_E = calcPredictionAccuracy(pred6, getData(Jester5k_es, "unknown")),<br class="title-page-name"/>  UBCF_N_P = calcPredictionAccuracy(pred7, getData(Jester5k_es, "unknown")),<br class="title-page-name"/>  UBCF_C_P = calcPredictionAccuracy(pred8, getData(Jester5k_es, "unknown")),<br class="title-page-name"/>  UBCF_Z_P = calcPredictionAccuracy(pred9, getData(Jester5k_es, "unknown"))<br class="title-page-name"/>)<br class="title-page-name"/>library(knitr)<br class="title-page-name"/>print(kable(error_UBCF))</pre>
<p class="mce-root">这将导致以下输出:</p>
<pre class="calibre16">|         |     RMSE|      MSE|      MAE|<br class="title-page-name"/>|:--------|--------:|--------:|--------:|<br class="title-page-name"/>|UBCF_N_C | 4.877935| 23.79425| 3.986170|<br class="title-page-name"/>|UBCF_C_C | 4.518210| 20.41422| 3.578551|<br class="title-page-name"/>|UBCF_Z_C | 4.517669| 20.40933| 3.552120|<br class="title-page-name"/>|UBCF_N_E | 4.644877| 21.57488| 3.778046|<br class="title-page-name"/>|UBCF_C_E | 4.489157| 20.15253| 3.552543|<br class="title-page-name"/>|UBCF_Z_E | 4.496185| 20.21568| 3.528534|<br class="title-page-name"/>|UBCF_N_P | 4.927442| 24.27968| 4.074879|<br class="title-page-name"/>|UBCF_C_P | 4.487073| 20.13382| 3.553429|<br class="title-page-name"/>|UBCF_Z_P | 4.484986| 20.11510| 3.525356|</pre>
<p class="mce-root">基于UBCF输出，我们观察到以皮尔逊相关作为距离的<kbd class="calibre11">Z-score</kbd>标准化数据产生了最佳性能测量。此外，如果我们愿意，可以比较UBCF和ITCF的结果(测试需要在相同的测试数据集上进行)，以得出接受为最终推荐引擎部署而构建的18个模型中的最佳模型的结论。</p>
<p>代码中需要注意的关键点是传递给<kbd class="calibre24">method</kbd>参数的<kbd class="calibre24">UBCF</kbd>值。在之前的项目中，我们构建了一个基于项目的协作过滤器；我们需要做的就是用IBCF替换传递给参数<kbd class="calibre24">method</kbd>的值。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Building a recommendation system based on an association-rule mining technique</title>
    <meta content="urn:uuid:715f2a86-adaf-48a1-98a4-3c219c63f667" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">基于关联规则挖掘技术构建推荐系统</h1>
                
            
            
                
<p class="mce-root">关联规则挖掘或市场购物篮分析是零售业中非常流行的数据挖掘技术，用于识别需要放在一起以鼓励交叉销售的产品。该算法背后一个有趣的方面是挖掘历史发票来识别一起购买的产品。</p>
<p class="mce-root">有几种现成的算法可用于执行购物篮分析。其中有先验、<strong class="calibre3">等价类变换</strong> ( <strong class="calibre3"> ECLAT </strong>)、<strong class="calibre3">频繁模式增长</strong> ( <strong class="calibre3"> FP-growth </strong>)。我们将学习通过在Jester笑话数据集上应用Apriori算法来解决向用户推荐笑话的问题。我们现在将学习支持Apriori算法的理论方面。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>The Apriori algorithm</title>
    <meta content="urn:uuid:715f2a86-adaf-48a1-98a4-3c219c63f667" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">Apriori算法</h1>
                
            
            
                
<p class="mce-root">该算法的构建块是在任何给定交易中找到的项目。每个事务可以包含一个或多个项目。构成事务的项称为项集。交易的一个例子是发票。</p>
<p class="mce-root">给定事务数据集，目标是找到数据中相互关联的项。关联性被测量为项目在相同上下文中出现的频率。例如，在购买一个产品的同时购买另一个产品，这代表了一个关联规则。关联规则检测项目的常见用法。</p>
<p class="mce-root">更正式地说，我们可以将关联规则挖掘定义为，给定一组项目I = {I1，I2，..Im}和数据库事务D = {t1，t，2..tn}，其中ti= { Ii1，Ii2..Iim}其中Iik是的元素，关联是X-&gt;Y的蕴涵，其中I的X，Y子集是项目集，X交集Y是φ。简而言之，关联表达了一个来自X-&gt; Y的蕴涵，其中X和Y是项集。</p>
<p class="mce-root">通过一个例子可以更好的理解算法。因此，让我们考虑下表，它显示了一个超市中典型的交易示例列表:</p>
<table border="1" class="calibre17">
<tbody class="calibre18">
<tr class="calibre19">
<td class="calibre27">
<p class="CDPAlignCenter1"><strong class="calibre3">交易</strong></p>
</td>
<td class="calibre28">
<p class="CDPAlignCenter1"><strong class="calibre3">项目</strong></p>
</td>
</tr>
<tr class="calibre19">
<td class="calibre27">
<p class="mce-root">一</p>
</td>
<td class="calibre28">
<p class="mce-root">牛奶、凝乳、巧克力</p>
</td>
</tr>
<tr class="calibre19">
<td class="calibre27">
<p class="mce-root">2</p>
</td>
<td class="calibre28">
<p class="mce-root">面包，黄油</p>
</td>
</tr>
<tr class="calibre19">
<td class="calibre27">
<p class="mce-root">3</p>
</td>
<td class="calibre28">
<p class="mce-root">可乐，果酱</p>
</td>
</tr>
<tr class="calibre19">
<td class="calibre27">
<p class="mce-root">四</p>
</td>
<td class="calibre28">
<p class="mce-root">面包、牛奶、黄油、可乐</p>
</td>
</tr>
<tr class="calibre19">
<td class="calibre27">
<p class="mce-root">5</p>
</td>
<td class="calibre28">
<p class="mce-root">面包、牛奶、黄油、果酱</p>
</td>
</tr>
</tbody>
</table>
<p>超级市场中的交易示例</p>
<p class="mce-root">让我们尝试探索一些有助于理解Apriori算法工作原理的基本概念:</p>
<ul class="calibre9">
<li class="calibre10"><strong class="calibre1">项目</strong>:项目是每笔交易中的任何单个产品。例如，牛奶、可乐和黄油都被称为物品。</li>
<li class="calibre10"><strong class="calibre1">项目集</strong>:一个或多个项目的集合。比如<em class="calibre22">{黄油，牛奶，可乐}，{黄油，牛奶} </em>。</li>
</ul>
<ul class="calibre9">
<li class="calibre10"><strong class="calibre1">支持计数</strong>:一个项目集出现的频率。例如，支持计数或<em class="calibre22">σ{黄油、面包、牛奶} = 2 </em>。</li>
<li class="calibre10"><strong class="calibre1">支持</strong>:包含一个项集的事务的一部分。比如<em class="calibre22">s = {黄油面包牛奶} = 2/5 </em>。</li>
<li class="calibre10"><strong class="calibre1">频繁项集</strong>:支持度大于最小阈值的项集。</li>
<li class="calibre10"><strong class="calibre1">支持上下文</strong>中的项集:包含<em class="calibre22"> X </em>和<em class="calibre22"> Y </em>的部分上下文:</li>
</ul>
<p class="CDPAlignCenter1"><img class="fm-editor-equation3" src="img/d64f7390-23d7-409f-94cf-887150e51c11.png"/></p>
<p class="calibre29">所以，<em class="calibre15"> s </em>对于<em class="calibre15">{牛奶，黄油}-&gt;{面包}将是s =σ{牛奶，黄油，面包}/N = 2/5 = 0.4 </em></p>
<ul class="calibre9">
<li class="calibre10"><strong class="calibre1">置信度</strong>:度量规则的强度，而支持度度量规则在数据库中出现的频率。它通过以下公式计算出<em class="calibre22"> Y </em>中的项目在包含<em class="calibre22"> X </em>中出现的频率:</li>
</ul>
<p class="CDPAlignCenter1"><img class="fm-editor-equation4" src="img/d00a906f-97da-40fc-8a56-293d0461bcc9.png"/></p>
<p class="calibre29">例如:对于{面包}--&gt; {黄油}</p>
<p class="mce-root"><em class="calibre15"> c或α=σ{黄油，面包}/σ{面包} = 3/3 = 1 </em></p>
<p class="mce-root">让我们考虑<em class="calibre15">{凝乳}-&gt;{面包} </em>的另一个示例置信度:</p>
<p class="mce-root"><em class="calibre15"> c或α=σ{凝乳，面包}/σ{面包} = 0/3 = 0 </em></p>
<p class="mce-root">Apriori算法旨在从项目列表中生成所有可能的项目集组合，然后删除符合传递给该算法的预定义支持度和置信度参数值的项目集。因此，可以理解，Apriori算法是一个两步算法:</p>
<ol class="calibre12">
<li class="calibre10">从项目生成项目集</li>
<li class="calibre10">基于预定义的支持度和置信度评估和修剪项目集</li>
</ol>
<p class="mce-root">让我们详细讨论步骤1。假设集合中有<em class="calibre15"> n </em>个项目。一个人可以创建的项目集的数量是2^ <em class="calibre15"> n </em>，所有这些都需要在第二步中进行评估，以便得出最终结果。即使只考虑100个不同的项目，生成的项目集数量也是1.27e+30！大量的项目集带来了严峻的计算挑战。</p>
<p class="mce-root">Apriori算法通过抢占通常很少或不太重要的项目集来克服这一挑战。先验原则声明<em class="calibre15">如果一个项目集是频繁的，那么它的所有子集也一定是频繁的</em>。这意味着，如果一个项目不满足预定义的支持阈值，则该项目不会参与项目集的创建。因此，Apriori算法提出了有限数量的可评估项目集，而不会遇到计算挑战。</p>
<p class="mce-root">该算法的第一步本质上是迭代的。在第一次迭代中，它考虑长度为1的所有项集，即每个项集中只包含一项。然后，对每个项目进行评估，以消除被发现不符合预设支持阈值的项目集。第一次迭代的输出是满足所需支持的长度为1的所有项集。这成为迭代2的输入，现在长度为2的项集仅使用第一次迭代中输出的最终项集来形成。再次检查在步骤2中形成的每个项目集的支持度阈值；如果不满足，则删除此类项目集。迭代继续进行，直到无法创建新的项集。下图说明了项目集的处理过程:</p>
<p class="CDPAlignCenter1"><img class="aligncenter24" src="img/6eead20b-c634-450e-be63-eba894c02b86.png"/></p>
<p>显示Apriori算法中项目集创建的图示</p>
<p class="mce-root">一旦所有项目集都提交了算法的第一步迭代，第二步就开始了。对生成的每个项目集进行测试，以检查它是否满足预定义的置信度值。如果不满足阈值，则从最终输出中删除这些项目集。</p>
<p class="mce-root">在一个阶段，所有的迭代都完成了，最终的规则是先验的输出，我们利用一个叫做lift的度量来消费来自最终输出的相关规则。Lift定义了一个项目或项目集相对于其典型购买率被购买的可能性，假设我们知道另一个项目或项目集已被购买。对于每个项目集，我们使用以下公式获得提升度量:</p>
<p class="CDPAlignCenter1"><img class="fm-editor-equation5" src="img/d40eaf00-9435-4131-9272-b62dc512c54b.png"/></p>
<p class="mce-root">让我们更深入地理解提升度量。假设在超市，牛奶和面包是偶然一起买的。在这种情况下，预计大量交易将涵盖购买的牛奶和面包。lift(牛奶-&gt;面包)大于1意味着这些物品被发现放在一起的次数比偶然一起购买的次数多。当评估规则在商业中的有用性时，我们通常会寻找大于1的提升值。提升值大于1表示生成的项集非常强大，因此值得考虑实现。</p>
<p class="mce-root">现在，让我们使用Apriori算法实现推荐系统:</p>
<pre class="calibre16"># load the required libraries<br class="title-page-name"/>library(data.table)<br class="title-page-name"/>library(arules)<br class="title-page-name"/>library(recommenderlab)<br class="title-page-name"/># set the seed so that the results are replicable<br class="title-page-name"/>set.seed(42)<br class="title-page-name"/># reading the Jester5k data<br class="title-page-name"/>data(Jester5k)<br class="title-page-name"/>class(Jester5k)</pre>
<p class="mce-root">这将导致以下输出:</p>
<pre class="calibre16">[1] "realRatingMatrix"<br class="title-page-name"/>attr(,"package")<br class="title-page-name"/>[1] "recommenderlab"</pre>
<p class="mce-root">从输出中我们可以看到，<kbd class="calibre11">recommenderlab</kbd>库中的<kbd class="calibre11">Jester5k</kbd>数据是<kbd class="calibre11">realRatingsMatrix</kbd>格式的。我们还知道，该矩阵中的单元格包含用户对各种笑话提供的评级，我们知道评级范围在-10到+10之间。</p>
<p class="mce-root">在<kbd class="calibre11">Jester5k</kbd>数据集上应用Apriori算法让我们有机会理解笑话之间的关联。但是，在应用Apriori算法之前，我们需要将数据集转换为二进制值，其中1表示正面评级，0表示负面评级或无评级。<kbd class="calibre11">recommenderlab</kbd>库提供了<kbd class="calibre11">binarize()</kbd>函数，它可以为我们执行所需的操作。以下代码将评级矩阵二进制化:</p>
<pre class="calibre16"># binarizing the Jester ratings<br class="title-page-name"/>Jester5k_bin &lt;- binarize(Jester5k, minRating=1)<br class="title-page-name"/># let us verify the binarized object<br class="title-page-name"/>class(Jester5k_bin)</pre>
<p class="mce-root">这将导致以下输出:</p>
<pre class="calibre16">[1] "binaryRatingMatrix"<br class="title-page-name"/>attr(,"package")<br class="title-page-name"/>[1] "recommenderlab"</pre>
<p class="mce-root">我们可以从输出中观察到<kbd class="calibre11">realRatingsMatrix</kbd>被成功转换为<kbd class="calibre11">binaryRatingMatrix</kbd>。挖掘关联的Apriori算法期望传递一个矩阵作为输入，而不是<kbd class="calibre11">binaryRatingMatrix</kbd>。我们可以很容易地用下面的代码将<kbd class="calibre11">Jester5k_bin</kbd>对象转换成矩阵格式:</p>
<pre class="calibre16"># converting the binaryratingsmatrix to matrix format<br class="title-page-name"/>Jester5k_bin_mat &lt;- as(Jester5k_bin,"matrix")<br class="title-page-name"/># visualizing the matrix object<br class="title-page-name"/>View(Jester5k_bin_mat)</pre>
<p class="mce-root">这将导致以下输出:</p>
<p class="CDPAlignCenter1"><img class="aligncenter25" src="img/94f50034-68a7-44df-9c4e-653e4d103700.png"/></p>
<p class="mce-root">我们从输出中看到，矩阵的所有单元都表示为<kbd class="calibre11">TRUE</kbd>和<kbd class="calibre11">FALSE</kbd>，但是Apriori期望单元是数字的。现在让我们用下面的代码将单元格分别转换为<kbd class="calibre11">TRUE</kbd>和<kbd class="calibre11">FALSE</kbd>的<kbd class="calibre11">1</kbd>和<kbd class="calibre11">0</kbd>:</p>
<pre class="calibre16"># converting the cell values to 1 and 0<br class="title-page-name"/>Jester5k_bin_mat_num &lt;- 1*Jester5k_bin_mat<br class="title-page-name"/># viewing the matrix<br class="title-page-name"/>View(Jester5k_bin_mat_num)</pre>
<p class="mce-root">这将导致以下输出:</p>
<p class="CDPAlignCenter1"><img class="aligncenter26" src="img/5f7b4675-5f57-4d77-82bb-3768722b41c0.png"/></p>
<p class="mce-root">现在，我们已经准备好对数据集应用Apriori算法。我们需要将两个参数<kbd class="calibre11">support</kbd>和<kbd class="calibre11">confidence</kbd>传递给算法。该算法基于这两个参数值挖掘数据集。我们将<kbd class="calibre11">0.5</kbd>作为支持的值，将<kbd class="calibre11">0.8</kbd>作为信心的值。下面一行代码提取了Jester笑话数据集中存在的笑话关联:</p>
<pre class="calibre16">rules &lt;- apriori(data = Jester5k_bin_mat_num, parameter = list(supp = 0.005, conf = 0.8))</pre>
<p class="mce-root">这将导致以下输出:</p>
<pre class="calibre16">Apriori<br class="title-page-name"/>Parameter specification:<br class="title-page-name"/> confidence minval smax arem  aval originalSupport maxtime support minlen maxlen target   ext<br class="title-page-name"/>        0.8    0.1    1 none FALSE            TRUE       5     0.5      1     10  rules FALSE<br class="title-page-name"/>Algorithmic control:<br class="title-page-name"/> filter tree heap memopt load sort verbose<br class="title-page-name"/>    0.1 TRUE TRUE  FALSE TRUE    2    TRUE<br class="title-page-name"/>Absolute minimum support count: 2500<br class="title-page-name"/>set item appearances ...[0 item(s)] done [0.00s].<br class="title-page-name"/>set transactions ...[100 item(s), 5000 transaction(s)] done [0.02s].<br class="title-page-name"/>sorting and recoding items ... [29 item(s)] done [0.00s].<br class="title-page-name"/>creating transaction tree ... done [0.00s].<br class="title-page-name"/>checking subsets of size 1 2 3 done [0.01s].<br class="title-page-name"/>writing ... [78 rule(s)] done [0.00s].<br class="title-page-name"/>creating S4 object  ... done [0.00s].</pre>
<p class="mce-root">从Apriori算法的执行中创建的<kbd class="calibre11">rules</kbd>对象现在拥有从数据集中提取和挖掘的所有笑话关联。从输出中我们可以看到，总共提取了<kbd class="calibre11">78</kbd>个笑话关联。我们可以用下面一行代码来检查这些规则:</p>
<pre class="calibre16">inspect(rules)</pre>
<p class="mce-root">这将导致以下输出:</p>
<pre class="calibre16">     lhs          rhs   support confidence lift     count<br class="title-page-name"/>[1]  {j48}     =&gt; {j50} 0.5068  0.8376860  1.084523 2534<br class="title-page-name"/>[2]  {j56}     =&gt; {j36} 0.5036  0.8310231  1.105672 2518<br class="title-page-name"/>[3]  {j56}     =&gt; {j50} 0.5246  0.8656766  1.120762 2623<br class="title-page-name"/>[4]  {j42}     =&gt; {j50} 0.5150  0.8475971  1.097355 2575<br class="title-page-name"/>[5]  {j31}     =&gt; {j27} 0.5196  0.8255481  1.146276 2598</pre>
<p class="mce-root">显示的输出只是列表中全部78条规则中的5条。每个规则的阅读方式是左栏(<kbd class="calibre11">lhs</kbd>)显示的笑话引出右栏(<kbd class="calibre11">rhs</kbd>)的笑话；也就是说，喜欢规则的<kbd class="calibre11">lhs</kbd>上的笑话的用户通常倾向于喜欢<kbd class="calibre11">rhs</kbd>上显示的笑话。例如，在第一个规则中，如果用户喜欢笑话<kbd class="calibre11">j48</kbd>，很可能他们也会喜欢<kbd class="calibre11">j50</kbd>，因此值得向只看过笑话<kbd class="calibre11">j48</kbd>的用户推荐笑话<kbd class="calibre11">j50</kbd>。</p>
<p class="mce-root">虽然Apriori算法生成了几个规则，但是每个规则的强度都是由一个称为<kbd class="calibre11">lift</kbd>的度量来指定的。这是一个描述规则在业务环境中的价值的指标。注意，对于被认为是通用的规则，它必须具有小于或等于<kbd class="calibre11">1</kbd>的提升。lift值大于1表示在业务中实施更好的规则。下面几行代码的目的是将这些强规则放在列表的顶部:</p>
<pre class="calibre16"># converting the rules object into a dataframe<br class="title-page-name"/>rulesdf &lt;- as(rules, "data.frame")<br class="title-page-name"/># employing quick sort on the rules dataframe. lift and confidence are<br class="title-page-name"/># used as keys to sort the dataframe. - in the command indicates that we<br class="title-page-name"/># want lift and confidence to be sorted in descending order<br class="title-page-name"/>rulesdf[order(-rulesdf$lift, -rulesdf$confidence), ]</pre>
<p class="mce-root">这将导致以下输出:</p>
<p class="CDPAlignCenter1"><img class="aligncenter27" src="img/83ceb235-42e8-4278-8191-79cbceabdc2e.png"/></p>
<p class="mce-root">可以观察到，所示的输出只是规则输出的子集。第一个规则表明<kbd class="calibre11">j35</kbd>是可以推荐给已经阅读了笑话<kbd class="calibre11">j29</kbd>和<kbd class="calibre11">j50</kbd>的用户的笑话。</p>
<p class="mce-root">同样，我们可以编写一个脚本来搜索用户已经读过的所有笑话，并将其与规则的左侧匹配；如果找到匹配，则可以将规则的相应右侧推荐给用户作为笑话。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Content-based recommendation engine</title>
    <meta content="urn:uuid:715f2a86-adaf-48a1-98a4-3c219c63f667" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">基于内容的推荐引擎</h1>
                
            
            
                
<p class="mce-root">完全基于从客户那里收到的明确或隐含的反馈的推荐引擎被称为<strong class="calibre3">基于内容的推荐系统</strong>。显性反馈是客户通过填写关于偏好的调查或对感兴趣的笑话进行评级，或选择与笑话相关的时事通讯，或将笑话添加到观察列表等方式表达兴趣。隐式反馈更像是一种成熟的方法，客户访问一个页面，点击一个笑话链接，或者只是花时间阅读电子商务页面上的笑话评论。根据收到的反馈，向顾客推荐类似的笑话。可以注意到，基于内容的推荐没有考虑系统中其他客户的偏好和反馈；相反，它纯粹基于特定客户的个性化反馈。</p>
<p class="mce-root">在推荐过程中，系统将已经被客户正面评价的产品与客户尚未评价的产品进行识别，并寻找等同物。将与正面评价产品相似的产品推荐给客户。在这个模型中，客户的偏好和行为在增量微调推荐中起着主要作用——也就是说，对于每个推荐，并且基于客户是否对推荐做出响应，系统学习增量地推荐不同的推荐。下图说明了基于内容的推荐系统的工作原理:</p>
<p class="CDPAlignCenter1"><img class="aligncenter28" src="img/62443519-42f8-4de0-9d16-df39c9b9205d.png"/></p>
<p>基于内容的推荐系统的工作原理</p>
<p class="mce-root">在我们的Jester笑话数据集中，我们有用户对各种笑话给出的评级以及笑话本身的内容。记住<kbd class="calibre11">JesterJokes</kbd>字符向量包含了笑话中的文本。笑话中存在的文本之间的相似性可以被用作向用户推荐笑话的一种方法。假设是，如果一个人喜欢一个笑话中的内容，并且如果有另一个笑话的内容非常相似，那么推荐后一个笑话很可能会被用户喜欢。</p>
<p class="mce-root">在Jester笑话数据集中没有给出与笑话相关的附加元数据，但是这种元数据可以从笑话的内容中创建。例如，笑话的长度、名词的数量、笑话中出现的有趣术语的数量以及笑话的中心主题。处理文本不仅仅是一个推荐领域，还涉及到使用NLP技术。因为我们将在不同的章节中讨论NLP，所以我们在这里不做介绍。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Differentiating between ITCF and content-based recommendations</title>
    <meta content="urn:uuid:715f2a86-adaf-48a1-98a4-3c219c63f667" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">区分ITCF和基于内容的推荐</h1>
                
            
            
                
<p class="mce-root">基于项目的协作推荐和基于内容的推荐可能看起来是一样的。实际上，它们并不相同。让我们来谈谈不同之处。</p>
<p class="mce-root">ITCF完全基于用户项目排名。当我们计算项目之间的相似性时，我们不包括项目属性，而只是根据所有客户的评分计算项目的相似性。因此，项目之间的相似性是基于评级而不是项目本身的元数据来计算的。</p>
<p class="mce-root">在基于内容的推荐中，我们利用用户和商品的内容。通常，我们使用共享属性空间的内容来构建用户简档和项目简档。例如，对于一部电影，我们用电影中的演员和类型来表示它(例如，使用二进制编码)。对于用户档案，我们可以根据用户做同样的事情，比如一些演员/流派。则用户和项目的相似性可以使用例如余弦相似性来计算。这个余弦度量导致了这些建议。</p>
<p class="mce-root">基于内容的过滤根据分配给每个产品的标签来识别相似的产品。基于每个标签的术语频率和逆文档频率，为每个产品分配权重。在此之后，计算用户喜欢某个产品的概率，以便得出最终的推荐列表。</p>
<p class="mce-root">虽然基于内容的推荐系统非常高效和个性化，但这种模式存在一个固有的问题。我们用一个例子来了解一下基于内容推荐的过度专业化问题。</p>
<p class="mce-root">假设有以下五种电影类型:</p>
<ul class="calibre9">
<li class="calibre10">喜剧</li>
<li class="calibre10">惊悚片</li>
<li class="calibre10">科幻小说</li>
<li class="calibre10">行动</li>
<li class="calibre10">浪漫性</li>
</ul>
<p class="mce-root">有这样一个客户，杰克，他通常看恐怖片和科幻电影。基于这种偏好，基于内容的推荐引擎只会推荐与这些类型相关的电影，而不会推荐其他类别的电影。由于基于内容的推荐引擎仅仅依靠用户过去的行为和偏好来确定推荐，所以出现了这个问题。</p>
<p class="mce-root">与内容推荐系统不同，在ITCF推荐系统中，类似的产品根据顾客的积极偏好建立社区。因此，系统会生成客户可能喜欢的邻近产品的推荐。ITCF通过利用基于不同用户给它们的评分的项目之间的相关性来做到这一点，而协同过滤依靠用户之间过去的偏好或评分相关性，它甚至能够从客户的兴趣领域为类似产品生成推荐。如果产品不受欢迎，并且很少有用户给出反馈，这种技术会导致糟糕的预测。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Building a hybrid recommendation system for Jokes recommendations</title>
    <meta content="urn:uuid:715f2a86-adaf-48a1-98a4-3c219c63f667" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">构建笑话推荐的混合推荐系统</h1>
                
            
            
                
<p class="mce-root">我们看到基于内容的过滤和协同过滤都有各自的优点和缺点。为了克服这些问题，组织建立了结合两种或多种技术的推荐系统，它们被称为混合推荐模型。一个这样的例子是基于内容、IBCF、UBCF和基于模型的推荐引擎的组合。这考虑了有助于向用户做出最相关的推荐的所有可能的方面。下图显示了混合推荐引擎中遵循的示例方法:</p>
<p class="CDPAlignCenter1"><img class="aligncenter29" src="img/de76d7c8-e602-45d1-a149-fba5f673ac84.png"/></p>
<p>混合推荐引擎的示例方法</p>
<p class="mce-root">我们需要注意的是，实现混合推荐引擎没有标准的方法。为了综合这些建议，以下是一些建议的策略:</p>
<ul class="calibre9">
<li class="calibre10"><strong class="calibre1">投票</strong>:对各个推荐系统的推荐输出进行投票。</li>
<li class="calibre10"><strong class="calibre1">基于规则的选择</strong>:我们可以设计规则，建议对从单个推荐系统获得的输出推荐进行加权。在这种情况下，获得较高权重的推荐系统的输出将占主导地位，并对最终的推荐结果有更大的影响。</li>
<li class="calibre10"><strong class="calibre1">组合</strong>:来自所有推荐引擎的推荐被一起呈现。最终的推荐列表是从各个推荐系统获得的所有推荐输出的集合。</li>
<li class="calibre10"><strong class="calibre1">属性整合</strong>:从所有推荐系统中提取元数据，将其作为输入注入到另一个推荐系统中。</li>
</ul>
<p class="mce-root">同样，对一个问题起作用的可能对另一个问题不起作用，因此在提出最终的建议策略之前，需要单独测试这些策略。</p>
<p class="mce-root"><kbd class="calibre11">recommenderlab</kbd>库提供了<kbd class="calibre11">HybridRecommender</kbd>功能，允许用户一次对同一组数据训练多个推荐引擎，并组合预测。该函数有一个权重参数，该参数提供了一种方法来指定每个模型的权重，该权重将用于合并各个预测，以获得对未知数据的最终建议预测。实现一个基于混合推荐引擎的项目非常简单，与我们在基于项目的协同过滤或基于用户的协同过滤项目中学到的代码没有太大的不同。无论如何，让我们编写代码，为<kbd class="calibre11">Jester5k</kbd>数据集构建一个混合推荐引擎:</p>
<pre class="calibre16"># including the required libraries<br class="title-page-name"/>library(recommenderlab)<br class="title-page-name"/># accessing the Jester5k dataset that is a part of recommenderlab library<br class="title-page-name"/>data(Jester5k)<br class="title-page-name"/># split the data into the training and the test set<br class="title-page-name"/>Jester5k_es &lt;- evaluationScheme(Jester5k, method="split", train=0.8, given=20, goodRating=0)</pre>
<p class="mce-root">前面的代码是训练混合推荐器的代码。这就是它不同于我们已经建立的<kbd class="calibre11">ITCF</kbd>或<kbd class="calibre11">UBCF</kbd>推荐器的地方。我们可以从代码中观察到，我们使用了四种不同的推荐方法，它们将构成混合推荐器。让我们来讨论一下这些方法:</p>
<ul class="calibre9">
<li class="calibre10">热门推荐法只是把热门的段子(由收到的收视率决定)推荐给用户。</li>
<li class="calibre10">我们使用的第二种推荐方法是基于项目的协同过滤方法，该方法使用非归一化数据，但是通过余弦相似度来计算项目之间的距离。</li>
<li class="calibre10">对<kbd class="calibre11">Z-score</kbd>标准化数据进行基于用户的协同过滤，计算数据中用户之间的欧几里德距离。</li>
<li class="calibre10">向用户提供随机推荐的随机推荐方法。</li>
</ul>
<p class="mce-root">我们绝不认为这四种推荐方法的组合是解决这个问题的最佳方案。这个项目的目的是演示混合推荐器的实现。所涉及的方法的选择完全是随意的。在现实中，我们可能需要尝试多种组合来确定最佳的混合。混合分类器是使用以下代码构建的:</p>
<pre class="calibre16">#train a hybrid recommender model<br class="title-page-name"/>hybrid_recom &lt;- HybridRecommender(<br class="title-page-name"/>  Recommender(getData(Jester5k_es, "train"), method = "POPULAR"),<br class="title-page-name"/>  Recommender(getData(Jester5k_es, "train"), method="IBCF",<br class="title-page-name"/>              param=list(normalize = NULL, method="Cosine")),<br class="title-page-name"/>  Recommender(getData(Jester5k_es, "train"), method="UBCF",<br class="title-page-name"/>                          param=list(normalize = "Z-score",method="Euclidean")),<br class="title-page-name"/>  Recommender(getData(Jester5k_es, "train"), method = "RANDOM"),<br class="title-page-name"/>  weights = c(.2, .3, .3,.2)<br class="title-page-name"/>)<br class="title-page-name"/># Observe the model that is built<br class="title-page-name"/>print (getModel(hybrid_recom)</pre>
<p class="mce-root">这将导致以下输出:</p>
<pre class="calibre16">$recommender<br class="title-page-name"/>$recommender[[1]]<br class="title-page-name"/>Recommender of type ‘POPULAR’ for ‘realRatingMatrix’<br class="title-page-name"/>learned using 4000 users.<br class="title-page-name"/>$recommender[[2]]<br class="title-page-name"/>Recommender of type ‘IBCF’ for ‘realRatingMatrix’<br class="title-page-name"/>learned using 4000 users.<br class="title-page-name"/>$recommender[[3]]<br class="title-page-name"/>Recommender of type ‘UBCF’ for ‘realRatingMatrix’<br class="title-page-name"/>learned using 4000 users.<br class="title-page-name"/>$recommender[[4]]<br class="title-page-name"/>Recommender of type ‘RANDOM’ for ‘realRatingMatrix’<br class="title-page-name"/>learned using 4000 users.<br class="title-page-name"/>$weights<br class="title-page-name"/>[1] 0.2 0.3 0.3 0.2</pre>
<p class="mce-root">观察混合模型中的权重分配。我们看到，流行的和随机的推荐器各被分配了20%的权重，而前面混合的<kbd class="calibre11">ITCF</kbd>和<kbd class="calibre11">UBCF</kbd>方法各被分配了30%的权重。在构建混合推荐器时，设置权重并不是强制性的，在这种情况下，混合推荐器中涉及的每种方法被分配相等的权重。现在我们的模型已经准备好了，让我们用下面的代码进行预测并评估性能:</p>
<pre class="calibre16"># making predictions<br class="title-page-name"/>pred &lt;- predict(hybrid_recom, getData(Jester5k_es, "known"), type="ratings")<br class="title-page-name"/># # set the predictions that fall outside the valid range to the boundary values<br class="title-page-name"/>pred@data@x[pred@data@x[] &lt; -10] &lt;- -10<br class="title-page-name"/>pred@data@x[pred@data@x[] &gt; 10] &lt;- 10<br class="title-page-name"/># calculating performance measurements<br class="title-page-name"/>hybrid_recom_pred = calcPredictionAccuracy(pred, getData(Jester5k_es, "unknown"))<br class="title-page-name"/># printing the performance measurements<br class="title-page-name"/>library(knitr)<br class="title-page-name"/>print(kable(hybrid_recom_pred))</pre>
<p class="mce-root">这将导致以下输出:</p>
<pre class="calibre16">|     |         x|<br class="title-page-name"/>|:----|---------:|<br class="title-page-name"/>|RMSE |  4.468849|<br class="title-page-name"/>|MSE  | 19.970611|<br class="title-page-name"/>|MAE  |  3.493577|</pre>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Summary</title>
    <meta content="urn:uuid:715f2a86-adaf-48a1-98a4-3c219c63f667" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">摘要</h1>
                
            
            
                
<p class="mce-root">在这一章中，我们广泛使用了<kbd class="calibre11">recommenderlab</kbd>库来构建基于Jester笑话数据集的各种类型的笑话推荐引擎。我们还了解了这些方法背后的理论概念。</p>
<p class="mce-root">推荐系统是一个独立的ML领域。这个题目太大了，不可能在一章内涵盖。存在几种类型的推荐系统，它们可以应用于特定场景中的数据集。矩阵分解、奇异值分解近似、最受欢迎项目和SlopeOne是可以用来建立推荐系统的一些技术。这些技术超出了本章的范围，因为它们很少在商业环境中用于构建推荐系统，本章的目的是提供更流行的技术。对推荐引擎的进一步学习可以是探索和研究这些很少使用的技术，并将它们应用于现实世界的问题。</p>
<p class="mce-root">下一章将重点介绍NLP技术。我们将使用几种流行的技术在亚马逊产品评论上实现一个情感分析引擎。我们将探索分析文本的语义和句法方法，然后将它们应用于Amazon review语料库。我已经准备好翻过这一页，进入下一章。你呢？！</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>References</title>
    <meta content="urn:uuid:715f2a86-adaf-48a1-98a4-3c219c63f667" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">参考</h1>
                
            
            
                
<p class="mce-root">虽然<kbd class="calibre11">recommenderlab</kbd>库在R社区非常受欢迎，但这并不是构建推荐系统的唯一选择。下面是一些其他流行的库，您可以依赖它们来实现推荐引擎:</p>
<ul class="calibre9">
<li class="calibre10"><kbd class="calibre11">rrecsys</kbd>:有几个流行的推荐系统，比如全球/项目/用户平均基线，基于项目的KNN，FunkSVD，BPR，以及用于快速原型的加权ALS。更多信息请参考<a href="https://cran.r-project.org/web/packages/rrecsys/index.htmlImplementations" class="calibre8">https://cran . r-project . org/web/packages/rrecsys/index . html implementations</a>。</li>
<li class="calibre10"><kbd class="calibre11">recosystem</kbd>:用于使用矩阵分解的推荐系统的<kbd class="calibre11">libmf</kbd>库(<a href="http://www.csie.ntu.edu.tw/~cjlin/libmf/" class="calibre8">http://www.csie.ntu.edu.tw/~cjlin/libmf/</a>)的R包装器。它通常用于使用潜在空间中两个矩阵的乘积来逼近不完整矩阵。此任务的其他常见名称包括协作过滤、矩阵完成和矩阵恢复。该软件包支持高性能多核并行计算。</li>
<li class="calibre10"><kbd class="calibre11">rectools</kbd>:推荐系统的高级包，整合用户和项目协变量信息，包括并行计算的项目类别偏好，统计潜在因素模型的新变化，焦点组查找器，NMF，方差分析和余弦模型。</li>
</ul>


            

            
        
    </body>

</html>
</body></html>