<html><head/><body>
<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Predicting Employee Attrition Using Ensemble Models</title>
    <meta content="urn:uuid:715f2a86-adaf-48a1-98a4-3c219c63f667" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">使用集合模型预测员工流失</h1>
                
            
            
                
<p class="mce-root">如果你回顾了最近的机器学习竞赛，我相信你会做出的一个关键观察是，大多数竞赛中所有三个获奖作品的配方都包括非常好的特征工程，以及调整良好的集合模型。我从这一观察中得出的一个结论是，为了提供成功的机器学习解决方案，良好的特征工程和构建性能良好的模型是应该给予同等重视的两个领域。</p>
<p class="mce-root">虽然功能工程在大多数情况下依赖于构建模型的人的创造力和领域专业知识，但构建一个性能良好的模型是可以通过一种叫做<strong class="calibre3">集成</strong>的哲学来实现的。机器学习实践者经常使用集成技术来击败即使是性能最好的单个ML算法所产生的性能基准。在本章中，我们将了解ML这一激动人心的领域的以下主题:</p>
<ul class="calibre9">
<li class="calibre10">组装背后的哲学</li>
<li class="calibre10">了解损耗问题和数据集</li>
<li class="calibre10">性能基准测试的k近邻模型</li>
<li class="calibre10">制袋材料</li>
<li class="calibre10">随机森林随机化</li>
<li class="calibre10">助推</li>
<li class="calibre10">堆垛</li>
</ul>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Philosophy behind ensembling </title>
    <meta content="urn:uuid:715f2a86-adaf-48a1-98a4-3c219c63f667" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">组装背后的哲学</h1>
                
            
            
                
<p class="mce-root">在ML从业者中非常有名的集成，可以通过一个简单的真实世界的非ML例子很好地理解。</p>
<p class="mce-root">假设你申请了一个非常有名的公司的工作，你被通知去面试。仅仅根据面试官的一次面试，你是不可能被选中的。在大多数情况下，你会和几个面试官或者一个面试小组进行多轮面试。公司的期望是每个面试官都是某个领域的专家，并且面试官已经根据你在面试官专业领域的经验评估了你是否适合这份工作。当然，你对这份工作的选择取决于所有与你交谈过的面试官的综合反馈。该组织认为你会在工作中更成功，因为你的选择是基于多个专家做出的综合决定，而不是基于一个专家的决定，这可能会有一定的偏见。</p>
<p class="mce-root">现在，当我们谈到整合所有面试官的反馈时，可以通过几种方法进行整合:</p>
<ul class="calibre9">
<li class="calibre10"><strong class="calibre1">平均分</strong>:假设你的候选资格是基于你在面试中获得一个截止分数。假设你遇到了10个面试官，每个人都给你打了10分的最高分，这代表了面试官在他的专业领域对你的看法。现在，你的综合分数是由所有面试官给你的所有分数的简单平均值得出的。</li>
</ul>
<ul class="calibre9">
<li class="calibre10"><strong class="calibre1">多数投票</strong>:在这种情况下，没有每个面试官提供的实际分数(满分为10分)。然而，10位面试官中，有8位确认你非常适合这个职位。两位面试官对你的候选资格说不。大多数面试官对你的面试表现都很满意，所以你被选中了。</li>
<li class="calibre10"><strong class="calibre1">加权平均</strong>:让我们假设四位面试官都是一些小技能方面的专家，这些技能对你申请的工作来说是很有用的。这些并不是该职位必须具备的技能。你接受了所有10位面试官的面试，他们每个人都给了你满分。与平均法类似，在加权平均法中，你的面试最终分数是由所有面试官给出的分数的平均值得到的。</li>
</ul>
<p class="calibre23">但是，在计算最终分数时，并不是所有的分数都一视同仁。每个面试分数乘以一个权重，得到一个产品。将由此获得的所有乘积相加以获得最终得分。每次面试的权重是它测试的候选人技能的重要性和该技能对工作的重要性的函数。很明显，与必须拥有技能的<em xmlns:epub="http://www.idpf.org/2007/ops" class="calibre15">相比，拥有</em>技能的<em xmlns:epub="http://www.idpf.org/2007/ops" class="calibre15">在工作中的权重较低。现在，最终分数本质上代表了候选人拥有的必备技能的比例，这将对您的选择产生更大的影响。</em></p>
<p class="mce-root">类似于面试类比，ML中的集成也产生基于整合学习的模型。术语<strong class="calibre3">整合学习</strong>本质上表示通过应用若干ML算法获得的学习，或者是从作为大型数据集一部分的若干数据子集获得的学习。类似于访谈，通过应用集成技术学习多种模型。然而，通过将平均、多数投票或加权平均技术中的一种应用于由每个单独模型做出的单独预测，实现了关于预测的最终合并。应用集成技术和预测整合技术创建的模型通常被称为<strong class="calibre3">集成</strong>。</p>
<p class="mce-root">每个最大似然算法都是特殊的，并且有一种独特的方式来对基础训练数据进行建模。例如，k-最近邻算法通过计算数据集中元素之间的距离来学习；朴素贝叶斯通过计算属于特定类的数据中每个属性的概率来学习。可以使用不同的ML算法创建多个模型，并且可以通过组合几个ML算法的预测来进行预测。类似地，当数据集被分区以创建子集时，并且如果使用算法训练多个模型，每个模型专注于一个数据集，则每个模型非常专注，并且它专门学习它被训练的数据子集的特征。在这两种情况下，对于基于多种算法和多个数据子集的模型，当我们通过合并来组合多个模型的预测时，我们可以获得更好的预测，因为我们利用了集合中每个模型所具有的多种优势。否则，当使用单一模型进行预测时，这是无法实现的。</p>
<p class="mce-root">集成的关键是，当我们组合多个模型的预测时，会比只依赖一个模型进行预测获得更好的预测。这与我们一起做得更好的管理哲学没有什么不同，也就是所谓的<strong class="calibre3">协同</strong>！</p>
<p class="mce-root">既然我们理解了集成背后的核心理念，我们现在就准备探索不同类型的集成技术。然而，我们将通过在一个项目中实现它们来学习集合技术，以预测员工的流失。正如我们已经知道的，在构建任何ML项目之前，对问题和数据有一个深刻的理解是非常重要的。因此，在下一节中，我们首先重点了解手头的流失问题，然后研究与该问题相关的数据集，最后通过探索性数据分析(EDA)了解数据集的属性。我们在这一节中获得的关键见解来自一次性练习，并将适用于我们将在后面几节中应用的所有集成技术。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Getting started</title>
    <meta content="urn:uuid:715f2a86-adaf-48a1-98a4-3c219c63f667" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">入门指南</h1>
                
            
            
                
<p class="mce-root">要开始本节，您必须从GitHub链接下载本章代码的<kbd class="calibre11">WA_Fn-UseC_-HR-Employee-Attrition.csv</kbd>数据集。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Understanding the attrition problem and the dataset </title>
    <meta content="urn:uuid:715f2a86-adaf-48a1-98a4-3c219c63f667" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">了解损耗问题和数据集</h1>
                
            
            
                
<p class="mce-root">人力资源分析有助于解释组织数据。它找出数据中与人相关的趋势，并帮助人力资源部门采取适当的措施，以保持组织平稳运行和盈利。公司中的人员流失是人事经理和人力资源人员必须应对的复杂挑战之一。有趣的是，可以部署机器学习模型来预测潜在的流失情况，从而帮助适当的人力资源人员或人事经理采取必要的措施来留住员工。</p>
<p class="mce-root">在这一章中，我们将构建预测这种潜在损耗情况的ML集成。该项目使用的工作流失数据集是由IBM的数据科学家创建的虚拟数据集。<kbd class="calibre11">rsample</kbd>库包含了这个数据集，我们可以直接从库中使用这个数据集。</p>
<p class="mce-root">这是一个小型数据集，包含31个属性的1，470条记录。数据集的描述可通过以下代码获得:</p>
<pre class="calibre16">setwd("~/Desktop/chapter 2") <br class="title-page-name"/>library(rsample) <br class="title-page-name"/>data(attrition) <br class="title-page-name"/>str(attrition) <br class="title-page-name"/>mydata&lt;-attrition </pre>
<p class="mce-root">这将导致以下输出:</p>
<pre class="calibre16">'data.frame':1470 obs. of  31 variables: <br class="title-page-name"/> $ Age                     : int  41 49 37 33 27 32 59 30 38 36 ... <br class="title-page-name"/> $ Attrition               : Factor w/ 2 levels "No","Yes": 2 1 2 1 1 1 1 1 1 1 .... <br class="title-page-name"/> $ BusinessTravel          : Factor w/ 3 levels "Non-Travel","Travel_Frequently",..: 3 2 3 2 3 2 3 3 2 3 ... <br class="title-page-name"/> $ DailyRate               : int  1102 279 1373 1392 591 1005 1324 1358 216 1299 ... <br class="title-page-name"/> $ Department              : Factor w/ 3 levels "Human_Resources",..: 3 2 2 2 2 2 2 2 2 2 ... <br class="title-page-name"/> $ DistanceFromHome        : int  1 8 2 3 2 2 3 24 23 27 ... <br class="title-page-name"/> $ Education               : Ord.factor w/ 5 levels "Below_College"&lt;..: 2 1 2 4 1 2 3 1 3 3 ... <br class="title-page-name"/> $ EducationField          : Factor w/ 6 levels "Human_Resources",..: 2 2 5 2 4 2 4 2 2 4 ... <br class="title-page-name"/> $ EnvironmentSatisfaction : Ord.factor w/ 4 levels "Low"&lt;"Medium"&lt;..: 2 3 4 4 1 4 3 4 4 3 ... <br class="title-page-name"/> $ Gender                  : Factor w/ 2 levels "Female","Male": 1 2 2 1 2 2 1 2 2 2 ... <br class="title-page-name"/> $ HourlyRate              : int  94 61 92 56 40 79 81 67 44 94 ... <br class="title-page-name"/> $ JobInvolvement          : Ord.factor w/ 4 levels "Low"&lt;"Medium"&lt;..: 3 2 2 3 3 3 4 3 2 3 ... <br class="title-page-name"/> $ JobLevel                : int  2 2 1 1 1 1 1 1 3 2 ... <br class="title-page-name"/> $ JobRole                 : Factor w/ 9 levels "Healthcare_Representative",..: 8 7 3 7 3 3 3 3 5 1 ... <br class="title-page-name"/> $ JobSatisfaction         : Ord.factor w/ 4 levels "Low"&lt;"Medium"&lt;..: 4 2 3 3 2 4 1 3 3 3 ... <br class="title-page-name"/> $ MaritalStatus           : Factor w/ 3 levels "Divorced","Married",..: 3 2 3 2 2 3 2 1 3 2 ... <br class="title-page-name"/> $ MonthlyIncome           : int  5993 5130 2090 2909 3468 3068 2670 2693 9526 5237 ... <br class="title-page-name"/> $ MonthlyRate             : int  19479 24907 2396 23159 16632 11864 9964 13335 8787 16577 ... <br class="title-page-name"/> $ NumCompaniesWorked      : int  8 1 6 1 9 0 4 1 0 6 ... <br class="title-page-name"/> $ OverTime                : Factor w/ 2 levels "No","Yes": 2 1 2 2 1 1 2 1 1 1 ... <br class="title-page-name"/> $ PercentSalaryHike       : int  11 23 15 11 12 13 20 22 21 13 ... <br class="title-page-name"/> $ PerformanceRating       : Ord.factor w/ 4 levels "Low"&lt;"Good"&lt;"Excellent"&lt;..: 3 4 3 3 3 3 4 4 4 3 ... <br class="title-page-name"/> $ RelationshipSatisfaction: Ord.factor w/ 4 levels "Low"&lt;"Medium"&lt;..: 1 4 2 3 4 3 1 2 2 2 ... <br class="title-page-name"/> $ StockOptionLevel        : int  0 1 0 0 1 0 3 1 0 2 ... <br class="title-page-name"/> $ TotalWorkingYears       : int  8 10 7 8 6 8 12 1 10 17 ... <br class="title-page-name"/> $ TrainingTimesLastYear   : int  0 3 3 3 3 2 3 2 2 3 ... <br class="title-page-name"/> $ WorkLifeBalance         : Ord.factor w/ 4 levels "Bad"&lt;"Good"&lt;"Better"&lt;..: 1 3 3 3 3 2 2 3 3 2 ... <br class="title-page-name"/> $ YearsAtCompany          : int  6 10 0 8 2 7 1 1 9 7 ... <br class="title-page-name"/> $ YearsInCurrentRole      : int  4 7 0 7 2 7 0 0 7 7 ... <br class="title-page-name"/> $ YearsSinceLastPromotion : int  0 1 0 3 2 3 0 0 1 7 ... <br class="title-page-name"/> $ YearsWithCurrManager    : int  5 7 0 0 2 6 0 0 8 7 ... </pre>
<p class="mce-root">要查看数据集中的<kbd class="calibre11">Attrition</kbd>目标变量，请运行以下代码:</p>
<pre class="calibre16">table(mydata$Attrition) </pre>
<p class="mce-root">这将导致以下输出:</p>
<pre class="calibre16"> No   Yes  <br class="title-page-name"/>1233  237  </pre>
<p class="mce-root">在数据集中的1，470个观察值中，我们有1，233个样本(83.87%)是非损耗情况和237个损耗情况(16.12%)。显然，我们正在处理一个<em class="calibre15">类不平衡</em>数据集。</p>
<p class="mce-root">我们现在将使用下面的代码通过<kbd class="calibre11">corrplot</kbd>库可视化数据中高度相关的变量:</p>
<pre class="calibre16"># considering only the numeric variables in the dataset <br class="title-page-name"/>numeric_mydata &lt;- mydata[,c(1,4,6,7,10,11,13,14,15,17,19,20,21,24,25,26,28:35)] <br class="title-page-name"/># converting the target variable "yes" or "no" values into numeric <br class="title-page-name"/># it defaults to 1 and 2 however converting it into 0 and 1 to be consistent <br class="title-page-name"/>numeric_Attrition = as.numeric(mydata$Attrition)- 1 <br class="title-page-name"/># create a new data frame with numeric columns and numeric target  <br class="title-page-name"/>numeric_mydata = cbind(numeric_mydata, numeric_Attrition) <br class="title-page-name"/># loading the required library <br class="title-page-name"/>library(corrplot) <br class="title-page-name"/># creating correlation plot <br class="title-page-name"/>M &lt;- cor(numeric_mydata) <br class="title-page-name"/>corrplot(M, method="circle") </pre>
<p class="mce-root">这将导致以下输出:</p>
<p class="CDPAlignCenter1"><img class="aligncenter8" src="img/00693069-856f-49b3-b946-e3c7e53b1ac1.png"/></p>
<p class="mce-root">在前面的屏幕截图中，可以观察到单元格中较暗和较大的蓝色圆点表示构成单元格的相应行和列中的变量之间存在强相关性。独立变量之间的高度相关性表明数据中存在冗余特征。数据中存在高度相关特征的问题被称为<strong class="calibre3">多重共线性</strong>。如果我们要拟合一个回归模型，那么我们需要通过一些技术来处理数据中高度相关的变量，例如删除冗余特征，或者应用主成分分析或偏最小二乘回归，这可以直观地减少冗余特征。</p>
<p class="mce-root">我们从输出中推断出以下变量高度相关，如果我们要构建基于回归的模型，构建模型的人员需要考虑这些变量:</p>
<p class="mce-root"><kbd class="calibre11">JobLevel</kbd>-<kbd class="calibre11">MonthlyIncome</kbd>；<kbd class="calibre11">JobLevel</kbd>-<kbd class="calibre11">TotalWorkingYears</kbd>；<kbd class="calibre11">MonthlyIncome</kbd>-<kbd class="calibre11">TotalWorkingYears</kbd>；<kbd class="calibre11">PercentSalaryHike</kbd>-<kbd class="calibre11">PerformanceRating</kbd>；<kbd class="calibre11">YearsAtCompany</kbd>-<kbd class="calibre11">YearsInCurrentRole</kbd>；<kbd class="calibre11">YearsAtCompany</kbd>-<kbd class="calibre11">YearsWithCurrManager</kbd>；<kbd class="calibre11">YearsWithCurrManager</kbd> - <kbd class="calibre11">YearsInCurrentRole</kbd></p>
<p class="mce-root">现在，用因变量<kbd class="calibre11">Attrition</kbd>绘制各种自变量，以了解自变量对目标的影响:</p>
<pre class="calibre16">### Overtime vs Attiriton <br class="title-page-name"/>l &lt;- ggplot(mydata, aes(OverTime,fill = Attrition)) <br class="title-page-name"/>l &lt;- l + geom_histogram(stat="count") <br class="title-page-name"/><br class="title-page-name"/>tapply(as.numeric(mydata$Attrition) - 1 ,mydata$OverTime,mean) <br class="title-page-name"/><br class="title-page-name"/>No Yes<br class="title-page-name"/>0.104364326375712 0.305288461538462</pre>
<p class="mce-root">让我们运行以下命令来获得图形视图:</p>
<pre class="calibre16">print(l) </pre>
<p class="mce-root">上述命令会生成以下输出:</p>
<p class="CDPAlignCenter1"><img class="aligncenter9" src="img/bf9f27c2-82ba-4b9c-b71e-067888466d2b.png"/></p>
<p class="mce-root">在前面的输出中，可以观察到加班的员工比不加班的员工更容易流失:</p>
<p class="mce-root">让我们通过执行以下命令来计算员工的流失:</p>
<pre class="calibre16">### MaritalStatus vs Attiriton <br class="title-page-name"/>l &lt;- ggplot(mydata, aes(MaritalStatus,fill = Attrition)) <br class="title-page-name"/>l &lt;- l + geom_histogram(stat="count") <br class="title-page-name"/><br class="title-page-name"/>tapply(as.numeric(mydata$Attrition) - 1 ,mydata$MaritalStatus,mean) <br class="title-page-name"/>Divorced 0.100917431192661 <br class="title-page-name"/>Married 0.12481426448737 <br class="title-page-name"/>Single 0.25531914893617 </pre>
<p class="mce-root">让我们运行以下命令来获得图形视图:</p>
<pre class="calibre16">print(l) </pre>
<p class="mce-root">上述命令会生成以下输出:</p>
<p class="CDPAlignCenter1"><img class="aligncenter10" src="img/b1940a98-684a-401c-b1dc-2f2c8abece69.png"/></p>
<p class="mce-root">在前面的输出中，可以观察到单身员工的流失率更高:</p>
<pre class="calibre16">###JobRole vs Attrition <br class="title-page-name"/>l &lt;- ggplot(mydata, aes(JobRole,fill = Attrition)) <br class="title-page-name"/>l &lt;- l + geom_histogram(stat="count") <br class="title-page-name"/> <br class="title-page-name"/>tapply(as.numeric(mydata$Attrition) - 1 ,mydata$JobRole,mean) <br class="title-page-name"/><br class="title-page-name"/>Healthcare Representative    Human Resources <br class="title-page-name"/>               0.06870229    0.23076923 <br class="title-page-name"/>    Laboratory Technician    Manager <br class="title-page-name"/>               0.23938224    0.04901961 <br class="title-page-name"/>   Manufacturing Director    Research Director <br class="title-page-name"/>               0.06896552    0.02500000 <br class="title-page-name"/>       Research Scientist    Sales Executive <br class="title-page-name"/>               0.16095890    0.17484663 <br class="title-page-name"/>     Sales Representative <br class="title-page-name"/>               0.39759036 <br class="title-page-name"/>mean(as.numeric(mydata$Attrition) - 1) <br class="title-page-name"/>[1] 0.161224489795918 </pre>
<p class="mce-root">执行以下命令以获得相同的图形表示:</p>
<pre class="calibre16">print(l)</pre>
<p class="mce-root">看看运行前面的命令生成的以下输出:</p>
<p class="CDPAlignCenter1"><img class="aligncenter11" src="img/8469586f-dac2-4e9f-a5d3-229b91cb749c.png"/></p>
<p class="mce-root">在前面的输出中，可以观察到从事人力资源工作角色的实验室技术人员、销售代表和员工比其他组织角色有更多的流失。</p>
<p class="mce-root">让我们执行以下命令来检查员工的性别对归因的影响:</p>
<pre class="calibre16">###Gender vs Attrition <br class="title-page-name"/>l &lt;- ggplot(mydata, aes(Gender,fill = Attrition)) <br class="title-page-name"/>l &lt;- l + geom_histogram(stat="count") <br class="title-page-name"/> <br class="title-page-name"/>tapply(as.numeric(mydata$Attrition) - 1 ,mydata$Gender,mean) <br class="title-page-name"/><br class="title-page-name"/>Female 0.147959183673469 <br class="title-page-name"/>Male 0.170068027210884 </pre>
<p class="mce-root">运行以下命令以获取相同的图形表示:</p>
<pre class="calibre16">print(l)</pre>
<p class="mce-root">这将导致以下输出:</p>
<p class="CDPAlignCenter1"><img class="aligncenter12" src="img/8f15307f-e66a-43cf-bd52-de8ad0dd65ae.png"/></p>
<p class="mce-root">在前面的输出中，您可以看到员工的性别对自然减员没有任何影响，换句话说，所有性别的自然减员都是一样的。</p>
<p class="mce-root">让我们通过执行以下命令来计算各个字段中雇员的属性:</p>
<pre class="calibre16">###EducationField vs Attrition el &lt;- ggplot(mydata, aes(EducationField,fill = Attrition)) <br class="title-page-name"/>l &lt;- l + geom_histogram(stat="count") <br class="title-page-name"/> <br class="title-page-name"/>tapply(as.numeric(mydata$Attrition) - 1 ,mydata$EducationField,mean) <br class="title-page-name"/><br class="title-page-name"/>Human Resources    Life Sciences    Marketing <br class="title-page-name"/>       0.2592593    0.1468647        0.2201258 <br class="title-page-name"/>         Medical   Other Technical  Degree <br class="title-page-name"/>       0.1357759    0.1341463        0.2424242</pre>
<p class="mce-root">让我们执行以下命令来获得图形表示:</p>
<pre class="calibre16">print(l)</pre>
<p class="mce-root">这将导致以下输出:</p>
<p class="CDPAlignCenter1"><img class="aligncenter13" src="img/84dd7b0e-ee6a-49fe-aea9-c1e7b1d26f00.png"/></p>
<p class="mce-root">看一下上图，我们可以得出结论，拥有技术学位或人力资源学位的员工流失更多。看一下下面的代码:</p>
<pre class="calibre16">###Department vs Attrition <br class="title-page-name"/>l &lt;- ggplot(mydata, aes(Department,fill = Attrition)) <br class="title-page-name"/>l &lt;- l + geom_histogram(stat="count") <br class="title-page-name"/><br class="title-page-name"/>tapply(as.numeric(mydata$Attrition) - 1 ,mydata$Department,mean) <br class="title-page-name"/>Human Resources  Research &amp; Development  Sales <br class="title-page-name"/>   0.1904762       0.1383975              0.2062780 </pre>
<p class="mce-root">让我们执行下面的命令来检查各个部门的归属:</p>
<pre class="calibre16">print(l) </pre>
<p class="mce-root">这将导致以下输出:</p>
<p class="CDPAlignCenter1"><img class="aligncenter14" src="img/5bd5d2df-9dd3-4e4c-aaae-0a027f4d7718.png"/></p>
<p class="mce-root">看前面的图表，我们可以得出结论，与销售和人力资源部门相比，研发部门的人员流失较少。看一下下面的代码:</p>
<pre class="calibre16">###BusinessTravel vs Attrition <br class="title-page-name"/>l &lt;- ggplot(mydata, aes(BusinessTravel,fill = Attrition)) <br class="title-page-name"/>l &lt;- l + geom_histogram(stat="count") <br class="title-page-name"/><br class="title-page-name"/>tapply(as.numeric(mydata$Attrition) - 1 ,mydata$BusinessTravel,mean) <br class="title-page-name"/> Non-Travel   Travel_Frequently   Travel_Rarely <br class="title-page-name"/>  0.0800000    0.2490975           0.1495686</pre>
<p class="mce-root">执行以下命令以获得相同的图形表示:</p>
<pre class="calibre16">print(l) </pre>
<p class="mce-root">这将导致以下输出:</p>
<p class="CDPAlignCenter1"><img class="aligncenter15" src="img/1283f61e-dd01-4435-98da-9c8ca191a61a.png"/></p>
<p class="mce-root">看一下上图，我们可以得出这样的结论:与不出差或很少出差的员工相比，经常出差的员工更容易流失。</p>
<p class="mce-root">让我们通过执行以下命令来计算员工的加班时间:</p>
<pre class="calibre16">### x=Overtime, y= Age, z = MaritalStatus , t = Attrition <br class="title-page-name"/>ggplot(mydata, aes(OverTime, Age)) +   <br class="title-page-name"/>  facet_grid(.~MaritalStatus) + <br class="title-page-name"/>  geom_jitter(aes(color = Attrition),alpha = 0.4) +   <br class="title-page-name"/>  ggtitle("x=Overtime, y= Age, z = MaritalStatus , t = Attrition") +   <br class="title-page-name"/>  theme_light() </pre>
<p class="mce-root">这将导致以下输出:</p>
<p class="CDPAlignCenter1"><img class="aligncenter16" src="img/ee279cb3-4192-40e4-b608-81e10487a03b.png"/></p>
<p class="mce-root">查看上图，我们可以得出结论，年轻的员工(年龄&lt; 35 ) and are single, but work overtime, are more prone to attrition: </p>
<pre class="calibre16">### MonthlyIncome vs. Age, by  color = Attrition <br class="title-page-name"/>ggplot(mydata, aes(MonthlyIncome, Age, color = Attrition)) +  <br class="title-page-name"/>  geom_jitter() + <br class="title-page-name"/>  ggtitle("MonthlyIncome vs. Age, by  color = Attrition ") + <br class="title-page-name"/>  theme_light() </pre>
<p class="mce-root">This will result in the following output:</p>
<p class="CDPAlignCenter1"><img class="aligncenter17" src="img/5d910b21-22e9-4301-a211-b4ae423cff62.png"/></p>
<p class="mce-root">查看上图，我们可以得出结论，年轻员工(年龄&lt; 30岁)的流失率更高，大多数流失率出现在收入低于7，500美元的员工中。</p>
<p class="mce-root">尽管我们已经了解了手头数据的许多重要细节，但实际上还有更多需要探索和学习。然而，为了进入下一步，我们在这个EDA步骤停止。应该注意的是，在现实世界中，数据不会像我们在这个损耗数据集中看到的那样非常干净。例如，数据中可能会有缺失值；在这种情况下，我们将进行缺失值插补。幸运的是，我们有一个无可挑剔的数据集，为我们创建模型做好了准备，无需进行任何数据清理或额外的预处理。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>K-nearest neighbors model for benchmarking the performance</title>
    <meta content="urn:uuid:715f2a86-adaf-48a1-98a4-3c219c63f667" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">性能基准测试的k近邻模型</h1>
                
            
            
                
<p class="mce-root">在这一节中，我们将实现<strong class="calibre3">k-nearest neighbors</strong>(<strong class="calibre3">KNN</strong>)算法，在我们的IBM流失数据集上构建一个模型。当然，我们已经从EDA中意识到，我们手头的数据集中存在类不平衡问题。然而，我们现在不会针对类不平衡来处理数据集，因为这本身就是一个完整的领域，并且在该领域中有几种技术可用，因此不在本章所讨论的ML集成主题的范围之内。现在，我们将按原样考虑数据集并构建ML模型。此外，对于类别不平衡数据集，Kappa或精度和召回或接收器工作特性曲线下的面积(AUROC)是可以使用的适当指标。然而，为了简单起见，我们将使用<em class="calibre15">精确度</em>作为性能指标。我们将采用重复10次的10重交叉验证，以有助于模型性能测量。现在，让我们使用KNN算法构建我们的流失预测模型，如下所示:</p>
<pre class="calibre16"># Load the necessary libraries <br class="title-page-name"/># doMC is a library that enables R to use multiple cores available on the sysem thereby supporting multiprocessing.  <br class="title-page-name"/>library(doMC) <br class="title-page-name"/># registerDoMC command instructs R to use the specified number of cores to execute the code. In this case, we ask R to use 4 cores available on the system <br class="title-page-name"/>registerDoMC(cores=4) <br class="title-page-name"/># caret library has the ml algorithms and other routines such as cross validation etc.  <br class="title-page-name"/>library(caret) <br class="title-page-name"/># Setting the working directory where the dataset is located <br class="title-page-name"/>setwd("~/Desktop/chapter 2") <br class="title-page-name"/># Reading the csv file into R variable called mydata <br class="title-page-name"/>mydata &lt;- read.csv("WA_Fn-UseC_-HR-Employee-Attrition.csv") <br class="title-page-name"/>#Removing the non-discriminatory features (as identified during EDA) from the dataset  <br class="title-page-name"/>mydata$EmployeeNumber=mydata$Over18=mydata$EmployeeCount=mydata$StandardHours = NULL <br class="title-page-name"/># setting the seed prior to model building ensures reproducibility of the results obtained <br class="title-page-name"/>set.seed(10000) <br class="title-page-name"/># setting the train control parameters specifying gold standard 10 fold cross validation  repeated 10 times <br class="title-page-name"/>fitControl = trainControl(method="repeatedcv", number=10,repeats=10) <br class="title-page-name"/>###creating a model on the data. Observe that we specified Attrition as the target and that model should learn from rest of the variables. We specified mydata as the dataset to learn. We pass the train control parameters and specify that knn algorithm need to be used to build the model. K can be of any length - we specified 20 as parameter which means the train command will search through 20 different random k values and finally retains the model that produces the best performance measurements. The final model is stored as caretmodel <br class="title-page-name"/>caretmodel = train(Attrition~., data=mydata, trControl=fitControl, method = "knn", tuneLength = 20) <br class="title-page-name"/># We output the model object to the console  <br class="title-page-name"/>caretmodel </pre>
<p class="mce-root">这将导致以下输出:</p>
<pre class="calibre16">k-Nearest Neighbors  <br class="title-page-name"/>1470 samples <br class="title-page-name"/>  30 predictors <br class="title-page-name"/>   2 classes: 'No', 'Yes'  <br class="title-page-name"/>No pre-processing <br class="title-page-name"/>Resampling: Cross-Validated (10 fold, repeated 10 times)  <br class="title-page-name"/>Summary of sample sizes: 1323, 1323, 1324, 1323, 1324, 1322, ...  <br class="title-page-name"/>Resampling results across tuning parameters: <br class="title-page-name"/>  k   Accuracy   Kappa        <br class="title-page-name"/>   5  0.8216447  0.0902934591 <br class="title-page-name"/>   7  0.8349033  0.0929511324 <br class="title-page-name"/>   9  0.8374198  0.0752842114 <br class="title-page-name"/>  11  0.8410920  0.0687849122 <br class="title-page-name"/>  13  0.8406861  0.0459679081 <br class="title-page-name"/>  15  0.8406875  0.0337742424 <br class="title-page-name"/>  17  0.8400748  0.0315670261 <br class="title-page-name"/>  19  0.8402770  0.0245499585 <br class="title-page-name"/>  21  0.8398721  0.0143638854 <br class="title-page-name"/>  23  0.8393945  0.0084393721 <br class="title-page-name"/>  25  0.8391891  0.0063246624 <br class="title-page-name"/>  27  0.8389174  0.0013913143 <br class="title-page-name"/>  29  0.8388503  0.0007113939 <br class="title-page-name"/>  31  0.8387818  0.0000000000 <br class="title-page-name"/>  33  0.8387818  0.0000000000 <br class="title-page-name"/>  35  0.8387818  0.0000000000 <br class="title-page-name"/>  37  0.8387818  0.0000000000 <br class="title-page-name"/>  39  0.8387818  0.0000000000 <br class="title-page-name"/>  41  0.8387818  0.0000000000 <br class="title-page-name"/>  43  0.8387818  0.0000000000 <br class="title-page-name"/>Accuracy was used to select the optimal model using the largest value. <br class="title-page-name"/>The final value used for the model was k = 11. </pre>
<p class="mce-root">我们可以从模型输出中看到，最佳执行模型是在<kbd class="calibre11">k</kbd> <kbd class="calibre11">= 11</kbd>时，并且我们使用这个<kbd class="calibre11">k</kbd>值获得了84%的准确度。在这一章的其余部分，当用几种组合技术进行实验时，我们将检验从KNN获得的84%的准确率是否会被打破。</p>
<p class="mce-root">在现实的项目构建情况下，仅仅识别最佳超参数是不够的。需要在具有最佳超参数的完整数据集上训练模型，并且需要保存该模型以供将来使用。我们将在本节的剩余部分回顾这些步骤。</p>
<p class="mce-root">在这种情况下，<kbd class="calibre11">caretmodel</kbd>对象已经有了用<kbd class="calibre11">k = 11</kbd>训练的模型，因此我们不试图用最佳超参数重新训练模型。要检查最终模型，您可以使用代码查询模型对象:</p>
<pre class="calibre16">caretmodel$finalModel </pre>
<p class="mce-root">这将导致以下输出:</p>
<pre class="calibre16">11-nearest neighbor model <br class="title-page-name"/>Training set outcome distribution: <br class="title-page-name"/>  No  Yes  <br class="title-page-name"/>1233  237  </pre>
<p class="mce-root">下一步是将您的最佳模型保存到一个文件中，以便我们可以在以后加载它们，并根据看不见的数据进行预测。可以使用<kbd class="calibre11">saveRDS</kbd> R命令将模型保存到本地目录:</p>
<pre class="calibre16"> # save the model to disk <br class="title-page-name"/>saveRDS(caretmodel, "production_model.rds") </pre>
<p class="mce-root">在这种情况下，<kbd class="calibre11">caretmodel</kbd>被保存为工作目录中的<kbd class="calibre11">production_model.rds</kbd>。该模型现在被序列化为一个文件，可以随时加载，并可用于对看不见的数据进行评分。加载和评分可以通过下面的R代码实现:</p>
<pre class="calibre16"># Set the working directory to the directory where the saved .rds file is located  <br class="title-page-name"/>setwd("~/Desktop/chapter 2") <br class="title-page-name"/>#Load the model  <br class="title-page-name"/>loaded_model &lt;- readRDS("production_model.rds") </pre>
<pre class="calibre16">#Using the loaded model to make predictions on unseen data <br class="title-page-name"/>final_predictions &lt;- predict(loaded_model, unseen_data) </pre>
<p>请注意，在通过<kbd class="calibre24">predict</kbd>命令划线之前，需要读取<kbd class="calibre24">unseen_data</kbd>。</p>
<p class="mce-root">在整个数据集上训练最终模型的代码部分，保存模型，在需要时从文件中重新加载它，并对看不见的数据进行集体评分，这被称为构建ML生产化管道。这个流水线对于所有的ML模型保持相同，而不管模型是使用单一算法还是使用集成技术来构建的。因此，在后面的部分中，当我们实现各种集成技术时，我们将不会涉及生产化管道，而只是停留在通过重复10次的10重交叉验证来获得性能度量。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Bagging</title>
    <meta content="urn:uuid:715f2a86-adaf-48a1-98a4-3c219c63f667" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">制袋材料</h1>
                
            
            
                
<div><p class="mce-root">Bootstrap aggregation或<strong class="calibre3"> bagging </strong>是最早被ML实践社区广泛采用的集成技术。打包涉及从单个数据集创建多个不同的模型。为了理解bagging，理解称为bootstrapping的重要统计技术是很重要的。</p>
</div>
<div><p class="mce-root">引导包括创建数据集的多个随机子集。有可能在多个子集中获得相同的数据样本，这被称为<strong class="calibre3">替换引导</strong>。这种方法的优点是，由于使用整个数据集，在估计数量时会出现标准误差。这个技巧可以用一个例子来更好地解释。</p>
</div>
<div><p class="mce-root">假设您有一个1000个样本的小数据集。根据样本，要求您计算样本所代表的总体的平均值。现在，一种直接的方法是通过下面的公式:</p>
</div>
<div><p class="CDPAlignCenter1"><img class="fm-editor-equation" src="img/1ffab3de-df4f-489c-9a25-be38913f6d33.png"/></p>
</div>
<div><p class="mce-root">由于这是一个小样本，我们在估计总体平均值时可能会有误差。这种误差可以通过采用带替换的自举采样来减小。在该技术中，我们创建了数据集的10个子集，其中每个数据集包含100个项目。一个数据项可以在一个子集中被随机表示多次，并且一个数据项在一个数据子集内以及跨子集被表示的次数没有限制。现在，我们取每个数据子集中样本的平均值，因此，我们得到10个不同的平均值。使用所有这些收集的平均值，我们用以下公式估计总体的平均值:</p>
</div>
<div><p class="CDPAlignCenter1"><img class="fm-editor-equation1" src="img/ab180bc6-78d6-497a-ae47-abeabca5e347.png"/></p>
</div>
<div><p class="mce-root">现在，我们对平均值有了更好的估计，因为我们已经外推了小样本，以随机生成代表原始总体的多个样本。</p>
</div>
<div><p class="mce-root">在装袋中，实际的训练数据集通过具有替换的自举采样被分成多个袋。假设我们最终得到了<em class="calibre15"> n </em>个袋子，当对这些袋子中的每一个应用ML算法时，我们得到了<em class="calibre15"> n </em>个不同的模型。每个型号都专注于一款包袋。当谈到对新的看不见的数据进行预测时，这些<em class="calibre15"> n </em>模型中的每一个都对数据进行独立的预测。通过组合所有<em class="calibre15"> n </em>个模型的观察预测，得到观察的最终预测。在分类的情况下，采用投票方式，以多数为最终预测。对于回归，所有模型预测的平均值被视为最终预测。</p>
</div>
<div><p class="mce-root">基于决策树的算法，比如<strong class="calibre3">分类和回归树</strong> ( <strong class="calibre3"> CART </strong>)，都是不稳定的学习器。原因是训练数据集中的微小变化会严重影响所创建的模型。模型的改变实质上意味着预测也会改变。打包是一种非常有效的技术，可以处理对数据变化的高度敏感性。由于我们可以在数据集的子集上构建多个决策树模型，然后根据每个模型的预测得出最终预测，因此数据变化的影响会被抵消，或者不会被显著感受到。</p>
</div>
<div><p class="mce-root">在数据子集上建立多个模型的一个直观问题是<strong class="calibre3">过度拟合</strong>。然而，这可以通过在不对节点进行任何修剪的情况下生长深树来克服。</p>
</div>
<div><p class="mce-root">bagging的缺点是，与使用独立的ML算法构建模型相比，它需要更长的时间来构建模型。这是显而易见的，因为多个模型是在bagging中构建的，而不是一个单一的模型，并且构建这些多个模型需要时间。</p>
</div>
<p class="mce-root">现在，让我们实现R代码以实现bagging系综，并将获得的性能与从KNN获得的性能进行比较。然后，我们将探索装袋方法的工作机制。</p>
<p class="mce-root"><kbd class="calibre11">caret</kbd>库提供了用任何独立的ML算法实现bagging的框架。<kbd class="calibre11">ldaBag</kbd>、<kbd class="calibre11">plsBag</kbd>、<kbd class="calibre11">nbBag</kbd>、<kbd class="calibre11">treeBag</kbd>、<kbd class="calibre11">ctreeBag</kbd>、<kbd class="calibre11">svmBag</kbd>和<kbd class="calibre11">nnetBag</kbd>是caret中提供的一些示例方法。在本节中，我们将使用三种不同的<kbd class="calibre11">caret</kbd>方法进行装袋，如<kbd class="calibre11">treebag</kbd>、<kbd class="calibre11">svmbag</kbd>和<kbd class="calibre11">nbbag</kbd>。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Bagged classification and regression trees (treeBag) implementation</title>
    <meta content="urn:uuid:715f2a86-adaf-48a1-98a4-3c219c63f667" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">袋装分类和回归树(treeBag)实现</h1>
                
            
            
                
<p class="mce-root">首先，加载基本库并注册并行处理的内核数量:</p>
<pre class="calibre16">library(doMC) <br class="title-page-name"/>registerDoMC(cores = 4)  <br class="title-page-name"/>library(caret) <br class="title-page-name"/>#setting the random seed for replication <br class="title-page-name"/>set.seed(1234) <br class="title-page-name"/># setting the working directory where the data is located <br class="title-page-name"/>setwd("~/Desktop/chapter 2") <br class="title-page-name"/># reading the data <br class="title-page-name"/>mydata &lt;- read.csv("WA_Fn-UseC_-HR-Employee-Attrition.csv") <br class="title-page-name"/>#removing the non-discriminatory features identified during EDA <br class="title-page-name"/>mydata$EmployeeNumber=mydata$Over18=mydata$EmployeeCount=mydata$StandardHours = NULL <br class="title-page-name"/>#setting up cross-validation <br class="title-page-name"/>cvcontrol &lt;- trainControl(method="repeatedcv", repeats=10, number = 10, allowParallel=TRUE) <br class="title-page-name"/># model creation with treebag , observe that the number of bags is set as 10 <br class="title-page-name"/>train.bagg &lt;- train(Attrition ~ ., data=mydata, method="treebag",B=10, trControl=cvcontrol, importance=TRUE) <br class="title-page-name"/>train.bagg </pre>
<p class="mce-root">这将导致以下输出:</p>
<pre class="calibre16">Bagged CART  <br class="title-page-name"/>1470 samples <br class="title-page-name"/>  30 predictors <br class="title-page-name"/>   2 classes: 'No', 'Yes'  <br class="title-page-name"/>No pre-processing <br class="title-page-name"/>Resampling: Cross-Validated (10 fold, repeated 10 times)  <br class="title-page-name"/>Summary of sample sizes: 1324, 1323, 1323, 1322, 1323, 1322, ...  <br class="title-page-name"/>Resampling results: <br class="title-page-name"/>  Accuracy  Kappa     <br class="title-page-name"/>  0.854478  0.2971994 </pre>
<p class="mce-root">我们可以看到，与使用KNN算法获得的84%的准确度相比，我们获得了更好的85.4%的准确度。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Support vector machine bagging (SVMBag) implementation</title>
    <meta content="urn:uuid:715f2a86-adaf-48a1-98a4-3c219c63f667" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">支持向量机装袋(SVMBag)实现</h1>
                
            
            
                
<p class="mce-root">在SVMBag和NBBag实现中，加载库、注册多处理、设置工作目录、从工作目录中读取数据、从数据中删除非歧视性特征以及设置交叉验证参数的步骤也是相同的。因此，我们不会在SVMBag或NBBag代码中重复这些步骤。相反，我们将重点讨论特定于SVMBag或NBBag的代码:</p>
<pre class="calibre16"># Setting up SVM predict function as the default svmBag$pred function has some code issue <br class="title-page-name"/>svm.predict &lt;- function (object, x) <br class="title-page-name"/>{ <br class="title-page-name"/> if (is.character(lev(object))) { <br class="title-page-name"/>    out &lt;- predict(object, as.matrix(x), type = "probabilities") <br class="title-page-name"/>    colnames(out) &lt;- lev(object) <br class="title-page-name"/>    rownames(out) &lt;- NULL <br class="title-page-name"/>  } <br class="title-page-name"/>  else out &lt;- predict(object, as.matrix(x))[, 1] <br class="title-page-name"/>  out <br class="title-page-name"/>} <br class="title-page-name"/># setting up parameters to build svm bagging model <br class="title-page-name"/>bagctrl &lt;- bagControl(fit = svmBag$fit, <br class="title-page-name"/>                      predict = svm.predict , <br class="title-page-name"/>                      aggregate = svmBag$aggregate) <br class="title-page-name"/># fit the bagged svm model <br class="title-page-name"/>set.seed(300) <br class="title-page-name"/>svmbag &lt;- train(Attrition ~ ., data = mydata, method="bag",trControl = cvcontrol, bagControl = bagctrl,allowParallel = TRUE) <br class="title-page-name"/># printing the model results <br class="title-page-name"/>svmbag </pre>
<div><p class="mce-root">这将导致以下输出:</p>
</div>
<div><pre class="calibre16">Bagged Model  <br class="title-page-name"/><br class="title-page-name"/>1470 samples <br class="title-page-name"/>  30 predictors <br class="title-page-name"/>   2 classes: 'No', 'Yes'  <br class="title-page-name"/><br class="title-page-name"/>No pre-processing <br class="title-page-name"/>Resampling: Cross-Validated (10 fold, repeated 10 times)  <br class="title-page-name"/>Summary of sample sizes: 1324, 1324, 1323, 1323, 1323, 1323, ...  <br class="title-page-name"/>Resampling results: <br class="title-page-name"/>  Accuracy   Kappa     <br class="title-page-name"/>  0.8777721  0.4749657 <br class="title-page-name"/><br class="title-page-name"/>Tuning parameter 'vars' was held constant at a value of 44 </pre></div>
<div><p class="mce-root">您将会看到，我们达到了87.7%的准确率，远远高于KNN模型84%的准确率。</p>
</div>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Naive Bayes (nbBag) bagging implementation</title>
    <meta content="urn:uuid:715f2a86-adaf-48a1-98a4-3c219c63f667" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">朴素贝叶斯装袋实现</h1>
                
            
            
                
<p class="mce-root">我们现在将通过执行以下代码来实现<kbd class="calibre11">nbBag</kbd>:</p>
<pre class="calibre16"># setting up parameters to build svm bagging model <br class="title-page-name"/>bagctrl &lt;- bagControl(fit = nbBag$fit, <br class="title-page-name"/>                      predict = nbBag$pred , <br class="title-page-name"/>                      aggregate = nbBag$aggregate) <br class="title-page-name"/># fit the bagged nb model <br class="title-page-name"/>set.seed(300) <br class="title-page-name"/>nbbag &lt;- train(Attrition ~ ., data = mydata, method="bag", trControl = cvcontrol, bagControl = bagctrl) <br class="title-page-name"/># printing the model results <br class="title-page-name"/>nbbag </pre>
<div><p class="mce-root">这将导致以下输出:</p>
</div>
<div><pre class="calibre16">Bagged Model  <br class="title-page-name"/><br class="title-page-name"/>1470 samples <br class="title-page-name"/>  30 predictors <br class="title-page-name"/>   2 classes: 'No', 'Yes'  <br class="title-page-name"/><br class="title-page-name"/>No pre-processing <br class="title-page-name"/>Resampling: Cross-Validated (10 fold, repeated 10 times)  <br class="title-page-name"/>Summary of sample sizes: 1324, 1324, 1323, 1323, 1323, 1323, ...  <br class="title-page-name"/>Resampling results: <br class="title-page-name"/><br class="title-page-name"/>  Accuracy   Kappa      <br class="title-page-name"/>  0.8389878  0.00206872 <br class="title-page-name"/><br class="title-page-name"/>Tuning parameter 'vars' was held constant at a value of 44 </pre></div>
<div><p class="mce-root">我们看到，在这种情况下，我们只实现了83.89%的准确性，这比KNN模型的84%的性能稍差。</p>
</div>
<div><p class="mce-root">虽然我们只展示了三个用于装袋的<kbd class="calibre11">caret</kbd>方法的例子，但是实现其他方法的代码是一样的。代码中唯一需要的改变是替换<kbd class="calibre11">bagControl</kbd>中的<kbd class="calibre11">fit</kbd>、<kbd class="calibre11">predict</kbd>和<kbd class="calibre11">aggregate</kbd>参数。例如，为了用神经网络算法实现bagging，我们需要如下定义<kbd class="calibre11">bagControl</kbd>:</p>
</div>
<div><pre class="calibre16">bagControl(fit = nnetBag$fit, predict = nnetBag$pred , aggregate = nnetBag$aggregate) </pre></div>
<div><p class="mce-root">需要注意的是，在R中需要有一个合适的库来让<kbd class="calibre11">caret</kbd>运行这些方法，否则会导致错误。例如，<kbd class="calibre11">nbBag</kbd>要求在执行代码之前在系统上安装<kbd class="calibre11">klaR</kbd>库。同样，<kbd class="calibre11">ctreebag</kbd>函数需要安装<kbd class="calibre11">party</kbd>包。用户需要先检查系统上适当库的可用性，然后再将其用于<kbd class="calibre11">caret</kbd>装袋。</p>
</div>
<div><p class="mce-root">我们现在对通过装袋技术实现项目有了一个了解。下一小节介绍装袋的基本工作机制。这将有助于明确bagging在内部对我们的数据集做了什么，从而产生比独立模型性能更好的性能测量。</p>
</div>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Randomization with random forests</title>
    <meta content="urn:uuid:715f2a86-adaf-48a1-98a4-3c219c63f667" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">随机森林随机化</h1>
                
            
            
                
<div><div><p class="mce-root">正如我们在装袋中看到的，我们制作了许多袋子，每个模型都在这些袋子上进行训练。每个包都由实际数据集的子集组成，但是每个包中的特征或变量的数量保持不变。换句话说，我们在bagging中执行的是数据集行的子集化。</p>
</div>
<div><p class="mce-root">在随机森林中，当我们通过对行进行子集化来从数据集创建包时，我们还对需要包含在每个包中的要素(列)进行子集化。</p>
</div>
<div><p class="mce-root">假设您的数据集中有1000个包含20个要素的观测值。我们可以创建20个包，其中每个包有100个观察值(这是可能的，因为有替换的引导)和五个特征。现在有20个模特接受训练，每个模特只能看到分配给她的包。基于问题是回归问题还是分类问题的事实，通过投票或平均得到最终预测。</p>
</div>
<div><p class="mce-root">bagging和random forests之间的另一个关键区别是用于构建模型的ML算法。在bagging中，可以使用任何ML算法来创建模型，但是随机森林模型是专门使用CART构建的。</p>
</div>
<p class="mce-root">随机森林建模是另一种非常流行的机器学习算法。这是一种已经多次证明自己是性能最好的算法之一，尽管它应用于噪声数据集。对于一个了解引导的人来说，理解随机森林是一件轻而易举的事情。</p>
</div>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Implementing an attrition prediction model with random forests</title>
    <meta content="urn:uuid:715f2a86-adaf-48a1-98a4-3c219c63f667" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">使用随机森林实现损耗预测模型</h1>
                
            
            
                
<p class="mce-root">让我们通过执行以下代码，通过随机森林建模获得我们的损耗模型:</p>
<div><pre class="calibre16"># loading required libraries and registering multiple cores to enable parallel processing <br class="title-page-name"/>library(doMC) <br class="title-page-name"/>library(caret) <br class="title-page-name"/>registerDoMC(cores=4) <br class="title-page-name"/># setting the working directory and reading the dataset <br class="title-page-name"/>setwd("~/Desktop/chapter 2") <br class="title-page-name"/>mydata &lt;- read.csv("WA_Fn-UseC_-HR-Employee-Attrition.csv") <br class="title-page-name"/># removing the non-discriminatory features from the dataset as identified during EDA step <br class="title-page-name"/>mydata$EmployeeNumber=mydata$Over18=mydata$EmployeeCount=mydata$StandardHours = NULL <br class="title-page-name"/># setting the seed for reproducibility <br class="title-page-name"/>set.seed(10000) <br class="title-page-name"/># setting the cross validation parameters <br class="title-page-name"/>fitControl = trainControl(method="repeatedcv", number=10,repeats=10) <br class="title-page-name"/># creating the caret model with random forest algorithm <br class="title-page-name"/>caretmodel = train(Attrition~., data=mydata, method="rf", trControl=fitControl, verbose=F) <br class="title-page-name"/># printing the model summary <br class="title-page-name"/>caretmodel </pre></div>
<div><p class="mce-root">这将导致以下输出:</p>
</div>
<div><pre class="calibre16">Random Forest  <br class="title-page-name"/><br class="title-page-name"/>1470 samples <br class="title-page-name"/>  30 predictors <br class="title-page-name"/>   2 classes: 'No', 'Yes'  <br class="title-page-name"/><br class="title-page-name"/>No pre-processing <br class="title-page-name"/>Resampling: Cross-Validated (10 fold, repeated 10 times)  <br class="title-page-name"/>Summary of sample sizes: 1323, 1323, 1324, 1323, 1324, 1322, ...  <br class="title-page-name"/>Resampling results across tuning parameters: <br class="title-page-name"/><br class="title-page-name"/>  mtry  Accuracy   Kappa     <br class="title-page-name"/>   2    0.8485765  0.1014859 <br class="title-page-name"/>  23    0.8608271  0.2876406 <br class="title-page-name"/>  44    0.8572929  0.2923997 <br class="title-page-name"/><br class="title-page-name"/>Accuracy was used to select the optimal model using the largest value. <br class="title-page-name"/>The final value used for the model was mtry = 23. </pre></div>
<div><p class="mce-root">我们看到，与KNN的84%相比，最佳随机森林模型达到了更好的86%的准确率。</p>
</div>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Boosting </title>
    <meta content="urn:uuid:715f2a86-adaf-48a1-98a4-3c219c63f667" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">助推</h1>
                
            
            
                
<div><div><p class="mce-root">弱学习器是一种性能相对较差的算法——通常，弱学习器获得的准确度只是高于概率。人们经常观察到，弱学习者在计算上很简单。决策树桩或1R算法是弱学习者的一些例子。强化将弱学习者转化为强学习者。这实质上意味着boosting不是一种进行预测的算法，但它与底层的弱ML算法一起工作以获得更好的性能。</p>
</div>
<div><p class="mce-root">boosting模型是在数据子集上学习的一系列模型，类似于bagging集成技术。区别在于数据子集的创建。与bagging不同，用于模型训练的所有数据子集不是在训练开始之前创建的。相反，boosting使用ML算法构建第一个模型，对整个数据集进行预测。现在，有一些错误分类的实例是第二个模型使用的子集。第二个模型只从第一个模型的输出中筛选出的这个错误分类的数据集学习。</p>
<p class="mce-root">第二个模型的错误分类实例成为第三个模型的输入。重复建立模型的过程，直到满足停止标准。对未知数据集中某个观测值的最终预测是通过对该特定未知观测值的所有模型的预测进行平均或投票得出的。</p>
</div>
<div><p class="mce-root">boosting算法家族中的各种算法之间存在细微的差异，但是我们不打算详细讨论它们，因为本章的目的是获得对ML系综的一般理解，而不是获得对各种boosting算法的深入了解。</p>
</div>
<div><p class="mce-root">在获得更好性能的同时，测量是boosting集成的最大优势；模型可解释性困难、较高的计算时间和模型过度拟合是boosting遇到的一些问题。当然，这些问题可以通过使用专门的技术来解决。</p>
</div>
<p class="mce-root">Boosting算法无疑是超级受欢迎的，据观察，许多Kaggle和类似比赛的获胜者都在使用它。有许多可用的增强算法，例如<strong class="calibre3">梯度增强机器</strong> ( <strong class="calibre3"> GBMs </strong>)、<strong class="calibre3">自适应增强</strong> ( <strong class="calibre3"> AdaBoost </strong>)、梯度树增强、<strong class="calibre3">极端梯度增强</strong> ( <strong class="calibre3"> XGBoost </strong>)和<strong class="calibre3">轻度梯度增强机器</strong> ( <strong class="calibre3"> LightGBM </strong>)。在本节中，我们将学习两种最流行的boosting算法的理论和实现，如GBMs和XGBoost。在学习boosting的理论概念及其优缺点之前，让我们首先开始关注如何使用GBMs和XGBoost实现流失预测模型。</p>
</div>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>The GBM implementation</title>
    <meta content="urn:uuid:715f2a86-adaf-48a1-98a4-3c219c63f667" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">GBM实施</h1>
                
            
            
                
<p class="mce-root">让我们用GBMs实现流失预测模型:</p>
<div><pre class="calibre16"># loading the essential libraries and registering the cores for multiprocessing <br class="title-page-name"/>library(doMC) <br class="title-page-name"/>library(mlbench) <br class="title-page-name"/>library(gbm) <br class="title-page-name"/>library(caret) <br class="title-page-name"/>registerDoMC(cores=4) <br class="title-page-name"/># setting the working directory and reading the dataset <br class="title-page-name"/>setwd("~/Desktop/chapter 2") <br class="title-page-name"/>mydata &lt;- read.csv("WA_Fn-UseC_-HR-Employee-Attrition.csv") <br class="title-page-name"/># removing the non-discriminatory features as identified by EDA step <br class="title-page-name"/>mydata$EmployeeNumber=mydata$Over18=mydata$EmployeeCount=mydata$StandardHours = NULL <br class="title-page-name"/># converting the target attrition feild to numeric as gbm model expects all numeric feilds in the dataset <br class="title-page-name"/>mydata$Attrition = as.numeric(mydata$Attrition) <br class="title-page-name"/># forcing the attrition column values to be 0 and 1 instead of 1 and 2 <br class="title-page-name"/>mydata = transform(mydata, Attrition=Attrition-1) <br class="title-page-name"/># running the gbm model with 10 fold cross validation to identify the number of trees to build - hyper parameter tuning <br class="title-page-name"/>gbm.model = gbm(Attrition~., data=mydata, shrinkage=0.01, distribution = 'bernoulli', cv.folds=10, n.trees=3000, verbose=F) <br class="title-page-name"/># identifying and printing the value of hyper parameter identified through the tuning above <br class="title-page-name"/>best.iter = gbm.perf(gbm.model, method="cv") <br class="title-page-name"/>print(best.iter) <br class="title-page-name"/># setting the seed for reproducibility <br class="title-page-name"/>set.seed(123) <br class="title-page-name"/># creating a copy of the dataset <br class="title-page-name"/>mydata1=mydata <br class="title-page-name"/># converting target to a factor <br class="title-page-name"/>mydata1$Attrition=as.factor(mydata1$Attrition) <br class="title-page-name"/># setting up cross validation controls <br class="title-page-name"/>fitControl = trainControl(method="repeatedcv", number=10,repeats=10) <br class="title-page-name"/># runing the gbm model in tandem with caret  <br class="title-page-name"/>caretmodel = train(Attrition~., data=mydata1, method="gbm", distribution="bernoulli",  trControl=fitControl, verbose=F, tuneGrid=data.frame(.n.trees=best.iter, .shrinkage=0.01, .interaction.depth=1, .n.minobsinnode=1)) <br class="title-page-name"/># printing the model summary <br class="title-page-name"/>print(caretmodel) </pre></div>
<div><p class="mce-root">这将导致以下输出:</p>
</div>
<div><pre class="calibre16">2623 <br class="title-page-name"/>Stochastic Gradient Boosting  <br class="title-page-name"/><br class="title-page-name"/>1470 samples <br class="title-page-name"/>  30 predictors <br class="title-page-name"/>   2 classes: '0', '1'  <br class="title-page-name"/><br class="title-page-name"/>No pre-processing <br class="title-page-name"/>Resampling: Cross-Validated (10 fold, repeated 10 times)  <br class="title-page-name"/>Summary of sample sizes: 1323, 1323, 1323, 1322, 1323, 1323, ...  <br class="title-page-name"/>Resampling results: <br class="title-page-name"/>  Accuracy   Kappa     <br class="title-page-name"/>  0.8771472  0.4094991 <br class="title-page-name"/>Tuning parameter 'n.trees' was held constant at a value of 2623 <br class="title-page-name"/>Tuning parameter 'shrinkage' was held constant at a value of 0.01 <br class="title-page-name"/>Tuning parameter 'n.minobsinnode' was held constant at a value of 1 </pre></div>
<div><p class="mce-root">您将会看到，使用GBM模型，我们已经实现了87%以上的准确性，与KNN的84%相比，这是一个更好的准确性。</p>
</div>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Building attrition prediction model with XGBoost</title>
    <meta content="urn:uuid:715f2a86-adaf-48a1-98a4-3c219c63f667" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">用XGBoost构建流失预测模型</h1>
                
            
            
                
<p class="mce-root">现在，让我们用XGBoost实现流失预测模型:</p>
<div><pre class="calibre16"># loading the required libraries and registering the cores for multiprocessing <br class="title-page-name"/>library(doMC) <br class="title-page-name"/>library(xgboost) <br class="title-page-name"/>library(caret) <br class="title-page-name"/>registerDoMC(cores=4) <br class="title-page-name"/># setting the working directory and loading the dataset <br class="title-page-name"/>setwd("~/Desktop/chapter 2") <br class="title-page-name"/>mydata &lt;- read.csv("WA_Fn-UseC_-HR-Employee-Attrition.csv") <br class="title-page-name"/># removing the non-discriminatory features from the dataset as identified in EDA step <br class="title-page-name"/>mydata$EmployeeNumber=mydata$Over18=mydata$EmployeeCount=mydata$StandardHours = NULL <br class="title-page-name"/># setting up cross validation parameters <br class="title-page-name"/>ControlParamteres &lt;- trainControl(method = "repeatedcv",number = 10, repeats=10, savePredictions = TRUE, classProbs = TRUE) <br class="title-page-name"/># setting up hyper parameters grid to tune   <br class="title-page-name"/>parametersGrid &lt;-  expand.grid(eta = 0.1, colsample_bytree=c(0.5,0.7), max_depth=c(3,6),nrounds=100, gamma=1, min_child_weight=2,subsample=0.5) <br class="title-page-name"/># printing the parameters grid to get an intuition <br class="title-page-name"/>print(parametersGrid) <br class="title-page-name"/># xgboost model building <br class="title-page-name"/>modelxgboost &lt;- train(Attrition~., data = mydata, method = "xgbTree", trControl = ControlParamteres, tuneGrid=parametersGrid) <br class="title-page-name"/># printing the model summary <br class="title-page-name"/>print(modelxgboost) </pre></div>
<div><p class="mce-root">这将导致以下输出:</p>
<p class="CDPAlignCenter1"><img class="aligncenter18" src="img/d37882b4-f89b-42d7-a2d2-69f6c208a1fc.png"/></p>
</div>
<div><pre class="calibre16">eXtreme Gradient Boosting  <br class="title-page-name"/>1470 samples <br class="title-page-name"/>  30 predictors <br class="title-page-name"/>   2 classes: 'No', 'Yes'  <br class="title-page-name"/><br class="title-page-name"/>No pre-processing <br class="title-page-name"/>Resampling: Cross-Validated (10 fold, repeated 10 times)  <br class="title-page-name"/>Summary of sample sizes: 1323, 1323, 1322, 1323, 1323, 1322, ...  <br class="title-page-name"/>Resampling results across tuning parameters: <br class="title-page-name"/><br class="title-page-name"/>  max_depth  colsample_bytree  Accuracy   Kappa     <br class="title-page-name"/>  3          0.5               0.8737458  0.3802840 <br class="title-page-name"/>  3          0.7               0.8734728  0.3845053 <br class="title-page-name"/>  6          0.5               0.8730674  0.3840938 <br class="title-page-name"/>  6          0.7               0.8732589  0.3920721 <br class="title-page-name"/><br class="title-page-name"/>Tuning parameter 'nrounds' was held constant at a value of 100 <br class="title-page-name"/>Tuning parameter 'min_child_weight' was held constant at a value of 2 <br class="title-page-name"/>Tuning parameter 'subsample' was held constant at a value of 0.5 <br class="title-page-name"/>Accuracy was used to select the optimal model using the largest value. <br class="title-page-name"/>The final values used for the model were nrounds = 100, max_depth = 3, eta = 0.1, gamma = 1, colsample_bytree = 0.5, min_child_weight = 2 and subsample = 0.5. </pre></div>
<div><p class="mce-root">同样，我们观察到，使用XGBoost模型，我们已经实现了87%以上的准确性，与使用KNN实现的84%相比，这是一个更好的准确性。</p>
</div>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Stacking </title>
    <meta content="urn:uuid:715f2a86-adaf-48a1-98a4-3c219c63f667" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">堆垛</h1>
                
            
            
                
<div><p class="mce-root">在迄今为止我们所了解的所有集合中，我们已经以特定的方式操纵了数据集，并公开了用于模型构建的数据子集。然而，在堆叠中，我们不会对数据集做任何事情；相反，我们将应用一种不同的技术，包括使用多种ML算法。在堆叠中，我们使用各种ML算法构建多个模型。每种算法都拥有一种独特的学习数据特征的方式，最终的堆叠模型间接地结合了所有这些独特的学习方式。正如我们在其他类型的集成中所做的那样，堆叠通过投票或平均的方式获得最终预测，从而获得几个ML算法的组合能力。</p>
</div>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Building attrition prediction model with stacking</title>
    <meta content="urn:uuid:715f2a86-adaf-48a1-98a4-3c219c63f667" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">用叠加法建立磨损预测模型</h1>
                
            
            
                
<p class="mce-root">让我们建立一个使用堆叠的流失预测模型:</p>
<div><pre class="calibre16"># loading the required libraries and registering the cpu cores for multiprocessing <br class="title-page-name"/>library(doMC) <br class="title-page-name"/>library(caret) <br class="title-page-name"/>library(caretEnsemble) <br class="title-page-name"/>registerDoMC(cores=4) <br class="title-page-name"/># setting the working directory and loading the dataset <br class="title-page-name"/>setwd("~/Desktop/chapter 2") <br class="title-page-name"/>mydata &lt;- read.csv("WA_Fn-UseC_-HR-Employee-Attrition.csv") <br class="title-page-name"/># removing the non-discriminatory features from the dataset as identified in EDA step <br class="title-page-name"/>mydata$EmployeeNumber=mydata$Over18=mydata$EmployeeCount=mydata$StandardHours = NULL <br class="title-page-name"/># setting up control paramaters for cross validation <br class="title-page-name"/>control &lt;- trainControl(method="repeatedcv", number=10, repeats=10, savePredictions=TRUE, classProbs=TRUE) <br class="title-page-name"/># declaring the ML algorithms to use in stacking <br class="title-page-name"/>algorithmList &lt;- c('C5.0', 'nb', 'glm', 'knn', 'svmRadial') <br class="title-page-name"/># setting the seed to ensure reproducibility of the results <br class="title-page-name"/>set.seed(10000) <br class="title-page-name"/># creating the stacking model <br class="title-page-name"/>models &lt;- caretList(Attrition~., data=mydata, trControl=control, methodList=algorithmList) <br class="title-page-name"/># obtaining the stacking model results and printing them <br class="title-page-name"/>results &lt;- resamples(models) <br class="title-page-name"/>summary(results) </pre></div>
<div><p class="mce-root">这将导致以下输出:</p>
</div>
<div><pre class="calibre16">summary.resamples(object = results) <br class="title-page-name"/><br class="title-page-name"/>Models: C5.0, nb, glm, knn, svmRadial  <br class="title-page-name"/>Number of resamples: 100  <br class="title-page-name"/><br class="title-page-name"/>Accuracy  <br class="title-page-name"/>               Min.   1st Qu.    Median      Mean   3rd Qu.      Max. NA's <br class="title-page-name"/>C5.0      0.8082192 0.8493151 0.8639456 0.8625833 0.8775510 0.9054054    0 <br class="title-page-name"/>nb        0.8367347 0.8367347 0.8378378 0.8387821 0.8424658 0.8435374    0 <br class="title-page-name"/>glm       0.8299320 0.8639456 0.8775510 0.8790444 0.8911565 0.9387755    0 <br class="title-page-name"/>knn       0.8027211 0.8299320 0.8367347 0.8370763 0.8438017 0.8630137    0 <br class="title-page-name"/>svmRadial 0.8287671 0.8648649 0.8775510 0.8790467 0.8911565 0.9319728    0 <br class="title-page-name"/><br class="title-page-name"/>Kappa  Min.          1st Qu.     Median     Mean   3rd Qu.      Max.  NA's <br class="title-page-name"/>C5.0   0.03992485 0.29828006 0.37227344 0.3678459 0.4495049 0.6112590    0 <br class="title-page-name"/>nb     0.00000000 0.00000000 0.00000000 0.0000000 0.0000000 0.0000000    0 <br class="title-page-name"/>glm    0.26690604 0.39925723 0.47859218 0.4673756 0.5218094 0.7455280    0 <br class="title-page-name"/>knn   -0.05965697 0.02599388 0.06782465 0.0756081 0.1320451 0.2431312    0 <br class="title-page-name"/>svmRadial 0.24565 0.38667527 0.44195662 0.4497538 0.5192393 0.7423764    0 <br class="title-page-name"/><br class="title-page-name"/># Identifying the correlation between results <br class="title-page-name"/>modelCor(results) </pre></div>
<p class="mce-root">这将导致以下输出:</p>
<p class="CDPAlignCenter1"><img class="aligncenter19" src="img/6659bd76-cb08-42b4-9b50-2fb804feba66.png"/></p>
<p class="mce-root">我们可以从相关表结果中看到，没有一个单独的ML算法预测是高度相关的。高度相关的结果意味着算法产生了非常相似的预测。与接受单个预测所能获得的收益相比，组合非常相似的预测可能不会真正产生显著的收益。在这种特定情况下，我们可以观察到没有一个算法预测是高度相关的，因此我们可以直接进入堆叠预测的下一步:</p>
<pre class="calibre16"># Setting up the cross validation control parameters for stacking the predictions from individual ML algorithms <br class="title-page-name"/>stackControl &lt;- trainControl(method="repeatedcv", number=10, repeats=10, savePredictions=TRUE, classProbs=TRUE) <br class="title-page-name"/># stacking the predictions of individual ML algorithms using generalized linear model <br class="title-page-name"/>stack.glm &lt;- caretStack(models, method="glm", trControl=stackControl) <br class="title-page-name"/># printing the stacked final results <br class="title-page-name"/>print(stack.glm) </pre>
<p class="mce-root">这将导致以下输出:</p>
<pre class="calibre16">A glm ensemble of 2 base models: C5.0, nb, glm, knn, svmRadial <br class="title-page-name"/>Ensemble results: <br class="title-page-name"/>Generalized Linear Model  <br class="title-page-name"/>14700 samples <br class="title-page-name"/>    5 predictors <br class="title-page-name"/>    2 classes: 'No', 'Yes'  <br class="title-page-name"/>No pre-processing <br class="title-page-name"/>Resampling: Cross-Validated (10 fold, repeated 10 times)  <br class="title-page-name"/>Summary of sample sizes: 13230, 13230, 13230, 13230, 13230, 13230, ...  <br class="title-page-name"/>Resampling results: <br class="title-page-name"/>  Accuracy   Kappa     <br class="title-page-name"/>  0.8844966  0.4869556 </pre>
<p class="mce-root">基于GLM的叠加，我们有88%的准确率。现在，让我们检查使用随机森林建模而不是GLM来堆叠五种最大似然算法中每一种算法对观测值的单个预测的效果:</p>
<pre class="calibre16"># stacking the predictions of individual ML algorithms using random forest <br class="title-page-name"/>stack.rf &lt;- caretStack(models, method="rf", trControl=stackControl) <br class="title-page-name"/># printing the summary of rf based stacking <br class="title-page-name"/>print(stack.rf) </pre>
<p class="mce-root">这将导致以下输出:</p>
<pre class="calibre16">A rf ensemble of 2 base models: C5.0, nb, glm, knn, svmRadial <br class="title-page-name"/>Ensemble results: <br class="title-page-name"/>Random Forest  <br class="title-page-name"/>14700 samples <br class="title-page-name"/>    5 predictors <br class="title-page-name"/>    2 classes: 'No', 'Yes'  <br class="title-page-name"/>No pre-processing <br class="title-page-name"/>Resampling: Cross-Validated (10 fold, repeated 10 times)  <br class="title-page-name"/>Summary of sample sizes: 13230, 13230, 13230, 13230, 13230, 13230, ...  <br class="title-page-name"/>Resampling results across tuning parameters: <br class="title-page-name"/>  mtry  Accuracy   Kappa     <br class="title-page-name"/>  2     0.9122041  0.6268108 <br class="title-page-name"/>  3     0.9133605  0.6334885 <br class="title-page-name"/>  5     0.9132925  0.6342740 <br class="title-page-name"/>Accuracy was used to select the optimal model using the largest value.<br class="title-page-name"/>The final value used for the model was mtry = 3. </pre>
<p class="mce-root">我们看到，不需要太多的努力，我们就可以通过叠加预测达到91%的准确率。现在，我们来探讨一下堆叠的工作原理。</p>
<p class="mce-root">最后，我们发现了各种可以为我们提供性能更好的模型的集成技术。然而，在结束这一章之前，有几件事我们需要注意。</p>
<p>在r中实现ML模型并不只有一种方法。例如，可以使用<kbd class="calibre24">ipred</kbd>库中可用的函数来实现bagging，而不是像我们在本章中那样使用<kbd class="calibre24">caret</kbd>。我们应该意识到，超参数调整是模型构建的重要组成部分，有助于获得最佳性能的模型。超参数的数量和这些超参数的可接受值根据我们打算使用的库而变化。这就是我们在本章构建的模型中较少关注超参数调整的原因。然而，通读库文档以理解可以用库函数调优的超参数是非常重要的。在大多数情况下，在模型中引入超参数调整可以显著提高模型的性能。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Summary</title>
    <meta content="urn:uuid:715f2a86-adaf-48a1-98a4-3c219c63f667" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">摘要</h1>
                
            
            
                
<p class="mce-root">回想一下，我们使用类别不平衡数据集来构建流失模型。在建模之前使用技术来解决类不平衡是获得更好的模型性能度量的另一个关键方面。我们使用装袋、随机化、增强和堆叠来实现和预测流失模型。仅通过使用模型中现成的功能，我们就能够实现91%的准确率。特征工程是ML模型中不可忽视的一个重要方面。这可能是进一步提高模型性能的另一条途径。</p>
<div><p class="mce-root">在下一章中，我们将通过构建个性化推荐引擎来探索推荐产品或内容的秘方。我准备实施一个推荐笑话的项目。翻到下一章继续学习之旅。</p>
</div>


            

            
        
    </body>

</html>
</body></html>