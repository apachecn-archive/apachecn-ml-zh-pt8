<html><head/><body>
<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Credit Card Fraud Detection Using Autoencoders</title>
    <meta content="urn:uuid:715f2a86-adaf-48a1-98a4-3c219c63f667" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">使用自动编码器的信用卡欺诈检测</h1>
                
            
            
                
<p class="mce-root">众所周知，欺诈管理对于银行和金融公司来说是一个非常棘手的问题。事实证明，信用卡欺诈对公司来说尤其难以打击。芯片和PIN等技术是可用的，并且已经被大多数信用卡系统供应商使用，如Visa和MasterCard。然而，现有技术无法100%遏制信用卡欺诈。不幸的是，骗子想出了更新的网络钓鱼方法来获取信用卡用户的密码。此外，设备，如skimmers使窃取信用卡数据易如反掌！</p>
<p class="mce-root">尽管存在一些打击信用卡欺诈的技术能力，<em class="calibre15">覆盖全球支付系统的领先出版物尼尔森报告</em>估计，信用卡欺诈将在2020年飙升至320亿美元(<a href="https://nilsonreport.com/upload/content_promo/The_Nilson_Report_10-17-2017.pdf" class="calibre8">https://尼尔森报告. some上传/内容_推广/The _尼尔森报告_10-17-2017.pdf </a>)。从估计损失的角度来看，这比可口可乐(20亿美元)、沃伦巴菲特的伯克希尔哈撒韦(240亿美元)和摩根大通(235亿美元)等公司最近公布的利润还要多！</p>
<p class="mce-root">虽然信用卡芯片技术提供公司一直在投入巨资推进反信用卡欺诈的技术，但在本章中，我们将研究机器学习是否能帮助解决信用卡欺诈问题，以及能在多大程度上帮助解决这一问题。在本章中，我们将讨论以下主题:</p>
<ul class="calibre9">
<li class="calibre10">机器学习在信用卡欺诈检测中的应用</li>
<li class="calibre10">自动编码器和各种类型</li>
<li class="calibre10">信用卡欺诈数据集</li>
<li class="calibre10">用R中的H2O图书馆构建AEs</li>
<li class="calibre10">用于信用卡欺诈检测的自动编码器的实现</li>
</ul>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Machine learning in credit card fraud detection</title>
    <meta content="urn:uuid:715f2a86-adaf-48a1-98a4-3c219c63f667" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">机器学习在信用卡欺诈检测中的应用</h1>
                
            
            
                
<p class="mce-root">欺诈检测的任务通常归结为异常值检测，即验证数据集以发现数据中的潜在异常。传统上，这项任务被视为手动任务，风险专家手动检查所有交易。尽管有一个技术层，但它完全是基于一个规则库，扫描每笔交易，然后将入围的可疑交易发送给人工审查，以对交易做出最终决定。然而，这个系统有一些主要的缺点:</p>
<ul class="calibre9">
<li class="calibre10">组织需要为人工审查人员提供大量欺诈管理预算。</li>
<li class="calibre10">需要广泛的培训来培训作为人工审查人员工作的雇员。</li>
<li class="calibre10">培训人员手动审查交易既耗时又昂贵。</li>
<li class="calibre10">即使是训练有素的人工审查人员也会带有一定的偏见，从而使整个审查系统不准确。</li>
<li class="calibre10">人工审核增加了完成交易所需的时间。客户可能会对通过信用卡交易所需的长时间等待感到沮丧。这可能会影响客户的忠诚度。</li>
<li class="calibre10">人工审查可能会产生误报。误报不仅会影响流程中的销售，还会影响客户产生的终身价值。</li>
</ul>
<p class="mce-root">幸运的是，随着<strong class="calibre3">机器学习</strong> ( <strong class="calibre3"> ML </strong>)、<strong class="calibre3">人工智能</strong> ( <strong class="calibre3"> AI </strong>)以及深度学习的兴起，很大程度上使得人工信用卡交易审核流程的自动化变得可行。这不仅节省了大量的劳动力，还能更好地检测信用卡欺诈，否则会因人工审查人员的偏见而受到影响。</p>
<p class="mce-root">基于ML的欺诈检测策略通常可以使用监督ML和非监督ML技术来实现。</p>
<p class="mce-root">当标记为<strong class="calibre3">真实</strong>或<strong class="calibre3">欺诈</strong>的大量交易数据可用时，通常使用监督式ML模型。在标记的数据集上训练模型，然后使用结果模型将任何新的信用卡交易分类到两个可能的类别中的一个。</p>
<p class="mce-root">对于大多数组织来说，问题是标记数据不可用，或者很少标记数据可用。这使得监督学习模型不太可行。这就是无监督模型发挥作用的地方。它们旨在发现交易中的异常行为，并且不需要明确的预先标记的数据来识别异常行为。无监督欺诈检测的一般思想是通过识别不符合多数的交易来检测行为异常。</p>
<p class="mce-root">另一件要记住的事情是，欺诈事件很少发生，不像真实交易那样普遍。由于欺诈的罕见性，在与信用卡欺诈相关的数据集中可以看到严重的类别不平衡问题。换句话说，人们会观察到数据集中95%或更多的数据是真实的交易，而不到5%的数据属于欺诈性交易。此外，即使您今天了解到一个欺诈性交易，该模型明天也可能会面临具有不同特征的异常情况。因此，真实交易的问题空间是众所周知的，它几乎停滞不前；然而，欺诈交易的问题空间并不广为人知，也不是恒定的。由于这些原因，用非监督学习而不是监督学习来处理欺诈检测问题是有意义的。</p>
<p class="mce-root">异常检测是一种无监督学习算法，也称为<strong class="calibre3">单类分类</strong>算法。它区分了<strong class="calibre3">正常</strong>和<strong class="calibre3">异常</strong>观测。建立该算法的关键原则是异常观测值不符合数据集中其他常见观测值的预期模式。它被称为一类分类，因为它学习真实交易的模式，任何显示不符合该模式的行为都被称为<strong class="calibre3">异常</strong>，因此被称为欺诈性<strong class="calibre3">交易</strong>。下图显示了二维空间中的异常检测:</p>
<p class="CDPAlignCenter1"><img class="aligncenter81" src="img/a74dd4da-4def-42ae-aa44-3d2cf811cb62.png"/></p>
<p>2D空间中的异常检测</p>
<p class="mce-root">异常的一个简单例子是识别时间序列中离平均值(标准偏差)太远的数据点。下图显示了时间序列中被识别为异常的数据点:</p>
<p class="CDPAlignCenter1"><img class="aligncenter82" src="img/9a73590b-e9ae-403e-86b8-b13ce39d2a66.png"/></p>
<p>时间序列中的异常—通过标准偏差识别</p>
<p class="mce-root">在本章中，我们将重点关注一种被称为<strong class="calibre3"> AEs </strong>的无监督深度学习应用。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Autoencoders explained</title>
    <meta content="urn:uuid:715f2a86-adaf-48a1-98a4-3c219c63f667" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">自动编码器解释</h1>
                
            
            
                
<p class="mce-root"><strong class="calibre3">自动编码器</strong> ( <strong class="calibre3"> AEs </strong>)是前馈和非递归类型的神经网络。他们的目标是把给定的输入复制到输出。AE的工作原理是将输入压缩成一个较低维度的摘要。这种概括通常被称为潜在空间表征。AE试图从潜在空间表示中重建输出。一个<strong class="calibre3">编码器</strong>、一个<strong class="calibre3">潜在空间表示</strong>和一个<strong class="calibre3">解码器</strong>是组成AEs的三个部分。下图显示了对从MNIST数据集中选取的样本应用AE的情况:</p>
<p class="CDPAlignCenter1"><img class="aligncenter83" src="img/1ec6a118-78cf-4d2c-9747-e56c5f0a31fb.png"/></p>
<p>AE在MNIST数据集样本上的应用</p>
<p class="mce-root">AEs的编码器和解码器组件是全连接的前馈网络。潜在空间表示中的神经元数量是一个超参数，需要作为构建AE的一部分进行传递。在潜在语义空间中决定的神经元或节点的数量决定了在将实际输入图像压缩成潜在空间表示时获得的压缩量。AE的一般架构如下图所示:</p>
<p class="CDPAlignCenter1"><img class="aligncenter84" src="img/bfd126a4-2ff5-4855-860e-3fbf58cf59e0.png"/></p>
<p>AE的一般架构</p>
<p class="mce-root">给定的输入首先经过一个<strong class="calibre3">编码器</strong>，它是一个全连接的<strong class="calibre3">人工神经网络</strong> ( <strong class="calibre3"> ANN </strong>)。<strong class="calibre3">编码器</strong>作用于<strong class="calibre3">输入</strong>并减小其尺寸，如超参数中所规定。<strong class="calibre3">解码器</strong>是另一个全连接的ANN，它拾取这个减少的<strong class="calibre3">输入</strong>(潜在空间表示)，然后重构<strong class="calibre3">输出</strong>。目标是使<strong class="calibre3">输出</strong>与<strong class="calibre3">输入</strong>相同。一般来说，<strong class="calibre3">编码器</strong>和<strong class="calibre3">解码器</strong>的架构是镜像的。虽然没有要求要求<strong class="calibre3">编码器</strong>和<strong class="calibre3">解码器</strong>的架构应该相同，但通常都是这样实施的。事实上，AE的唯一要求是从给定输入获得相同的输出。任何介于两者之间的东西都可以根据建造AE的个人的奇思妙想进行定制。</p>
<p class="mce-root">数学上，编码器可以表示为:</p>
<p class="CDPAlignCenter1"><sub class="calibre40"> <img class="fm-editor-equation7" src="img/f0867ffa-839a-4d32-b873-572ef7961eb2.png"/> </sub></p>
<p class="mce-root">其中<em class="calibre15"> x </em>是输入，<em class="calibre15"> h </em>是作用于输入的函数，以简洁的摘要格式表示输入。另一方面，解码器可以表示为:</p>
<p class="CDPAlignCenter1"><sub class="calibre40"> <img class="fm-editor-equation8" src="img/f8c2a45f-0bf3-4960-bc5b-5d66df7ad3a2.png"/>。</sub></p>
<p class="mce-root">虽然期望获得<img class="fm-editor-equation9" src="img/7eed3d3e-b794-4999-a444-e13c99a809a8.png"/>，但情况并非总是如此，因为重建是从紧凑的概要表示中完成的；因此，会出现一定的误差。误差<em class="calibre15"> e </em>由原始输入<em class="calibre15"> x </em>和重构输出<em class="calibre15"> r </em>、<img class="fm-editor-equation10" src="img/71b0ef36-ab8e-44a8-9243-cfb52997e5e1.png"/>计算得出。</p>
<p class="mce-root">然后，AE网络通过减少<strong class="calibre3">均方误差</strong> ( <strong class="calibre3"> MSE </strong>)来学习，并且误差被传播回隐藏层以进行调整。解码器和编码器的权重是彼此交换的，这使得学习训练参数更快。编码器和解码器的镜像架构使得更快地学习训练参数成为可能。在不同的架构中，权重不能简单互换；因此，计算时间会增加。这就是为编码器和解码器保留镜像架构的原因。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Types of AEs based on hidden layers</title>
    <meta content="urn:uuid:715f2a86-adaf-48a1-98a4-3c219c63f667" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">基于隐藏层的AEs类型</h1>
                
            
            
                
<p class="mce-root">根据隐藏层的大小，AEs可以分为两种类型，<strong class="calibre3">欠完全AEs </strong>和<strong class="calibre3">过完全AEs </strong>:</p>
<ul class="calibre9">
<li class="calibre10"><strong class="calibre1"> Undercomplete AE </strong>:如果AE只是简单的学习将输入复制到输出，那么它是没有用的。这个想法是产生一个简洁的表示作为编码器的输出，这个简洁的表示应该包含输入的最有用的特征。输入层所达到的简洁程度是由我们在潜在空间表示中使用的神经元或节点的数量决定的。这可以在构建AE时设置为一个参数。如果神经元的数量被设置为比输入特征的数量更少的维数，那么AE被迫学习输入数据的大多数关键特征。潜在空间中神经元的数量少于输入维度的数量的结构被称为欠完全AE。</li>
<li class="calibre10"><strong class="calibre1">过完备AE </strong>:可以将潜在空间的神经元数量表示为等于或大于输入维度的数量。这种体系结构被称为过完备AE。在这种情况下，AE不学习任何东西，而只是将输入复制到潜在空间，该潜在空间又被传播到解码器。</li>
</ul>
<p class="mce-root">除了潜在空间中的神经元数量之外，以下是可以在AE架构中使用的一些其他参数:</p>
<ul class="calibre9">
<li class="calibre10"><strong class="calibre1">编码器和解码器的层数</strong>:编码器和解码器的深度可以任意设定。通常，在编码器和解码器的镜像架构中，层数被设置为相同的数目。最后一张图展示了编码器和解码器中两层的AE，不包括输入和输出。</li>
<li class="calibre10"><strong class="calibre1">编码器和解码器中每层的神经元数量</strong>:编码器中每层的神经元数量减少，解码器中每层的神经元数量增加。编码器和解码器层中的神经元是对称的。</li>
<li class="calibre10"><strong class="calibre1">损失函数</strong>:AEs使用MSE或交叉熵等损失函数来学习反向传播期间的权重。如果输入在(0，1)的范围内，则使用交叉熵作为度量，否则使用MSE。</li>
</ul>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Types of AEs based on restrictions</title>
    <meta content="urn:uuid:715f2a86-adaf-48a1-98a4-3c219c63f667" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">基于限制的AEs类型</h1>
                
            
            
                
<p class="mce-root">根据对损失的限制，不良事件可分为以下几类:</p>
<ul class="calibre9">
<li class="calibre10"><strong class="calibre1">普通AEs </strong>:这是最简单的AE架构，采用全连接神经层作为编码器和解码器。</li>
<li class="calibre10"><strong class="calibre1">稀疏AEs </strong>:稀疏AEs是一种引入信息瓶颈的替代方法，不需要减少隐藏层中的节点数量。损失函数不是倾向于不完全AE，而是以惩罚层内激活的方式构造的。对于任何给定的观察，网络都被鼓励学习编码和解码，这仅依赖于激活一小部分神经元。</li>
<li class="calibre10"><strong class="calibre1">去噪AEs </strong>:这是一种过完备AE，经历学习<strong class="calibre1">恒等函数</strong>或<strong class="calibre1">空函数</strong>的风险。本质上，AE学习等于输入的输出，因此使AE无用。去噪AEs通过将一些输入随机初始化为0来避免学习恒等函数的问题。在损失函数的计算过程中，不考虑噪声引起的输入；因此，网络仍然学习正确的权重，而没有学习身份函数的风险。同时，AE被训练来学习重构输出，即使是从被破坏的输入。</li>
</ul>
<p class="calibre23">下图是对MNIST数据集中的样本图像进行AEs去噪的示例:</p>
<p class="CDPAlignCenter1"><img class="aligncenter85" src="img/d7a07b41-c689-4e55-a083-f06fe8654b83.png"/></p>
<p>去噪AEs在MNIST样品中的应用</p>
<ul class="calibre9">
<li class="calibre10"><strong class="calibre1">卷积AEs </strong>:当处理作为输入的图像时，可以使用卷积层作为编码器和解码器网络的一部分。这种使用卷积层的AEs被称为<strong class="calibre1">卷积AEs </strong>。下图显示了AEs中卷积的使用:</li>
</ul>
<p class="CDPAlignCenter1"><img src="img/cad4e496-083e-4442-9e06-9dfba7e17d0c.png" class="calibre41"/></p>
<p>卷积AEs</p>
<ul class="calibre9">
<li class="calibre10"><strong class="calibre1">堆栈式AEs </strong>:堆栈式AEs在编码器和解码器中都有多层。您可以参考AE的一般架构作为堆叠式AE架构的示例说明，其中编码器和解码器具有两层(不包括输入和输出层)。<ul class="calibre38">
<li class="calibre10"><strong class="calibre1">变分AEs </strong>:一个<strong class="calibre1">变分AE </strong> ( <strong class="calibre1"> VAE </strong>)，而不是建立一个输出信号的编码器</li>
</ul>
</li>
<li class="calibre10">描述每个潜在状态属性的e值描述了每个潜在属性的概率分布。这使得设计复杂的数据生成模型以及生成虚构的名人图像和数字艺术品成为可能。下图描述了VAEs中的数据表示:</li>
</ul>
<p class="CDPAlignCenter1"><img src="img/f0cf2cf0-7185-44d1-a669-4a7522e025b3.png" class="calibre42"/> <br class="calibre5"/></p>
<p class="calibre23">在VAE中，编码器模型有时被称为识别模型，而解码器模型有时被称为生成模型。编码器输出潜在特征的统计分布范围。这些特征被随机采样，并被解码器用来重构输入。对于潜在分布的任何采样，期望解码器能够准确地重建输入。因此，在潜在空间中彼此接近的值应该对应于非常相似的重构。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Applications of AEs</title>
    <meta content="urn:uuid:715f2a86-adaf-48a1-98a4-3c219c63f667" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">AEs的应用</h1>
                
            
            
                
<p class="mce-root">以下是AEs可能用到的一些实际应用:</p>
<ul class="calibre9">
<li class="calibre10"><strong class="calibre1">图像着色</strong>:给定一幅灰度图像作为输入，AEs可以自动给图像着色并返回彩色图像作为输出。</li>
<li class="calibre10"><strong class="calibre1">去噪</strong>:去噪AEs能够去除图像中的噪声，重建无噪声的图像。可以完成诸如从视频和图像中去除水印的任务。</li>
<li class="calibre10"><strong class="calibre1">降维</strong> : AEs以压缩形式表示输入数据，但只关注关键特征。因此，像图像这样的东西可以用减少的像素来表示，而不会在图像重建期间丢失太多信息。</li>
<li class="calibre10"><strong class="calibre1">图像搜索</strong>:用于根据给定的输入识别相似的图像。</li>
</ul>
<ul class="calibre9">
<li class="calibre10"><strong class="calibre1">信息检索</strong>:当从语料库中检索信息时，AEs可用于将属于给定输入的所有文档分组在一起。</li>
<li class="calibre10"><strong class="calibre1">主题建模</strong>:变分AEs用于近似后验分布，它已经成为推断文本文档潜在主题分布的一种有前途的替代方法。</li>
</ul>
<p class="mce-root">我们已经讲述了理解AEs及其应用所需的基础知识。让我们在高层次上理解一下，我们将使用AEs来解决信用卡欺诈检测问题。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>The credit card fraud dataset</title>
    <meta content="urn:uuid:715f2a86-adaf-48a1-98a4-3c219c63f667" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">信用卡欺诈数据集</h1>
                
            
            
                
<p class="mce-root">一般来说，在欺诈数据集中，我们有足够的数据用于负面类别(非欺诈/真实交易)，而很少或没有数据用于正面类别(欺诈交易)。这在ML世界中被称为<strong class="calibre3">等级不平衡问题</strong>。我们在非欺诈数据上训练一个AE，并使用编码器学习特征。然后，解码器用于计算训练集的重建误差，以找到阈值。该阈值将用于看不见的数据(测试数据集或其他)。我们使用阈值来将那些值大于阈值的测试实例识别为欺诈实例。</p>
<p class="mce-root">对于本章的项目，我们将使用一个来自这个URL的数据集:【https://essentials.togaware.com/data/<a href="https://essentials.togaware.com/data/" class="calibre8"/>。这是信用卡交易的公共数据集。该数据集最初通过研究论文<em class="calibre15">利用欠采样对不平衡分类进行概率校准</em>，A. Dal Pozzolo，O. Caelen，R. A Johnson和G. Bontempi，IEEE <strong class="calibre3">计算智能系列研讨会</strong> ( <strong class="calibre3"> SSCI </strong>)，南非开普敦，2015年。该数据集也可从以下网址获得:<a href="http://www.ulb.ac.be/di/map/adalpozz/data/creditcard.Rdata" class="calibre8">http://www.ulb.ac.be/di/map/adalpozz/data/creditcard.Rdata</a>。该数据集是在Worldline和ulb(布鲁塞尔自由大学)机器学习小组(<a href="http://mlg.ulb.ac.be/" class="calibre8"> http://mlg.ulb.ac.be </a>)关于大数据挖掘和欺诈检测的研究合作期间收集和分析的。</p>
<p class="mce-root">以下是数据集的特征:</p>
<ul class="calibre9">
<li class="calibre10">该论文将数据集作为Rdata文件提供。在Kaggle和其他网站上都有这个数据集的CSV转换版本。</li>
<li class="calibre10">它包含欧洲持卡人在2013年9月通过信用卡进行的交易。</li>
<li class="calibre10">两天内发生的交易被记录下来，并作为数据集呈现。</li>
</ul>
<ul class="calibre9">
<li class="calibre10">数据集中总共有284，807个事务。</li>
<li class="calibre10">数据集遭受严重的类不平衡问题。所有交易中只有0.172%是欺诈交易(492笔欺诈交易)。</li>
<li class="calibre10">数据集中共有三十个特征，分别是<kbd class="calibre11">V1</kbd>、<kbd class="calibre11">V2</kbd>、...、<kbd class="calibre11">V28</kbd>、<kbd class="calibre11">Time</kbd>、<kbd class="calibre11">Amount</kbd>。</li>
<li class="calibre10">变量<kbd class="calibre11">V1</kbd>、<kbd class="calibre11">V2</kbd>、...，<kbd class="calibre11">V28</kbd>是用PCA从原始变量集中获得的主成分。</li>
<li class="calibre10">由于保密性，产生主要成分的原始变量组没有被披露。</li>
<li class="calibre10"><kbd class="calibre11">Time</kbd>特性包含数据集中每个事务和第一个事务之间经过的秒数。</li>
<li class="calibre10"><kbd class="calibre11">Amount</kbd>特征是交易金额。</li>
<li class="calibre10">因变量命名为<kbd class="calibre11">Class</kbd>。欺诈交易在类中表示为1，而真实交易表示为0。</li>
</ul>
<p class="mce-root">我们现在将跳转到使用AEs的信用卡欺诈检测。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Building AEs with the H2O library in R</title>
    <meta content="urn:uuid:715f2a86-adaf-48a1-98a4-3c219c63f667" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">用R中的H2O图书馆构建AEs</h1>
                
            
            
                
<p class="mce-root">我们将在我们的项目中使用H2O可用的AE实现。H2O是一个完全开源的分布式内存ML平台，具有线性可伸缩性。它提供了一些最广泛使用的ML算法的并行实现。它支持一种易于使用、无监督和非线性的AE，作为其深度学习模型的一部分。H2O的DL AE基于多层神经网络架构，其中整个网络被一起训练，而不是一层一层地堆叠。</p>
<p class="mce-root">可以使用以下命令在R中安装<kbd class="calibre11">h2o</kbd>包:</p>
<pre class="calibre16"><strong class="calibre1">install.packages("h2o")</strong></pre>
<p>关于R中H2O的安装和依赖的更多细节可以从这个URL获得:<a href="https://cran.r-project.org/web/packages/h2o/index.html" class="calibre39">https://cran.r-project.org/web/packages/h2o/index.html</a>。</p>
<p class="mce-root">一旦软件包安装成功，由<kbd class="calibre11">h2o</kbd>软件包提供的功能，包括AE，可以简单地通过在R代码中包含以下代码行来使用:</p>
<pre class="calibre16">library(h2o)</pre>
<p class="mce-root">这是我们在用AE编码我们的信用卡欺诈检测系统之前需要做的所有事情。不要再等了，让我们开始构建我们的代码来探索和准备我们的数据集，以及实现捕获欺诈性信用卡交易的AE。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Autoencoder code implementation for credit card fraud detection</title>
    <meta content="urn:uuid:715f2a86-adaf-48a1-98a4-3c219c63f667" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">用于信用卡欺诈检测的自动编码器代码实现</h1>
                
            
            
                
<p class="mce-root">像往常一样，像所有其他项目一样，让我们首先将数据加载到R dataframe中，然后执行EDA以更好地理解数据集。请注意代码中包含了<kbd class="calibre11">h2o</kbd>和<kbd class="calibre11">doParallel</kbd>库。这些包含使我们能够使用作为<kbd class="calibre11">h2o</kbd>库一部分的AE，以及利用笔记本电脑/台式机中的多个CPU内核，如下所示:</p>
<pre class="calibre16"># including the required libraries<br class="title-page-name"/>library(tidyverse)<br class="title-page-name"/>library(h2o)<br class="title-page-name"/>library(rio)<br class="title-page-name"/>library(doParallel)<br class="title-page-name"/>library(viridis)<br class="title-page-name"/>library(RColorBrewer)<br class="title-page-name"/>library(ggthemes)<br class="title-page-name"/>library(knitr)<br class="title-page-name"/>library(caret)<br class="title-page-name"/>library(caretEnsemble)<br class="title-page-name"/>library(plotly)<br class="title-page-name"/>library(lime)<br class="title-page-name"/>library(plotROC)<br class="title-page-name"/>library(pROC)</pre>
<p class="mce-root">在本地主机的端口<kbd class="calibre11">54321</kbd>下初始化H2O集群。<kbd class="calibre11">nthreads</kbd>定义了要使用的线程池的数量，这接近于要使用的CPU的数量。在我们的例子中，我们说使用所有CPU，我们还指定H2O集群使用的最大内存为<kbd class="calibre11">8G</kbd>:</p>
<pre class="calibre16">localH2O = h2o.init(ip = 'localhost', port = 54321, nthreads = -1,max_mem_size = "8G")<br class="title-page-name"/># Detecting the available number of cores<br class="title-page-name"/>no_cores &lt;- detectCores() - 1<br class="title-page-name"/># utilizing all available cores<br class="title-page-name"/>cl&lt;-makeCluster(no_cores)<br class="title-page-name"/>registerDoParallel(cl)</pre>
<p class="mce-root">您将获得类似于以下代码块所示的输出:</p>
<pre class="calibre16">H2O is not running yet, starting it now...<br class="title-page-name"/>Note:  In case of errors look at the following log files:<br class="title-page-name"/>    /tmp/RtmpKZvQ3m/h2o_sunil_started_from_r.out<br class="title-page-name"/>    /tmp/RtmpKZvQ3m/h2o_sunil_started_from_r.err<br class="title-page-name"/>java version "1.8.0_191"<br class="title-page-name"/>Java(TM) SE Runtime Environment (build 1.8.0_191-b12)<br class="title-page-name"/>Java HotSpot(TM) 64-Bit Server VM (build 25.191-b12, mixed mode)<br class="title-page-name"/>Starting H2O JVM and connecting: ..... Connection successful!<br class="title-page-name"/>R is connected to the H2O cluster:<br class="title-page-name"/>    H2O cluster uptime:         4 seconds 583 milliseconds<br class="title-page-name"/>    H2O cluster timezone:       Asia/Kolkata<br class="title-page-name"/>    H2O data parsing timezone:  UTC<br class="title-page-name"/>    H2O cluster version:        3.20.0.8<br class="title-page-name"/>    H2O cluster version age:    2 months and 27 days <br class="title-page-name"/>    H2O cluster name:           H2O_started_from_R_sunil_jgw200<br class="title-page-name"/>    H2O cluster total nodes:    1<br class="title-page-name"/>    H2O cluster total memory:   7.11 GB<br class="title-page-name"/>    H2O cluster total cores:    4<br class="title-page-name"/>    H2O cluster allowed cores:  4<br class="title-page-name"/>    H2O cluster healthy:        TRUE<br class="title-page-name"/>    H2O Connection ip:          localhost<br class="title-page-name"/>    H2O Connection port:        54321<br class="title-page-name"/>    H2O Connection proxy:       NA<br class="title-page-name"/>    H2O Internal Security:      FALSE<br class="title-page-name"/>    H2O API Extensions:         XGBoost, Algos, AutoML, Core V3, Core V4<br class="title-page-name"/>    R Version:                  R version 3.5.1 (2018-07-02)</pre>
<p class="mce-root">现在，要设置数据文件位置的工作目录，加载Rdata并将其读入dataframe，并使用以下代码查看dataframe:</p>
<pre class="calibre16"># setting the working directory where the data file is location<br class="title-page-name"/>setwd("/home/sunil/Desktop/book/chapter 7")<br class="title-page-name"/># loading the Rdata file and reading it into the dataframe called cc_fraud<br class="title-page-name"/>cc_fraud&lt;-get(load("creditcard.Rdata"))<br class="title-page-name"/># performing basic EDA on the dataset<br class="title-page-name"/># Viewing the dataframe to confirm successful load of the dataset<br class="title-page-name"/>View(cc_fraud)</pre>
<p class="mce-root">将给出以下输出:</p>
<p class="CDPAlignCenter1"><img class="aligncenter86" src="img/3e302731-40c7-43f1-9350-8c3cb93e9608.png"/></p>
<p class="mce-root">现在让我们使用以下代码打印dataframe结构:</p>
<pre class="calibre16">print(str(cc_fraud))</pre>
<p class="mce-root">这将产生以下输出:</p>
<pre class="calibre16">'data.frame':     284807 obs. of  31 variables:<br class="title-page-name"/> $ Time  : num  0 0 1 1 2 2 4 7 7 9 ...<br class="title-page-name"/> $ V1    : num  -1.36 1.192 -1.358 -0.966 -1.158 ...<br class="title-page-name"/> $ V2    : num  -0.0728 0.2662 -1.3402 -0.1852 0.8777 ...<br class="title-page-name"/> $ V3    : num  2.536 0.166 1.773 1.793 1.549 ...<br class="title-page-name"/> $ V4    : num  1.378 0.448 0.38 -0.863 0.403 ...<br class="title-page-name"/> $ V5    : num  -0.3383 0.06 -0.5032 -0.0103 -0.4072 ...<br class="title-page-name"/> $ V6    : num  0.4624 -0.0824 1.8005 1.2472 0.0959 ...<br class="title-page-name"/> $ V7    : num  0.2396 -0.0788 0.7915 0.2376 0.5929 ...<br class="title-page-name"/> $ V8    : num  0.0987 0.0851 0.2477 0.3774 -0.2705 ...<br class="title-page-name"/> $ V9    : num  0.364 -0.255 -1.515 -1.387 0.818 ...<br class="title-page-name"/> $ V10   : num  0.0908 -0.167 0.2076 -0.055 0.7531 ...<br class="title-page-name"/> $ V11   : num  -0.552 1.613 0.625 -0.226 -0.823 ...<br class="title-page-name"/> $ V12   : num  -0.6178 1.0652 0.0661 0.1782 0.5382 ...<br class="title-page-name"/> $ V13   : num  -0.991 0.489 0.717 0.508 1.346 ...<br class="title-page-name"/> $ V14   : num  -0.311 -0.144 -0.166 -0.288 -1.12 ...<br class="title-page-name"/> $ V15   : num  1.468 0.636 2.346 -0.631 0.175 ...<br class="title-page-name"/> $ V16   : num  -0.47 0.464 -2.89 -1.06 -0.451 ...<br class="title-page-name"/> $ V17   : num  0.208 -0.115 1.11 -0.684 -0.237 ...<br class="title-page-name"/> $ V18   : num  0.0258 -0.1834 -0.1214 1.9658 -0.0382 ...<br class="title-page-name"/> $ V19   : num  0.404 -0.146 -2.262 -1.233 0.803 ...<br class="title-page-name"/> $ V20   : num  0.2514 -0.0691 0.525 -0.208 0.4085 ...<br class="title-page-name"/> $ V21   : num  -0.01831 -0.22578 0.248 -0.1083 -0.00943 ...<br class="title-page-name"/> $ V22   : num  0.27784 -0.63867 0.77168 0.00527 0.79828 ...<br class="title-page-name"/> $ V23   : num  -0.11 0.101 0.909 -0.19 -0.137 ...<br class="title-page-name"/> $ V24   : num  0.0669 -0.3398 -0.6893 -1.1756 0.1413 ...<br class="title-page-name"/> $ V25   : num  0.129 0.167 -0.328 0.647 -0.206 ...<br class="title-page-name"/> $ V26   : num  -0.189 0.126 -0.139 -0.222 0.502 ...<br class="title-page-name"/> $ V27   : num  0.13356 -0.00898 -0.05535 0.06272 0.21942 ...<br class="title-page-name"/> $ V28   : num  -0.0211 0.0147 -0.0598 0.0615 0.2152 ...<br class="title-page-name"/> $ Amount: num  149.62 2.69 378.66 123.5 69.99 ...<br class="title-page-name"/> $ Class : Factor w/ 2 levels "0","1": 1 1 1 1 1 1 1 1 1 1 ...</pre>
<p class="mce-root">现在，要查看类分布，请使用以下代码:</p>
<pre class="calibre16">print(table(cc_fraud$Class))</pre>
<p class="mce-root">您将获得以下输出:</p>
<pre class="calibre16">     0      1<br class="title-page-name"/>284315    492</pre>
<p class="mce-root">要查看<kbd class="calibre11">V1</kbd>和<kbd class="calibre11">Class</kbd>变量之间的关系，请使用以下代码:</p>
<pre class="calibre16"># Printing the Histograms for Multivariate analysis<br class="title-page-name"/>theme_set(theme_economist_white())<br class="title-page-name"/># visualization showing the relationship between variable V1 and the class<br class="title-page-name"/>ggplot(cc_fraud,aes(x="",y=V1,fill=Class))+geom_boxplot()+labs(x="V1",y="")</pre>
<p class="mce-root">这将产生以下输出:</p>
<p class="CDPAlignCenter1"><img class="aligncenter87" src="img/75981835-0fdf-4ffd-807e-6cceab13ec32.png"/></p>
<p class="mce-root">要可视化交易金额相对于类别的分布，请使用以下代码:</p>
<pre class="calibre16"># visualization showing the distribution of transaction amount with<br class="title-page-name"/># respect to the class, it may be observed that the amount are discretized<br class="title-page-name"/># into 50 bins for plotting purposes<br class="title-page-name"/>ggplot(cc_fraud,aes(x = Amount)) + geom_histogram(color = "#D53E4F", fill = "#D53E4F", bins = 50) + facet_wrap( ~ Class, scales = "free", ncol = 2)</pre>
<p class="mce-root">这将产生以下输出:</p>
<p class="CDPAlignCenter1"><img class="aligncenter88" src="img/95ac410b-3790-435f-a980-d0f89f27af11.png"/></p>
<p class="mce-root">要直观显示与类相关的事务时间分布，请使用以下代码:</p>
<pre class="calibre16">ggplot(cc_fraud, aes(x =Time,fill = Class))+ geom_histogram(bins = 30)+<br class="title-page-name"/>  facet_wrap( ~ Class, scales = "free", ncol = 2)</pre>
<p class="mce-root">这将产生以下输出:</p>
<p class="CDPAlignCenter1"><img class="aligncenter89" src="img/cc9a994e-1e30-440c-9f0e-80c79e7ae4ba.png"/></p>
<p class="mce-root">使用以下代码来可视化与<kbd class="calibre11">Class</kbd>相关的<kbd class="calibre11">V2</kbd>变量:</p>
<pre class="calibre16">ggplot(cc_fraud, aes(x =V2, fill=Class))+ geom_histogram(bins = 30)+<br class="title-page-name"/>  facet_wrap( ~ Class, scales = "free", ncol = 2)</pre>
<p class="mce-root">您将获得以下输出:</p>
<p class="CDPAlignCenter1"><img class="aligncenter90" src="img/1c891040-a5e6-4568-a669-bfa9307f150e.png"/></p>
<p class="mce-root">使用以下代码将<kbd class="calibre11">V3</kbd>相对于<kbd class="calibre11">Class</kbd>可视化:</p>
<pre class="calibre16">ggplot(cc_fraud, aes(x =V3, fill=Class))+ geom_histogram(bins = 30)+<br class="title-page-name"/>  facet_wrap( ~ Class, scales = "free", ncol = 2)</pre>
<p class="mce-root">下图是结果输出:</p>
<p class="CDPAlignCenter1"><img class="aligncenter91" src="img/084bee5f-c39d-4cd7-a4ef-f3654ca44992.png"/></p>
<p class="mce-root">为了可视化相对于<kbd class="calibre11">Class</kbd>的<kbd class="calibre11">V3</kbd>变量，使用下面的代码:</p>
<pre class="calibre16">ggplot(cc_fraud, aes(x =V4,fill=Class))+ geom_histogram(bins = 30)+<br class="title-page-name"/>  facet_wrap( ~ Class, scales = "free", ncol = 2)</pre>
<p class="mce-root">下图是结果输出:</p>
<p class="CDPAlignCenter1"><img class="aligncenter92" src="img/312d60a0-e11b-4ec9-ac1a-5b5a2fb77cc3.png"/></p>
<p class="mce-root">使用以下代码来可视化关于<kbd class="calibre11">Class</kbd>的<kbd class="calibre11">V6</kbd>变量:</p>
<pre class="calibre16">ggplot(cc_fraud, aes(x=V6, fill=Class)) + geom_density(alpha=1/3) + scale_fill_hue()</pre>
<p class="mce-root">下图是结果输出:</p>
<p class="CDPAlignCenter1"><img class="aligncenter93" src="img/0ec1dc19-0116-4bae-b1f4-72f520de15f8.png"/></p>
<p class="mce-root">使用以下代码来可视化与<kbd class="calibre11">Class</kbd>相关的<kbd class="calibre11">V7</kbd>变量:</p>
<pre class="calibre16">ggplot(cc_fraud, aes(x=V7, fill=Class)) + geom_density(alpha=1/3) + scale_fill_hue()</pre>
<p class="mce-root">下图是结果输出:</p>
<p class="CDPAlignCenter1"><img class="aligncenter94" src="img/9b97b5a5-1b06-4151-adde-1b85b632f657.png"/></p>
<p class="mce-root">使用以下代码来可视化与<kbd class="calibre11">Class</kbd>相关的<kbd class="calibre11">V8</kbd>变量:</p>
<pre class="calibre16">ggplot(cc_fraud, aes(x=V8, fill=Class)) + geom_density(alpha=1/3) + scale_fill_hue()</pre>
<p class="mce-root">下图是结果输出:</p>
<p class="CDPAlignCenter1"><img class="aligncenter95" src="img/7c471bfc-a6ff-4867-96cc-30da7a810d47.png"/></p>
<p class="mce-root">为了可视化与<kbd class="calibre11">Class</kbd>相关的<kbd class="calibre11">V9</kbd>变量，使用以下代码:</p>
<pre class="calibre16"># visualizationshowing the V7 variable with respect to the class<br class="title-page-name"/>ggplot(cc_fraud, aes(x=V9, fill=Class)) + geom_density(alpha=1/3) + scale_fill_hue()</pre>
<p class="mce-root">下图是结果输出:</p>
<p class="CDPAlignCenter1"><img class="aligncenter96" src="img/b82a52f6-7fe5-4983-b56f-9c9d92dfeed7.png"/></p>
<p class="mce-root">为了可视化与<kbd class="calibre11">Class</kbd>相关的<kbd class="calibre11">V10</kbd>变量，使用以下代码:</p>
<pre class="calibre16"># observe we are plotting the data quantiles<br class="title-page-name"/>ggplot(cc_fraud, aes(x ="",y=V10, fill=Class))+ geom_violin(adjust = .5,draw_quantiles = c(0.25, 0.5, 0.75))+labs(x="V10",y="")</pre>
<p class="mce-root">下图是结果输出:</p>
<p class="CDPAlignCenter1"><img class="aligncenter97" src="img/aeee5f93-f562-4bd6-944f-e2cfb1936b0c.png"/></p>
<p class="mce-root">从与类相关的变量的所有可视化中，我们可以推断出大多数主要成分都集中在<kbd class="calibre11">0</kbd>上。现在，要绘制数据中类的分布，请使用以下代码:</p>
<pre class="calibre16">cc_fraud %&gt;%<br class="title-page-name"/>  ggplot(aes(x = Class)) +<br class="title-page-name"/>  geom_bar(color = "chocolate", fill = "chocolate", width = 0.2) +<br class="title-page-name"/>  theme_bw()</pre>
<p class="mce-root">下面的条形图是结果输出:</p>
<p class="CDPAlignCenter1"><img class="aligncenter98" src="img/1ab03c79-8eea-4c65-94a7-ba90deedae22.png"/></p>
<p class="mce-root">我们观察到班级的分布很不平衡。与少数类(欺诈性交易:<kbd class="calibre11">1</kbd>)相比，数据集中主要类(非欺诈性交易，由<kbd class="calibre11">0</kbd>表示)的表示太重。在处理这类问题的传统监督ML方法中，我们会使用诸如<strong class="calibre3">合成少数过采样技术</strong> ( <strong class="calibre3"> SMORT </strong>)之类的技术来处理类不平衡问题。然而，对于AEs，我们不处理数据预处理期间的类不平衡；相反，我们将数据原样提供给AE进行学习。事实上，AE正在从多数类学习阈值和数据特征；这就是我们称之为一类分类问题的原因。</p>
<p class="mce-root">在培训我们的AE之前，我们需要做一些功能工程。让我们首先关注数据中的<kbd class="calibre11">Time</kbd>变量。目前，它是秒的格式，但是我们可以更好地用天来表示它。运行以下代码查看数据集中的当前时间形式:</p>
<pre class="calibre16">print(summary(cc_fraud$Time))</pre>
<p class="mce-root">您将获得以下输出:</p>
<pre class="calibre16">   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.<br class="title-page-name"/>      0   54202   84692   94814  139320  172792</pre>
<p class="mce-root">我们知道给定的一天有86，400秒(每分钟60秒*每小时60分钟*每天24小时)。我们将通过考虑<kbd class="calibre11">Time</kbd>中的值并将其表示为<kbd class="calibre11">day1</kbd>来将<kbd class="calibre11">Time</kbd>变量转换为<kbd class="calibre11">Day</kbd>，如果秒数小于或等于86，400，并且任何超过86，400的都变成<kbd class="calibre11">day2.</kbd>只有两天的可能，因为我们可以从摘要中看到时间变量表示的最大值是<kbd class="calibre11">172792</kbd>秒:</p>
<pre class="calibre16"># creating a new variable called day based on the seconds <br class="title-page-name"/># represented in Time variable<br class="title-page-name"/> cc_fraud=cc_fraud %&gt;% mutate(Day = case_when(.$Time &gt; 3600 * 24 ~ "day2",.$Time &lt; 3600 * 24 ~ "day1"))<br class="title-page-name"/>#visualizing the dataset post creating the new variable<br class="title-page-name"/>View(cc_fraud%&gt;%head())</pre>
<p class="mce-root">以下是转换后前六行的结果输出:</p>
<p class="CDPAlignCenter1"><img class="aligncenter99" src="img/a810fdad-2a9b-4045-a5ba-92635cd881ac.png"/></p>
<p class="mce-root">现在，使用以下代码查看最后六行:</p>
<pre class="calibre16">View(cc_fraud%&gt;%tail())</pre>
<p class="mce-root">以下是转换后最后六行的结果输出:</p>
<p class="CDPAlignCenter1"><img class="aligncenter100" src="img/5506a84a-a119-421a-be3c-1284e371c32a.png"/></p>
<p class="mce-root">现在，让我们使用以下代码，按交易发生的日期打印交易的分布情况:</p>
<pre class="calibre16">print(table(cc_fraud[,"Day"]))</pre>
<p class="mce-root">您将获得以下输出:</p>
<pre class="calibre16">  day1   day2<br class="title-page-name"/>144786 140020</pre>
<p class="mce-root">让我们根据<kbd class="calibre11">Time</kbd>变量中表示的秒数创建一个新变量<kbd class="calibre11">Time_day</kbd>，并使用以下代码总结<kbd class="calibre11">Time_day</kbd>变量与<kbd class="calibre11">Day</kbd>的关系:</p>
<pre class="calibre16">cc_fraud$Time_day &lt;- if_else(cc_fraud$Day == "day2", cc_fraud$Time - 86400, cc_fraud$Time)<br class="title-page-name"/>print(tapply(cc_fraud$Time_day,cc_fraud$Day,summary,simplify = FALSE))</pre>
<p class="mce-root">我们得到以下结果输出:</p>
<pre class="calibre16">$day1<br class="title-page-name"/>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.<br class="title-page-name"/>      0   38432   54689   52948   70976   86398<br class="title-page-name"/><br class="title-page-name"/>$day2<br class="title-page-name"/>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.<br class="title-page-name"/>      1   37843   53425   51705   68182   86392</pre>
<p class="mce-root">使用以下代码将数据集中的所有字符变量转换为因子:</p>
<pre class="calibre16">cc_fraud&lt;-cc_fraud%&gt;%mutate_if(is.character,as.factor)</pre>
<p class="mce-root">我们可以通过将变量转换成因子来进一步微调<kbd class="calibre11">Time_day</kbd>变量。factors表示交易发生的时间，例如<kbd class="calibre11">morning</kbd>、<kbd class="calibre11">afternoon</kbd>、<kbd class="calibre11">evening</kbd>和<kbd class="calibre11">night</kbd>。我们可以使用下面的代码，基于当天的不同时段，创建一个名为<kbd class="calibre11">Time_Group</kbd>的新变量:</p>
<pre class="calibre16">cc_fraud=cc_fraud %&gt;% <br class="title-page-name"/>  mutate(Time_Group = case_when(.$Time_day &lt;= 38138~ "morning" ,<br class="title-page-name"/>                                .$Time_day &lt;= 52327~  "afternoon",<br class="title-page-name"/>                                .$Time_day &lt;= 69580~"evening",<br class="title-page-name"/>                                .$Time_day &gt; 69580~"night"))<br class="title-page-name"/>#Visualizing the data post creating the new variable<br class="title-page-name"/>View(head(cc_fraud))</pre>
<p class="mce-root">以下是前六行的结果输出:</p>
<p class="CDPAlignCenter1"><img class="alignnone1" src="img/26eb4e24-39aa-4069-8b8b-b62b16d185af.png"/></p>
<p class="mce-root">使用以下代码查看并确认最后六行:</p>
<pre class="calibre16">View(tail(cc_fraud))</pre>
<p class="mce-root">这将给出以下输出，我们看到我们已经成功地转换了代表一天中不同时间的数据:</p>
<p class="CDPAlignCenter1"><img class="aligncenter101" src="img/4bf537f3-165f-47c8-a6b2-b04cd963ba4e.png"/></p>
<p class="mce-root">看一下下面的代码:</p>
<pre class="calibre16">#visualizing the transaction count by day<br class="title-page-name"/>cc_fraud %&gt;%drop_na()%&gt;%<br class="title-page-name"/>  ggplot(aes(x = Day)) +<br class="title-page-name"/>  geom_bar(fill = "chocolate",width = 0.3,color="chocolate") +<br class="title-page-name"/>  theme_economist_white()</pre>
<p class="mce-root">上述代码将生成以下输出:</p>
<p class="CDPAlignCenter1"><img class="aligncenter102" src="img/8c44ad84-e7fe-4871-a9b6-b0a84d54b8d1.png"/></p>
<p class="mce-root">我们可以从可视化中推断出，第1天和第2天发生的事务的数量没有区别。两者都保持在近15万笔交易。</p>
<p class="mce-root">现在我们将把<kbd class="calibre11">Class</kbd>变量转换成一个因子，然后使用下面的代码通过<kbd class="calibre11">Time_Group</kbd>变量可视化数据:</p>
<pre class="calibre16">cc_fraud$Class &lt;- factor(cc_fraud$Class)<br class="title-page-name"/>cc_fraud %&gt;%drop_na()%&gt;%<br class="title-page-name"/>  ggplot(aes(x = Time_Group)) +<br class="title-page-name"/>  geom_bar(color = "#238B45", fill = "#238B45") +<br class="title-page-name"/>  theme_bw() +<br class="title-page-name"/>  facet_wrap( ~ Class, scales = "free", ncol = 2)</pre>
<p class="mce-root">这将生成以下输出:</p>
<p class="CDPAlignCenter1"><img class="aligncenter103" src="img/e186689d-e77c-4cde-b52d-5ed9c1d5707c.png"/></p>
<p class="mce-root">从这个可视化中得出的结论是，在一天的所有时间段中，非欺诈性交易的数量几乎保持不变，而我们看到在早上<kbd class="calibre11">Time</kbd>组中欺诈性交易的数量大幅上升。</p>
<p class="mce-root">让我们对与类相关的交易量做最后一点探索:</p>
<pre class="calibre16"># getting the summary of amount with respect to the class<br class="title-page-name"/>print(tapply(cc_fraud$Amount  ,cc_fraud$Class,summary))</pre>
<p class="mce-root">上述代码将生成以下输出:</p>
<pre class="calibre16">$`0`<br class="title-page-name"/>    Min.  1st Qu.   Median     Mean  3rd Qu.     Max.<br class="title-page-name"/>    0.00     5.65    22.00    88.29    77.05 25691.16<br class="title-page-name"/>$`1`<br class="title-page-name"/>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.<br class="title-page-name"/>   0.00    1.00    9.25  122.21 105.89 2125.87</pre>
<p class="mce-root">摘要中一个有趣的发现是，欺诈交易的平均金额高于真实交易。然而，我们在欺诈交易中看到的最大交易金额远低于真实交易。也可以看出，真正的交易有更高的中位金额。</p>
<p class="mce-root">现在，让我们将R数据帧转换为H2O数据帧，并对其应用AE。这是使用<kbd class="calibre11">h2o</kbd>库中函数的一个要求:</p>
<pre class="calibre16"># converting R dataframe to H2O dataframe<br class="title-page-name"/>cc_fraud_h2o &lt;- as.h2o(cc_fraud)<br class="title-page-name"/>#splitting the data into 60%, 20%, 20% chunks to use them as training,<br class="title-page-name"/>#vaidation and test datasets<br class="title-page-name"/>splits &lt;- h2o.splitFrame(cc_fraud_h2o,ratios = c(0.6, 0.2), seed = 148)  <br class="title-page-name"/># creating new train, validation and test h2o dataframes<br class="title-page-name"/>train &lt;- splits[[1]]<br class="title-page-name"/>validation &lt;- splits[[2]]<br class="title-page-name"/>test &lt;- splits[[3]]<br class="title-page-name"/># getting the target and features name in vectors<br class="title-page-name"/>target &lt;- "Class"<br class="title-page-name"/>features &lt;- setdiff(colnames(train), target)</pre>
<p class="mce-root"><kbd class="calibre11">tanh</kbd>激活函数是一个重新标度和移位的逻辑函数。其他函数，如ReLu和Maxout，也由<kbd class="calibre11">h2o</kbd>库提供，也可以使用。在第一个AE模型中，让我们使用<kbd class="calibre11">tanh</kbd>激活功能。这种选择是任意的，也可以根据需要尝试其他激活功能。</p>
<p class="mce-root"><kbd class="calibre11">h2o.deeplearning</kbd>功能有一个参数AE，该参数应设置为<kbd class="calibre11">TRUE</kbd>以训练AE模型。现在让我们来构建我们的AE模型:</p>
<pre class="calibre16">model_one = h2o.deeplearning(x = features, training_frame = train,<br class="title-page-name"/>                             AE = TRUE,<br class="title-page-name"/>                             reproducible = TRUE,<br class="title-page-name"/>                             seed = 148,<br class="title-page-name"/>                             hidden = c(10,10,10), epochs = 100,<br class="title-page-name"/> activation = "Tanh",<br class="title-page-name"/>                             validation_frame = test)</pre>
<p class="mce-root">上述代码生成以下输出:</p>
<pre class="calibre16"> |===========================================================================================================================| 100%</pre>
<p class="mce-root">我们将保存模型，这样我们就不必一次又一次地重新训练。然后加载保存在磁盘上的模型，并使用以下代码打印该模型以验证AE学习:</p>
<pre class="calibre16">h2o.saveModel(model_one, path="model_one", force = TRUE)<br class="title-page-name"/>model_one&lt;-h2o.loadModel("/home/sunil/model_one/DeepLearning_model_R_1544970545051_1")<br class="title-page-name"/>print(model_one)</pre>
<p class="mce-root">这将生成以下输出:</p>
<pre class="calibre16">Model Details:<br class="title-page-name"/>==============<br class="title-page-name"/>H2OAutoEncoderModel: deeplearning<br class="title-page-name"/>Model ID:  DeepLearning_model_R_1544970545051_1<br class="title-page-name"/>Status of Neuron Layers: auto-encoder, gaussian distribution, Quadratic loss, 944 weights/biases, 20.1 KB, 2,739,472 training samples, mini-batch size 1<br class="title-page-name"/>  layer units  type dropout       l1       l2 mean_rate rate_rms momentum mean_weight weight_rms mean_bias bias_rms<br class="title-page-name"/>1     1    34 Input  0.00 %       NA       NA        NA       NA       NA          NA         NA        NA       NA<br class="title-page-name"/>2     2    10  Tanh  0.00 % 0.000000 0.000000  0.610547 0.305915 0.000000   -0.000347   0.309377 -0.028166 0.148318<br class="title-page-name"/>3     3    10  Tanh  0.00 % 0.000000 0.000000  0.181705 0.103598 0.000000    0.022774   0.262611 -0.056455 0.099918<br class="title-page-name"/>4     4    10  Tanh  0.00 % 0.000000 0.000000  0.133090 0.079663 0.000000    0.000808   0.337259  0.032588 0.101952<br class="title-page-name"/>5     5    34  Tanh      NA 0.000000 0.000000  0.116252 0.129859 0.000000    0.006941   0.357547  0.167973 0.688510<br class="title-page-name"/>H2OAutoEncoderMetrics: deeplearning<br class="title-page-name"/><strong class="calibre1"> Reported on training data.<br class="title-page-name"/></strong> Training Set Metrics:<br class="title-page-name"/>=====================<br class="title-page-name"/>MSE: (Extract with `h2o.mse`) 0.0003654009<br class="title-page-name"/>RMSE: (Extract with `h2o.rmse`) 0.01911546<br class="title-page-name"/>H2OAutoEncoderMetrics: deeplearning<br class="title-page-name"/><strong class="calibre1"> Reported on validation data.<br class="title-page-name"/></strong> Validation Set Metrics:<br class="title-page-name"/>=====================<br class="title-page-name"/>MSE: (Extract with `h2o.mse`) 0.0003508435<br class="title-page-name"/>RMSE: (Extract with `h2o.rmse`) 0.01873082</pre>
<p class="mce-root">我们现在将使用构建的AE模型对测试数据集进行预测，使用以下代码:</p>
<pre class="calibre16">test_autoencoder &lt;- h2o.predict(model_one, test)</pre>
<p class="mce-root">这将生成以下输出:</p>
<pre class="calibre16">|===========================================================================================================================| 100%</pre>
<p class="mce-root">通过<kbd class="calibre11">h2o.deepfeatures</kbd>功能，可以在内层中以有意识的方式可视化表示数据的编码器。让我们尝试在第二层中可视化缩减的数据:</p>
<pre class="calibre16">train_features &lt;- h2o.deepfeatures(model_one, train, layer = 2) %&gt;%<br class="title-page-name"/>  as.data.frame() %&gt;%<br class="title-page-name"/>  mutate(Class = as.vector(train[, 31]))<br class="title-page-name"/># printing the reduced data represented in layer2<br class="title-page-name"/>print(train_features%&gt;%head(3))</pre>
<p class="mce-root">上述代码将生成以下输出:</p>
<pre class="calibre16">DF.L2.C1  DF.L2.C2     DF.L2.C3    DF.L2.C4   DF.L2.C5 <br class="title-page-name"/>-0.12899115 0.1312075  0.115971952 -0.12997648 0.23081912<br class="title-page-name"/>-0.10437942 0.1832959  0.006427409 -0.08018725 0.05575977<br class="title-page-name"/>-0.07135827 0.1705700 -0.023808057 -0.11383244 0.10800857<br class="title-page-name"/>DF.L2.C6   DF.L2.C7    DF.L2.C8  DF.L2.C9  DF.L2.C10  Class0.1791547 0.10325721  0.05589069 0.5607497 -0.9038150     0<br class="title-page-name"/>0.1588236 0.11009450 -0.04071038 0.5895413 -0.8949729     0<br class="title-page-name"/>0.1676358 0.10703990 -0.03263755 0.5762191 -0.8989759     0</pre>
<p class="mce-root">现在让我们绘制<kbd class="calibre11">DF.L2.C1</kbd>相对于<kbd class="calibre11">DF.L2.C2</kbd>的数据，以验证编码器是否检测到欺诈交易，使用以下代码:</p>
<pre class="calibre16">ggplot(train_features, aes(x = DF.L2.C1, y = DF.L2.C2, color = Class)) +<br class="title-page-name"/>  geom_point(alpha = 0.1,size=1.5)+theme_bw()+<br class="title-page-name"/>  scale_fill_brewer(palette = "Accent")</pre>
<p class="mce-root">这将生成以下输出:</p>
<p class="CDPAlignCenter1"><img class="aligncenter104" src="img/1d57f16e-1bf6-47eb-94e4-83557dbb69eb.png"/></p>
<p class="mce-root">我们再次绘制<kbd class="calibre11">DF.L2.C3</kbd>相对于<kbd class="calibre11">DF.L2.C4</kbd>的数据，以验证编码器是否检测到任何欺诈交易，使用以下代码:</p>
<pre class="calibre16">ggplot(train_features, aes(x = DF.L2.C3, y = DF.L2.C4, color = Class)) +<br class="title-page-name"/>  geom_point(alpha = 0.1,size=1.5)+theme_bw()+<br class="title-page-name"/>  scale_fill_brewer(palette = "Accent")</pre>
<p class="mce-root">上述代码将生成以下输出:</p>
<p class="CDPAlignCenter1"><img class="aligncenter105" src="img/3bcd6f63-b386-415a-a650-87cf67b96e22.png"/></p>
<p class="mce-root">我们从两个可视化中看到，欺诈性交易确实是通过使用AE模型的维数约简方法检测到的。那些分散的小点(由<kbd class="calibre11">1</kbd>代表)描绘了被检测到的欺诈交易。我们也可以使用我们的第一个模型，用其他隐藏层训练一个新的模型。这导致10列，因为第三层有10个节点。我们只是试图切掉一个进行了某种程度缩减的层，并使用它来建立一个新的模型:</p>
<pre class="calibre16"># let's consider the third hidden layer. This is again a random choice<br class="title-page-name"/># in fact we could have taken any layer among the 10 inner layers<br class="title-page-name"/>train_features &lt;- h2o.deepfeatures(model_one, validation, layer = 3) %&gt;%<br class="title-page-name"/>  as.data.frame() %&gt;%<br class="title-page-name"/>  mutate(Class = as.factor(as.vector(validation[, 31]))) %&gt;%<br class="title-page-name"/>  as.h2o()</pre>
<p class="mce-root">上述代码将生成以下输出:</p>
<pre class="calibre16">|===========================================================================================================================| 100% |===========================================================================================================================| 100%</pre>
<p class="mce-root">正如我们所看到的，训练模型和数据已经成功创建。我们现在将继续训练新模型，保存并打印它。首先，我们将从切片编码器层获取特性名称:</p>
<pre class="calibre16">features_two &lt;- setdiff(colnames(train_features), target)</pre>
<p class="mce-root">然后我们将训练一个新的模型:</p>
<pre class="calibre16">model_two &lt;- h2o.deeplearning(y = target,<br class="title-page-name"/>                              x = features_two,<br class="title-page-name"/>                              training_frame = train_features,<br class="title-page-name"/>                              reproducible = TRUE,<br class="title-page-name"/>                              balance_classes = TRUE,<br class="title-page-name"/>                              ignore_const_cols = FALSE,<br class="title-page-name"/>                              seed = 148,<br class="title-page-name"/>                              hidden = c(10, 5, 10),<br class="title-page-name"/>                              epochs = 100,<br class="title-page-name"/>                              activation = "Tanh")</pre>
<p class="mce-root">然后，我们将保存模型以避免再次重新训练，然后检索模型并使用以下代码打印它:</p>
<pre class="calibre16">h2o.saveModel(model_two, path="model_two", force = TRUE)<br class="title-page-name"/>model_two &lt;- h2o.loadModel("/home/sunil/model_two/DeepLearning_model_R_1544970545051_2")<br class="title-page-name"/>print(model_two)</pre>
<p class="mce-root">这将生成以下输出:</p>
<pre class="calibre16">Model Details:<br class="title-page-name"/>==============<br class="title-page-name"/>H2OBinomialModel: deeplearning<br class="title-page-name"/>Model ID:  DeepLearning_model_R_1544970545051_2<br class="title-page-name"/>Status of Neuron Layers: predicting Class, 2-class classification, bernoulli distribution, CrossEntropy loss, 247 weights/biases, 8.0 KB, 2,383,962 training samples, mini-batch size 1<br class="title-page-name"/>  layer units    type dropout       l1       l2 mean_rate rate_rms momentum mean_weight weight_rms mean_bias bias_rms<br class="title-page-name"/>1     1    10   Input  0.00 %       NA       NA        NA       NA       NA          NA         NA        NA       NA<br class="title-page-name"/>2     2    10    Tanh  0.00 % 0.000000 0.000000  0.001515 0.001883 0.000000   -0.149216   0.768610 -0.038682 0.891455<br class="title-page-name"/>3     3     5    Tanh  0.00 % 0.000000 0.000000  0.003293 0.004916 0.000000   -0.251950   0.885017 -0.307971 0.531144<br class="title-page-name"/>4     4    10    Tanh  0.00 % 0.000000 0.000000  0.002252 0.001780 0.000000    0.073398   1.217405 -0.354956 0.887678<br class="title-page-name"/>5     5     2 Softmax      NA 0.000000 0.000000  0.007459 0.007915 0.000000   -0.095975   3.579932  0.223286 1.172508<br class="title-page-name"/>H2OBinomialMetrics: deeplearning<br class="title-page-name"/><strong class="calibre1"> Reported on training data.<br class="title-page-name"/>  Metrics reported on temporary training frame with 9892 samples<br class="title-page-name"/></strong> MSE:  0.1129424<br class="title-page-name"/>RMSE:  0.336069<br class="title-page-name"/>LogLoss:  0.336795<br class="title-page-name"/>Mean Per-Class Error:  0.006234916<br class="title-page-name"/>AUC:  0.9983688<br class="title-page-name"/>Gini:  0.9967377<br class="title-page-name"/>Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:<br class="title-page-name"/>          0    1    Error      Rate<br class="title-page-name"/>0      4910   62 0.012470  =62/4972<br class="title-page-name"/>1         0 4920 0.000000   =0/4920<br class="title-page-name"/>Totals 4910 4982 0.006268  =62/9892<br class="title-page-name"/>Maximum Metrics: Maximum metrics at their respective thresholds<br class="title-page-name"/>                        metric threshold    value idx<br class="title-page-name"/>1                       max f1  0.009908 0.993739 153<br class="title-page-name"/>2                       max f2  0.009908 0.997486 153<br class="title-page-name"/>3                 max f0point5  0.019214 0.990107 142<br class="title-page-name"/>4                 max accuracy  0.009908 0.993732 153<br class="title-page-name"/>5                max precision  1.000000 1.000000   0<br class="title-page-name"/>6                   max recall  0.009908 1.000000 153<br class="title-page-name"/>7              max specificity  1.000000 1.000000   0<br class="title-page-name"/>8             max absolute_mcc  0.009908 0.987543 153<br class="title-page-name"/>9   max min_per_class_accuracy  0.019214 0.989541 142<br class="title-page-name"/>10 max mean_per_class_accuracy  0.009908 0.993765 153<br class="title-page-name"/>Gains/Lift Table: Extract with `h2o.gainsLift(&lt;model&gt;, &lt;data&gt;)` or `h2o.gainsLift(&lt;model&gt;, valid=&lt;T/F&gt;, xval=&lt;T/F&gt;)</pre>
<p class="mce-root">为了测量测试数据的模型性能，我们需要将测试数据转换为与训练数据相同的缩减维度:</p>
<pre class="calibre16">test_3 &lt;- h2o.deepfeatures(model_one, test, layer = 3)<br class="title-page-name"/>print(test_3%&gt;%head())</pre>
<p class="mce-root">上述代码将生成以下输出:</p>
<pre class="calibre16">|===========================================================================================================================| 100%</pre>
<p class="mce-root">我们看到，数据已经转换成功。现在，为了用<kbd class="calibre11">model_two</kbd>对测试数据集进行预测，我们将使用下面的代码:</p>
<pre class="calibre16">test_pred=h2o.predict(model_two, test_3,type="response")%&gt;%<br class="title-page-name"/>  as.data.frame() %&gt;%<br class="title-page-name"/>  mutate(actual = as.vector(test[, 31]))</pre>
<p class="mce-root">这将生成以下输出:</p>
<pre class="calibre16">|===========================================================================================================================| 100%</pre>
<p class="mce-root">正如我们从输出中看到的，预测已经成功完成，现在让我们使用以下代码来可视化预测:</p>
<pre class="calibre16">test_pred%&gt;%head()<br class="title-page-name"/>  predict        p0           p1 actual<br class="title-page-name"/>1       0 1.0000000 1.468655e-23      0<br class="title-page-name"/>2       0 1.0000000 2.354664e-23      0<br class="title-page-name"/>3       0 1.0000000 5.987218e-09      0<br class="title-page-name"/>4       0 1.0000000 2.888583e-23      0<br class="title-page-name"/>5       0 0.9999988 1.226122e-06      0<br class="title-page-name"/>6       0 1.0000000 2.927614e-23      0<br class="title-page-name"/># summarizing the predictions<br class="title-page-name"/>print(h2o.predict(model_two, test_3) %&gt;%<br class="title-page-name"/>  as.data.frame() %&gt;%<br class="title-page-name"/>  dplyr::mutate(actual = as.vector(test[, 31])) %&gt;%<br class="title-page-name"/>  group_by(actual, predict) %&gt;%<br class="title-page-name"/>  dplyr::summarise(n = n()) %&gt;%<br class="title-page-name"/>  mutate(freq = n / sum(n)))</pre>
<p class="mce-root">这将生成以下输出:</p>
<pre class="calibre16">|===========================================================================================================================| 100%<br class="title-page-name"/># A tibble: 4 x 4<br class="title-page-name"/># Groups:   actual [2]<br class="title-page-name"/>  actual predict     n   freq<br class="title-page-name"/>  &lt;chr&gt;  &lt;fct&gt;   &lt;int&gt;  &lt;dbl&gt;<br class="title-page-name"/>1 0      0       55811 0.986<br class="title-page-name"/>2 0      1         817 0.0144<br class="title-page-name"/>3 1      0          41 0.414<br class="title-page-name"/>4 1      1          58 0.586</pre>
<p class="mce-root">我们看到，我们的AE能够以98%的准确率正确预测非欺诈性交易，这很好。然而，在预测欺诈交易时，它的准确率只有58%。这绝对是需要重点关注的。我们的模型需要一些改进，这可以通过以下选项来实现:</p>
<ul class="calibre9">
<li class="calibre10">使用其他层的潜在空间表示作为输入来构建<kbd class="calibre11">model_two</kbd>(记得我们目前使用的是第三层表示)</li>
<li class="calibre10">使用ReLu或Maxout激活功能代替<kbd class="calibre11">Tanh</kbd></li>
<li class="calibre10">通过<kbd class="calibre11">h2o.anomaly</kbd>函数检查错误分类的实例，并增加或减少截止阈值MSE值，从而将欺诈性交易与非欺诈性交易区分开来</li>
<li class="calibre10">在编码器和解码器中尝试更复杂的架构</li>
</ul>
<p class="mce-root">我们不打算在本章尝试这些选项，因为它们本质上是实验性的。但是，感兴趣的读者可以通过尝试这些选项来尝试和提高模型的准确性。</p>
<p class="mce-root">最后，一个最佳实践是显式关闭<kbd class="calibre11">h2o</kbd>集群。这可以通过以下命令完成:</p>
<pre class="calibre16"><strong class="calibre1">h2o.shutdown()</strong></pre>
<p class="mce-root"/>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Summary</title>
    <meta content="urn:uuid:715f2a86-adaf-48a1-98a4-3c219c63f667" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">摘要</h1>
                
            
            
                
<p class="mce-root">在这一章中，我们学习了一种叫做AEs的无监督深度学习技术。我们介绍了AEs的定义、工作原理、类型和应用。H2O是一个开源库，它使我们能够创建深度学习模型，包括AEs。然后，我们讨论了一个信用卡欺诈开放数据集，并使用AE实现了一个项目来检测欺诈性信用卡交易。</p>
<p class="mce-root">深度神经网络能否帮助完成创造性任务，如散文生成、故事写作、图像标题生成和诗歌写作？不确定？！让我们在下一章探索RNNs，一种特殊类型的深度神经网络，它使我们能够完成创造性的任务。翻页探索散文生成的RNNs世界。</p>


            

            
        
    </body>

</html>
</body></html>