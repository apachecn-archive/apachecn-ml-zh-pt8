<html><head/><body>
<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Sentiment Analysis of Amazon Reviews with NLP</title>
    <meta content="urn:uuid:715f2a86-adaf-48a1-98a4-3c219c63f667" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">基于自然语言处理的亚马逊评论情感分析</h1>
                
            
            
                
<p class="mce-root">每天，我们都会从电子邮件、博客等在线帖子、社交媒体评论等中生成数据。毫不奇怪，非结构化文本数据比任何组织的数据库中的表格数据都要大得多。对于组织来说，从与组织相关的文本数据中获取有用的洞察力是很重要的。由于与数据库中的数据相比，文本数据具有不同的性质，因此需要采用不同的方法来理解文本数据。在这一章中，我们将学习自然语言处理中的一些关键技术，帮助我们处理文本数据。</p>
<p class="mce-root">NLP的常见定义如下:计算机科学和人工智能的一个领域，处理计算机和人类(自然)语言之间的交互；特别是，如何对计算机进行编程，以有效地处理大量的自然语言数据。</p>
<p class="mce-root">总的来说，自然语言处理的是理解人们所说的话。它帮助机器阅读和理解“文本”。</p>
<p class="mce-root">人类语言非常复杂，为了正确理解口语或书面语，需要解决一些歧义。在自然语言处理领域，应用了几种技术来处理这些歧义，包括<strong class="calibre3">词性</strong> ( <strong class="calibre3">词性</strong>)标记、术语消歧、实体提取、关系提取、关键术语识别等等。</p>
<p class="mce-root">对于成功工作的自然语言系统，一致的知识库，如详细的词库、词汇、语言和语法规则的数据集、本体和最新的实体，是先决条件。</p>
<p class="mce-root">值得注意的是，NLP不仅从句法的角度来理解文本，还从语义的角度来理解文本。与人类类似，这个想法是让机器能够感知口语背后的潜在信息，而不仅仅是句子中的单词结构。NLP有许多应用领域，以下只是其中的几个:</p>
<ul class="calibre9">
<li class="calibre10">语音识别系统</li>
<li class="calibre10">问答系统</li>
<li class="calibre10">机器翻译</li>
<li class="calibre10">文本摘要</li>
<li class="calibre10">虚拟代理或聊天机器人</li>
<li class="calibre10">文本分类</li>
<li class="calibre10">话题分割</li>
</ul>
<p class="mce-root">由于自然语言处理的主题领域本身非常广泛，在一章中涵盖所有领域是不现实的。因此，我们将在这一章集中讨论“文本分类”。为此，我们实施了一个项目，对Amazon.com客户的评论进行情感分析。情感分析是一种文本分类任务，其中我们将每个文档(评论)分类到一个可能的类别中。可能的类别可以是正面的、负面的或中性的，也可以是正面的、负面的或1到10的等级。</p>
<p class="mce-root">需要分类的文本文档不能直接输入到机器学习算法中。每个文档都需要以某种特定的格式来表示，这种格式对于ML算法作为输入来处理是可以接受的。在这一章中，我们探索、实现并理解了单词包 ( <strong xmlns:epub="http://www.idpf.org/2007/ops" class="calibre3">鞠躬</strong>)单词嵌入方法。这些是表示文本的方法。</p>
<p class="mce-root">随着本章的深入，我们将涵盖以下主题:</p>
<ul class="calibre9">
<li class="calibre10">情感分析问题</li>
<li class="calibre10">了解亚马逊评论数据集</li>
<li class="calibre10">用BoW方法构建文本情感分类器</li>
<li class="calibre10">理解单词嵌入方法</li>
<li class="calibre10">基于路透社新闻语料构建预训练Word2Vec单词嵌入的文本情感分类器</li>
<li class="calibre10">利用手套词嵌入构建文本情感分类器</li>
<li class="calibre10">用fastText构建文本情感分类器</li>
</ul>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>The sentiment analysis problem</title>
    <meta content="urn:uuid:715f2a86-adaf-48a1-98a4-3c219c63f667" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">情感分析问题</h1>
                
            
            
                
<p class="mce-root">情感分析是最常见的文本分类应用之一。它的目的是分析用户评论和员工反馈等信息，以确定潜在情绪是积极的、消极的还是中性的。</p>
<p class="mce-root">通过分析和报告文本中的情感，企业无需阅读收到的每一条评论，就可以快速获得统一的高层次见解。</p>
<p class="mce-root">虽然可以基于收到的总体评论生成整体情感，但是还有一个扩展区域叫做<strong class="calibre3">基于方面的情感分析</strong>。它侧重于根据服务的每个领域来获取情感。例如，客户在撰写评论时访问了一家餐馆，通常会涵盖诸如氛围、食品质量、服务质量和价格等方面。虽然关于每个领域的反馈可能不会在特定标题下引用，但评论意见中的句子自然会涵盖客户对这些领域中一个或多个领域的意见。基于方面的情感分析试图识别每个领域的评论中的句子，然后识别情感是积极的、消极的还是中性的。提供每个领域的情绪有助于企业快速识别他们的薄弱领域。</p>
<p class="mce-root">在这一章中，我们将讨论和实现旨在从评论文本中识别总体情感的方法。这项任务可以通过几种方式完成，从简单的词典方法到复杂的单词嵌入方法。</p>
<p class="mce-root">一个<strong class="calibre3">词典</strong>方法并不是真正的机器学习方法。它更像是一种基于规则的方法，基于预定义的肯定和否定单词字典。这种方法包括在每次评论中查找积极词汇和消极词汇的数量。如果评论中正面词的计数大于负面词的计数，则该评论被标记为正面，否则被标记为负面。如果正反词数量相等，则该评论被标记为中性。因为实现这个方法很简单，而且它需要一个预定义的字典，所以我们在本章中不讨论lexicon方法的实现。</p>
<p class="mce-root">虽然可以把情感分析问题看作一个无监督的聚类问题，但在本章中，我们把它看作一个有监督的分类问题。这是因为，我们有标有数据集的亚马逊评论可用。我们可以利用这些标签来建立分类模型，因此，监督算法。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Getting started</title>
    <meta content="urn:uuid:715f2a86-adaf-48a1-98a4-3c219c63f667" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">入门指南</h1>
                
            
            
                
<p class="mce-root">该数据集可从以下URL下载和使用:</p>
<p class="mce-root"><a href="https://drive.google.com/drive/u/0/folders/0Bz8a_Dbh9Qhbfll6bVpmNUtUcFdjYmF2SEpmZUZUcVNiMUw1TWN6RDV3a0JHT3kxLVhVR2M" class="calibre8">https://drive . Google . com/drive/u/0/folders/0 BZ 8 a _ db H9 qhbfll 6 bvpmnutucdjymf 2 sepmzuzuzucvnimuw 1 TWN 6 rdv 3a 0 jht 3 kxlvhvr 2m</a>。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Understanding the Amazon reviews dataset</title>
    <meta content="urn:uuid:715f2a86-adaf-48a1-98a4-3c219c63f667" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">了解亚马逊评论数据集</h1>
                
            
            
                
<p class="mce-root">我们在本章的各个项目中使用亚马逊产品评论极性数据集。这是一个由张翔构建并提供的开放数据集。在论文中作为文本分类基准:<em class="calibre15">用于文本分类的字符级卷积网络</em>和<em class="calibre15">神经信息处理系统进展</em> 28、<em class="calibre15"> </em> <em class="calibre15">张翔、赵俊波、Yann LeCun、</em> <em class="calibre15"> (NIPS 2015) </em>。</p>
<p class="mce-root">亚马逊评论极性数据集是通过将评论分数1和2视为负面，4和5视为正面来构建的。分数3的样本被忽略。在数据集中，类1是负数，类2是正数。该数据集有1，800，000个训练样本和200，000个测试样本。</p>
<p class="mce-root"><kbd class="calibre11">train.csv</kbd>和<kbd class="calibre11">test.csv</kbd>文件以逗号分隔值的形式包含所有样本。其中有三列，分别对应班级索引(1或2)、复习题目、复习正文。审阅标题和文本使用双引号(")进行转义，任何内部双引号都用两个双引号("")进行转义。新行由一个反斜杠转义，后跟一个“n”字符，即“\n”。</p>
<p class="mce-root">为了确保我们能够运行我们的项目，即使只有最少的基础设施，让我们将数据集中要考虑的记录数量限制为1，000条。当然，我们在项目中使用的代码可以扩展到任意数量的记录，只要硬件基础设施支持可用。让我们首先用下面的代码读取数据并可视化记录:</p>
<pre class="calibre16"># reading first 1000 reviews<br class="title-page-name"/>reviews_text&lt;-readLines('/home/sunil/Desktop/sentiment_analysis/amazon _reviews_polarity.csv', n = 1000)<br class="title-page-name"/># converting the reviews_text character vector to a dataframe<br class="title-page-name"/>reviews_text&lt;-data.frame(reviews_text)<br class="title-page-name"/># visualizing the dataframe<br class="title-page-name"/>View(reviews_text)</pre>
<p class="mce-root">这将导致以下输出:</p>
<p class="CDPAlignCenter1"><img class="aligncenter30" src="img/b6bce54f-dc46-455b-ad50-0c6c06ae41ca.png"/></p>
<p class="mce-root">阅读文件后，我们可以看到数据集中只有一列，这一列既有评论文本又有情感成分。我们将稍微修改数据集的格式，以便在本章的情感分析项目中使用，包括BoW、Word2vec和GloVe方法。让我们用下面的代码修改数据集的格式:</p>
<pre class="calibre16"># separating the sentiment and the review text<br class="title-page-name"/># post separation the first column will have the first 4 characters<br class="title-page-name"/># second column will have the rest of the characters<br class="title-page-name"/># first column should be named "Sentiment"<br class="title-page-name"/># second column to be named "SentimentText"<br class="title-page-name"/>library(tidyr)<br class="title-page-name"/>reviews_text&lt;-separate(data = reviews_text, col = reviews_text, into = c("Sentiment", "SentimentText"), sep = 4)<br class="title-page-name"/># viewing the dataset post the column split<br class="title-page-name"/>View(reviews_text)</pre>
<p class="mce-root">这将导致以下输出:</p>
<p class="CDPAlignCenter1"><img class="aligncenter31" src="img/79b22882-b09c-4e3e-9e20-92f7bbbed8f0.png"/></p>
<p class="mce-root">现在我们的数据集中有两列。但是，两列中都存在不必要的标点符号，这可能会导致进一步处理数据集时出现问题。让我们尝试用下面的代码删除标点符号:</p>
<pre class="calibre16"># Retaining only alphanumeric values in the sentiment column<br class="title-page-name"/>reviews_text$Sentiment&lt;-gsub("[^[:alnum:] ]","",reviews_text$Sentiment)<br class="title-page-name"/># Retaining only alphanumeric values in the sentiment text<br class="title-page-name"/>reviews_text$SentimentText&lt;-gsub("[^[:alnum:] ]"," ",reviews_text$SentimentText)<br class="title-page-name"/># Replacing multiple spaces in the text with single space<br class="title-page-name"/>reviews_text$SentimentText&lt;-gsub("(?&lt;=[\\s])\\s*|^\\s+|\\s+$", "", reviews_text$SentimentText, perl=TRUE)<br class="title-page-name"/># Viewing the dataset<br class="title-page-name"/>View(reviews_text)<br class="title-page-name"/># Writing the output to a file that can be consumed in other projects<br class="title-page-name"/>write.table(reviews_text,file = "/home/sunil/Desktop/sentiment_analysis/Sentiment Analysis Dataset.csv",row.names = F,col.names = T,sep=',')</pre>
<p class="mce-root">这将导致以下输出:</p>
<p class="CDPAlignCenter1"><img class="aligncenter32" src="img/0b22278e-b011-4631-bb32-b1e1742aba4f.png"/></p>
<p class="mce-root">从前面的输出中，我们看到我们有一个干净的数据集可以使用了。此外，我们已经将输出写入文件。当我们构建情感分析器时，我们可以直接从<kbd class="calibre11">Sentiment Analysis Dataset.csv</kbd>文件中读取数据集。</p>
<p class="mce-root">fastText算法要求数据集采用不同的格式。输入到fastText的数据应符合以下格式:</p>
<pre class="calibre16">__label__&lt;X&gt;  &lt;Text&gt;</pre>
<p class="mce-root">在本例中，<kbd class="calibre11">X</kbd>是类名。文本是导致该类别下指定评级的实际考核文本。评级和文本应该放在一行，没有引号。班级是<kbd class="calibre11">__label__1</kbd>和<kbd class="calibre11">__label__2</kbd>，每行应该只有一个班级。让我们用下面的代码块完成<kbd class="calibre11">fastText</kbd>库所需的格式:</p>
<pre class="calibre16"># reading the first 1000 reviews from the dataset<br class="title-page-name"/>reviews_text&lt;-readLines('/home/sunil/Desktop/sentiment_analysis/amazon _reviews_polarity.csv', n = 1000)<br class="title-page-name"/># basic EDA to confirm that the data is read correctly<br class="title-page-name"/>print(class(reviews_text))<br class="title-page-name"/>print(length(reviews_text))<br class="title-page-name"/>print(head(reviews_text,2))<br class="title-page-name"/># replacing the positive sentiment value 2 with __label__2<br class="title-page-name"/>reviews_text&lt;-gsub("\\\"2\\\",","__label__2 ",reviews_text)<br class="title-page-name"/># replacing the negative sentiment value 1 with __label__1<br class="title-page-name"/>reviews_text&lt;-gsub("\\\"1\\\",","__label__1 ",reviews_text)<br class="title-page-name"/># removing the unnecessary \" characters<br class="title-page-name"/>reviews_text&lt;-gsub("\\\""," ",reviews_text)<br class="title-page-name"/># replacing multiple spaces in the text with single space<br class="title-page-name"/>reviews_text&lt;-gsub("(?&lt;=[\\s])\\s*|^\\s+|\\s+$", "", reviews_text, perl=TRUE)<br class="title-page-name"/># Basic EDA post the required processing to confirm input is as desired<br class="title-page-name"/>print("EDA POST PROCESSING")<br class="title-page-name"/>print(class(reviews_text))<br class="title-page-name"/>print(length(reviews_text))<br class="title-page-name"/>print(head(reviews_text,2))<br class="title-page-name"/># writing the revamped file to the directory so we could use it with<br class="title-page-name"/># fastText sentiment analyzer project<br class="title-page-name"/>fileConn&lt;-file("/home/sunil/Desktop/sentiment_analysis/Sentiment Analysis Dataset_ft.txt")<br class="title-page-name"/>writeLines(reviews_text, fileConn)<br class="title-page-name"/>close(fileConn)</pre>
<p class="mce-root">这将导致以下输出:</p>
<pre class="calibre16">[1] "EDA PRIOR TO PROCESSING"<br class="title-page-name"/>[1] "character"<br class="title-page-name"/>[1] 1000<br class="title-page-name"/>[1] "\"2\",\"Stuning even for the non-gamer\",\"This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^\""                                                                                  <br class="title-page-name"/>[2] "\"2\",\"The best soundtrack ever to anything.\",\"I'm reading a lot of reviews saying that this is the best 'game soundtrack' and I figured that I'd write a review to disagree a bit. This in my opinino is Yasunori Mitsuda's ultimate masterpiece. The music is timeless and I'm been listening to it for years now and its beauty simply refuses to fade.The price tag on this is pretty staggering I must say, but if you are going to buy any cd for this much money, this is the only one that I feel would be worth every penny.\""<br class="title-page-name"/>[1] "EDA POST PROCESSING"<br class="title-page-name"/>[1] "character"<br class="title-page-name"/>[1] 1000\<br class="title-page-name"/>[1] "__label__2 Stuning even for the non-gamer , This sound track was beautiful! It paints the senery in your mind so well I would recommend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^"                                                                                   <br class="title-page-name"/>[2] "__label__2 The best soundtrack ever to anything. , I'm reading a lot of reviews saying that this is the best 'game soundtrack' and I figured that I'd write a review to disagree a bit. This in my opinino is Yasunori Mitsuda's ultimate masterpiece. The music is timeless and I'm been listening to it for years now and its beauty simply refuses to fade. The price tag on this is pretty staggering I must say, but if you are going to buy any cd for this much money, this is the only one that I feel would be worth every penny."</pre>
<p class="mce-root">从基本EDA代码的输出中，我们可以看到数据集符合要求的格式，因此我们可以继续下一部分，使用BoW方法实现情感分析引擎。除了实现之外，我们还将深入学习该方法背后的概念，并探索在该方法中可以用来获得更好结果的子技术。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Building a text sentiment classifier with the BoW approach</title>
    <meta content="urn:uuid:715f2a86-adaf-48a1-98a4-3c219c63f667" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">用BoW方法构建文本情感分类器</h1>
                
            
            
                
<p class="mce-root">BoW方法的目的是将提供的审查文本转换成矩阵形式。它通过忽略单词的顺序和含义，将文档表示为一组不同的单词。矩阵的每一行代表每一篇评论(在NLP中也称为文档)，列代表所有评论中出现的通用单词集。对于每个文档和每个单词，记录该单词在该特定文档中的存在或出现频率。最后，从词频向量创建的矩阵表示文档集。这种方法用于创建训练模型所需的输入数据集，并且还用于准备测试数据集，该测试数据集需要被已训练的模型用来执行文本分类。现在我们已经理解了BoW的动机，让我们开始实现基于这种方法构建情感分析分类器的步骤，如下面的代码块所示:</p>
<pre class="calibre16"># including the required libraries<br class="title-page-name"/>library(SnowballC)<br class="title-page-name"/>library(tm)<br class="title-page-name"/># setting the working directory where the text reviews dataset is located<br class="title-page-name"/># recollect that we pre-processed and transformed the raw dataset format<br class="title-page-name"/>setwd('/home/sunil/Desktop/sentiment_analysis/')<br class="title-page-name"/># reading the transformed file as a dataframe<br class="title-page-name"/>text &lt;- read.table(file='Sentiment Analysis Dataset.csv', sep=',',header = TRUE)<br class="title-page-name"/># checking the dataframe to confirm everything is in tact<br class="title-page-name"/>print(dim(text))<br class="title-page-name"/>View(text)</pre>
<p class="mce-root">这将导致以下输出:</p>
<pre class="calibre16">&gt; print(dim(text))<br class="title-page-name"/>[1] 1000 2<br class="title-page-name"/>&gt; View(text)</pre>
<p class="CDPAlignCenter1"><img class="aligncenter33" src="img/068d0389-1c4c-418b-b6c3-ecb897f30581.png"/></p>
<p class="mce-root">处理文本数据的第一步包括创建一个<em class="calibre15">语料库</em>，这是一个文本文档的集合。<kbd class="calibre11">tm</kbd>包中的<kbd class="calibre11">VCorpus</kbd>函数支持将数据框中的reviews comments列转换为可变语料库。这可以通过下面的代码实现:</p>
<pre class="calibre16"># transforming the text into volatile corpus<br class="title-page-name"/>train_corp = VCorpus(VectorSource(text$SentimentText))<br class="title-page-name"/>print(train_corp)</pre>
<p class="mce-root">这将导致以下输出:</p>
<pre class="calibre16">&gt; print(train_corp)<br class="title-page-name"/>&lt;&lt;VCorpus&gt;&gt;<br class="title-page-name"/>Metadata:  corpus specific: 0, document level (indexed): 0<br class="title-page-name"/>Content:  documents: 1000</pre>
<p class="mce-root">从易变语料库中，我们创建一个<strong class="calibre3">文档术语矩阵</strong> ( <strong class="calibre3"> DTM </strong>)。DTM是使用<kbd class="calibre11">tm</kbd>库的<kbd class="calibre11">DocumentTermMatrix</kbd>函数创建的稀疏矩阵。矩阵的行表示文档，列表示特征，即单词。该矩阵是稀疏的，因为数据集的所有唯一的unigram集合变成DTM中的列，并且由于每个评论评论不具有unigram集合的所有元素，所以大多数单元将具有0，指示unigram的缺失。</p>
<p class="mce-root">虽然作为BoW方法的一部分，可以提取n-grams(一元、二元、三元等),但是可以设置tokenize参数，并将其作为控制列表的一部分在<kbd class="calibre11">DocumentTermMatrix</kbd>函数中传递，以在DTM实现n-grams。必须注意，使用n-grams作为DTM的一部分会在DTM中创建非常多的列。这是BoW方法的缺点之一，在某些情况下，由于有限的内存，它可能会延迟项目的执行。由于我们的具体案例也受到硬件基础设施的限制，我们限制自己在这个项目中只包括DTM的unigrams。除了生成单字之外，我们还通过向<kbd class="calibre11">tm</kbd>库的<kbd class="calibre11">DocumentTermMatrix</kbd>函数中的控制列表传递参数，对reviews文本文档执行一些额外的处理。我们在创建DTM期间对审阅文本文档进行的处理如下所示:</p>
<ol class="calibre12">
<li class="calibre10">将文本的大小写改为小写。</li>
<li class="calibre10">删除任何数字。</li>
<li class="calibre10">使用Snowball stemmer项目中的英语停用词列表删除停用词。停用词是常见的词，如a、an、in和the，它们不会增加基于评论判断情感的价值。</li>
<li class="calibre10">去掉标点符号。</li>
<li class="calibre10">进行词干分析，目的是将一个单词分解成该单词的基本形式，即从名词中去掉复数<em class="calibre22"> s </em>，从动词或其他词缀中去掉复数<em class="calibre22"> ing </em>。词干是一组意思相同或非常相似的自然单词。词干化过程之后，每个单词都由其词干表示。<kbd class="calibre11">SnowballC</kbd>库提供了获取评论中每个单词的词根的能力。</li>
</ol>
<p class="mce-root">现在让我们从volatile语料库中创建一个DTM，并用下面的代码块进行文本预处理:</p>
<pre class="calibre16"># creating document term matrix<br class="title-page-name"/>dtm_train &lt;- DocumentTermMatrix(train_corp, control = list(<br class="title-page-name"/>  tolower = TRUE,removeNumbers = TRUE,<br class="title-page-name"/>  stopwords = TRUE,<br class="title-page-name"/>  removePunctuation = TRUE,<br class="title-page-name"/>  stemming = TRUE<br class="title-page-name"/>))<br class="title-page-name"/># Basic EDA on dtm<br class="title-page-name"/>inspect(dtm_train)</pre>
<p class="mce-root">这将导致以下输出:</p>
<pre class="calibre16">&gt; inspect(dtm_train)<br class="title-page-name"/>&lt;&lt;DocumentTermMatrix (documents: 1000, terms: 5794)&gt;&gt;<br class="title-page-name"/>Non-/sparse entries: 34494/5759506<br class="title-page-name"/>Sparsity           : 99%<br class="title-page-name"/>Maximal term length: 21<br class="title-page-name"/>Weighting          : term frequency (tf)<br class="title-page-name"/>Sample             :<br class="title-page-name"/>     Terms<br class="title-page-name"/>Docs  book can get great just like love one read time<br class="title-page-name"/>  111    0   3   2     0    0    0    2   1    0    2<br class="title-page-name"/>  162    4   1   0     0    0    1    0   0    1    0<br class="title-page-name"/>  190    0   0   0     0    0    0    0   0    0    0<br class="title-page-name"/>  230    0   1   1     0    0    0    1   0    0    0<br class="title-page-name"/>  304    0   0   0     0    0    3    0   2    0    0<br class="title-page-name"/>  399    0   0   0     0    0    0    0   0    0    0<br class="title-page-name"/>  431    9   1   0     0    0    1    2   0    0    1<br class="title-page-name"/>  456    1   0   0     0    0    0    0   1    2    0<br class="title-page-name"/>  618    0   2   3     1    4    1    3   1    0    1<br class="title-page-name"/>  72     0   0   1     0    2    0    0   1    0    1</pre>
<p class="mce-root">我们从输出中看到，有1，000个文档被处理并在矩阵中形成行。在额外的文本处理之后，有5，794列表示来自评论的独特单字。我们还看到DTM是99%稀疏的，并且仅在34，494个单元中包含非零条目。非零单元格表示该单词在DTM的行上表示的文档的列上出现的频率。由于我们没有在提供给<kbd class="calibre11">DocumentTermMatrix</kbd>函数的控制列表中指定任何加权参数，所以加权是通过默认的“词频”加权完成的。其他形式的加权，例如<strong class="calibre3">项频率-逆文档频率</strong> ( <strong class="calibre3"> TFIDF </strong>)，也可以通过将控制列表中的适当权重参数传递给<kbd class="calibre11">DocumentTermMatrix</kbd>函数来实现。现在，我们将坚持基于术语频率的加权，这是默认的。我们还从<kbd class="calibre11">inspect</kbd>函数中看到，输出了几个样本文档以及这些文档中的术语频率。</p>
<p class="mce-root">DTM往往会变得非常大，即使对于正常大小的数据集也是如此。去除稀疏术语，即只在很少的文档中出现的术语，是可以尝试的技术，以减小矩阵的大小，而不丢失矩阵固有的重要关系。让我们从矩阵中移除稀疏列。我们将尝试使用下面的代码行删除那些具有至少99%稀疏元素的术语:</p>
<pre class="calibre16"># Removing sparse terms<br class="title-page-name"/>dtm_train= removeSparseTerms(dtm_train, 0.99)<br class="title-page-name"/>inspect(dtm_train)</pre>
<p class="mce-root">这将导致以下输出:</p>
<pre class="calibre16">&gt; inspect(dtm_train)<br class="title-page-name"/>&lt;&lt;DocumentTermMatrix (documents: 1000, terms: 686)&gt;&gt;<br class="title-page-name"/>Non-/sparse entries: 23204/662796<br class="title-page-name"/>Sparsity           : 97%<br class="title-page-name"/>Maximal term length: 10<br class="title-page-name"/>Weighting          : term frequency (tf)<br class="title-page-name"/>Sample             :<br class="title-page-name"/>     Terms<br class="title-page-name"/>Docs  book can get great just like love one read time<br class="title-page-name"/>  174    0   0   1     1    1    2    0   2    0    1<br class="title-page-name"/>  304    0   0   0     0    0    3    0   2    0    0<br class="title-page-name"/>  355    3   0   0     0    1    1    2   3    1    0<br class="title-page-name"/>  380    4   1   0     0    1    0    0   1    0    2<br class="title-page-name"/>  465    5   0   1     1    0    0    0   2    6    0<br class="title-page-name"/>  618    0   2   3     1    4    1    3   1    0    1<br class="title-page-name"/>  72     0   0   1     0    2    0    0   1    0    1<br class="title-page-name"/>  836    1   0   0     0    0    3    0   0    5    1<br class="title-page-name"/>  866    8   0   1     0    0    1    0   0    4    0<br class="title-page-name"/>  959    0   0   2     1    1    0    0   2    0    1</pre>
<p class="mce-root">我们现在从<kbd class="calibre11">inspect</kbd>函数的输出中看到，矩阵的稀疏性减少到了97%，并且单字(矩阵的列)的数量减少到了<kbd class="calibre11">686</kbd>。我们现在已经准备好了DTM，它可以用于任何机器学习分类算法的训练。在接下来的几行代码中，让我们尝试将DTM分为训练数据集和测试数据集:</p>
<pre class="calibre16"># splitting the train and test DTM<br class="title-page-name"/>dtm_train_train &lt;- dtm_train[1:800, ]<br class="title-page-name"/>dtm_train_test &lt;- dtm_train[801:1000, ]<br class="title-page-name"/>dtm_train_train_labels &lt;- as.factor(as.character(text[1:800, ]$Sentiment))<br class="title-page-name"/>dtm_train_test_labels &lt;- as.factor(as.character(text[801:1000, ]$Sentiment))</pre>
<p class="mce-root">我们将使用名为<strong class="calibre3">朴素贝叶斯</strong>的机器学习算法来创建一个模型。朴素贝叶斯通常在具有名义特征的数据上训练。我们可以观察到，DTM中的像元是数值型的，因此需要在将数据集作为使用朴素贝叶斯创建模型的输入之前将其转换为名义值。由于每个单元格都表示评论中的词频，并且评论中使用一个词的次数不会影响情绪，因此让我们编写一个函数，将具有非零值的单元格值转换为<kbd class="calibre11">Y</kbd>，如果是零，则使用以下代码将其转换为<kbd class="calibre11">N</kbd>:</p>
<pre class="calibre16">cellconvert&lt;- function(x) {<br class="title-page-name"/>x &lt;- ifelse(x &gt; 0, "Y", "N")<br class="title-page-name"/>}</pre>
<p class="mce-root">现在，让我们将该函数应用于我们之前在此项目中使用以下代码创建的培训数据集和测试数据集的所有行:</p>
<pre class="calibre16"># applying the function to rows in training and test datasets<br class="title-page-name"/>dtm_train_train &lt;- apply(dtm_train_train, MARGIN = 2,cellconvert)<br class="title-page-name"/>dtm_train_test &lt;- apply(dtm_train_test, MARGIN = 2,cellconvert)<br class="title-page-name"/># inspecting the train dtm to confirm all is in tact<br class="title-page-name"/>View(dtm_train_train)</pre>
<p class="mce-root">这将导致以下输出:</p>
<p class="CDPAlignCenter1"><img class="aligncenter34" src="img/c894b708-f3b8-4a46-9951-4f55652ce045.png"/></p>
<p class="mce-root">我们可以从输出中看到，训练和测试DTM中的所有单元现在都转换为标称值。因此，让我们使用来自<kbd class="calibre11">e1071</kbd>库的朴素贝叶斯算法来构建一个文本情感分析分类器，如下所示:</p>
<pre class="calibre16"># training the naive bayes classifier on the training dtm<br class="title-page-name"/>library(e1071)<br class="title-page-name"/>nb_senti_classifier=naiveBayes(dtm_train_train,dtm_train_train_labels)<br class="title-page-name"/># printing the summary of the model created<br class="title-page-name"/>summary(nb_senti_classifier)</pre>
<p class="mce-root">这将导致以下输出:</p>
<pre class="calibre16">&gt; summary(nb_senti_classifier)<br class="title-page-name"/>        Length Class  Mode    <br class="title-page-name"/>apriori   2    table  numeric <br class="title-page-name"/>tables  686    -none- list    <br class="title-page-name"/>levels    2    -none- character<br class="title-page-name"/>call      3    -none- call  </pre>
<p class="mce-root">前面的摘要输出显示了从训练DTM成功创建了<kbd class="calibre11">nb_senti_classifier</kbd>对象。现在让我们使用模型对象来预测测试数据DTM的情绪。在下面的代码块中，我们指示预测应该是类，而不是预测概率:</p>
<pre class="calibre16"># making predictions on the test data dtm<br class="title-page-name"/>nb_predicts&lt;-predict(nb_senti_classifier, dtm_train_test,type="class")<br class="title-page-name"/># printing the predictions from the model<br class="title-page-name"/>print(nb_predicts)</pre>
<p class="mce-root">这将导致以下输出:</p>
<pre class="calibre16">[1] 1 1 2 1 1 1 1 1 1 2 2 1 2 2 2 2 1 2 1 1 2 1 2 1 1 1 2 2 1 2 2 2 2 1 2 1 1 1 1 2 2 2 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 1 1 1 1 1 1 1 2 1 1 2 2 1 2 2 2 2 1 2 2 1 1 1 1 1 2 1 1 2 1 1 1 1 1 2 2 2 2 2 2 1 2 2 1 2 1 1 1 1 2 2 2 2 2 1 1 1 2 2 2 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1 1 2 2 2 2 2 1 2 2 1 2 2 1 1 2 2 1 1 2 2 2 2 2 2 2 2 2 2 2 1 1 2 1 2 1 2 2 1 1 1 1 2<br class="title-page-name"/>Levels: 1 2</pre>
<p class="mce-root">使用下面的代码，现在让我们使用<kbd class="calibre11">rminer</kbd>库中的<kbd class="calibre11">mmetric</kbd>函数来计算模型的精确度:</p>
<pre class="calibre16"># computing accuracy of the model<br class="title-page-name"/>library(rminer)<br class="title-page-name"/>print(mmetric(nb_predicts, dtm_train_test_labels, c("ACC")))</pre>
<p class="mce-root">这将导致以下输出:</p>
<pre class="calibre16">[1] 79</pre>
<p class="mce-root">我们只用一个非常快速和基本的弓模型就达到了79%的准确率。该模型可以通过诸如参数调整、词汇化、新特征创建等技术来进一步改进。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Pros and cons of the BoW approach</title>
    <meta content="urn:uuid:715f2a86-adaf-48a1-98a4-3c219c63f667" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">弓法的利与弊</h1>
                
            
            
                
<p class="mce-root">现在我们已经了解了BoW方法的理论和实现，让我们来研究一下该方法的优缺点。就优点而言，BoW方法非常容易理解和实现，因此为任何文本数据集的定制提供了很大的灵活性。可以观察到，BoW方法不保留单词的顺序，特别是当只考虑单字时。这个问题通常通过在DTM中保留n-grams来解决。然而，这是有代价的，因为需要更大的基础设施来处理文本和构建分类器。这种方法的另一个严重缺点是它不尊重单词的语义。例如,“car”和“automobile”这两个词经常在同一上下文中使用。基于BoW构建的模型将句子“购买二手车”和“购买旧汽车”视为非常不同的句子。虽然这些句子是相同的，但是BoW模型不会将这些句子归类为相同的，因为这些句子中的单词不匹配。使用一种叫做单词嵌入的方法来考虑句子中单词的语义是可能的。这是我们将在下一节探讨的内容。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Understanding word embedding</title>
    <meta content="urn:uuid:715f2a86-adaf-48a1-98a4-3c219c63f667" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">理解单词嵌入</h1>
                
            
            
                
<p class="mce-root">我们在上一节中讨论的BoW模型存在一个问题，即它们不能捕获关于单词含义或上下文的信息。这意味着潜在的关系，如上下文的密切程度，不能在单词集合中被捕获。例如，这种方法不能捕捉简单的关系，例如确定单词“轿车”和“公共汽车”都是指在运输环境中经常讨论的车辆。我们在BoW方法中遇到的这个问题将通过单词嵌入来克服，单词嵌入是一种映射语义相似单词的改进方法。</p>
<p class="mce-root">单词向量将单词表示为多维连续浮点数，其中语义相似的单词被映射到几何空间中的邻近点。例如，单词<em class="calibre15">水果</em>和<em class="calibre15">树叶</em>会有一个相似的单词向量<em class="calibre15">树</em>。这是因为它们的意思相似，而单词<em class="calibre15"> television </em>在几何空间中会非常遥远。换句话说，在相似上下文中使用的单词将被映射到近似的向量空间。</p>
<p class="mce-root">单词向量可以有<em class="calibre15"> n </em>个维度，并且<em class="calibre15"> n </em>可以接受来自创建它的用户的任何数字作为输入(例如10、70、500)。这些维度是潜在的，因为对人类来说，这些维度中的每一个在现实中意味着什么并不明显。存在诸如<strong class="calibre3">连续单词包</strong> ( <strong class="calibre3"> CBOW </strong>)和<strong class="calibre3"> Skip-Gram </strong>之类的方法，使得能够从作为单词嵌入算法的训练输入而提供的文本中构思单词向量。此外，单词向量中的各个数字表示单词在各个维度上的分布权重。在一般意义上，每个维度代表一个潜在的意义，单词在该维度上的数字权重捕捉了它与该意义的联系的紧密程度。因此，单词的语义嵌入到向量的各个维度中。</p>
<p class="mce-root">虽然单词向量是多维的，不能直接可视化，但是可以通过使用诸如t-SNE维数缩减技术将它们投影到二维来可视化所学习的向量。下图显示了国家首都、动词时态和性别关系的二维学习单词向量:</p>
<p class="CDPAlignCenter1"><img class="aligncenter35" src="img/09d8ca48-57d7-4e72-a2f1-bf3c03b1a68a.png"/></p>
<p>二维空间中单词嵌入的可视化</p>
<p class="mce-root">当我们观察单词嵌入可视化时，我们可以察觉到向量捕获了一些关于单词及其相互关系的一般的、事实上非常有用的语义信息。这样，文本中的每个单词现在都可以表示为矩阵中的一行，类似于BoW方法，但与BoW方法不同，它捕捉单词之间的关系。</p>
<p class="mce-root">将单词表示为向量的优点是它们有助于数学运算符。例如，我们可以加减向量。此处的典型示例表明，通过使用词向量，我们可以确定以下内容:</p>
<p class="CDPAlignCenter1"><em class="calibre15">国王-男人+女人=王后</em></p>
<p class="mce-root">在给定的示例中，我们从king的单词向量中减去了性别(man)并添加了另一个性别(woman)，我们从运算(<em class="calibre15"> king - man + woman </em>)中获得了一个新的单词向量，它最接近地映射到queen的单词向量。</p>
<p class="mce-root">可以在单词向量上实现的数学运算的几个更惊人的例子如下所示:</p>
<ul class="calibre9">
<li class="calibre10">给定两个词，我们可以确定它们之间的相似程度:</li>
</ul>
<pre class="calibre26">model.similarity('woman','man')</pre>
<p class="calibre29">输出如下所示:</p>
<pre class="calibre26">0.73723527</pre>
<ul class="calibre9">
<li class="calibre10">从作为输入给出的一组单词中找出奇怪的一个:</li>
</ul>
<pre class="calibre26">model.doesnt_match('breakfast cereal dinner lunch';.split())</pre>
<p class="calibre23">奇数输出如下所示:</p>
<pre class="calibre26">'cereal'</pre>
<ul class="calibre9">
<li class="calibre10">进行类比，例如:</li>
</ul>
<pre class="calibre26">model.most_similar(positive=['woman','king'],negative=['man'],topn=1)</pre>
<p class="calibre23">输出如下所示:</p>
<pre class="calibre26">queen: 0.508</pre>
<p class="mce-root">现在，这对我们来说意味着机器能够识别句子中语义相似的单词。下图是一个与单词嵌入相关的插科打诨，让我忍俊不禁，但这个插科打诨确实传达了单词嵌入应用程序的强大功能，否则这对于BoW类型的文本表示是不可能的:</p>
<p class="CDPAlignCenter1"><img class="aligncenter36" src="img/e972fc21-e370-464a-9b08-22fef9b041bb.png"/></p>
<p>展示单词嵌入应用程序威力的插科打诨</p>
<p class="mce-root">有几种技术可以用来从文本数据中学习单词嵌入。Word2vec、GloVe和fastText是一些流行的技术。这些技术中的每一种都允许我们从我们拥有的文本数据中训练我们自己的单词嵌入，或者使用容易获得的预训练向量。</p>
<p class="mce-root">这种学习我们自己的单词嵌入的方法需要大量的训练数据，并且可能很慢，但是该选项将学习针对特定文本数据和手边的NLP任务的嵌入。</p>
<p class="mce-root">预训练的单词嵌入向量是在大量文本数据(通常是数十亿个单词)上训练的向量，这些数据可以从维基百科等来源获得。这些通常是由谷歌或脸书等公司提供的高质量单词嵌入向量。我们可以下载这些预先训练的向量文件，并使用它们来获得文本中我们想要分类或聚类的单词的单词向量。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Building a text sentiment classifier with pretrained word2vec word embedding based on Reuters news corpus</title>
    <meta content="urn:uuid:715f2a86-adaf-48a1-98a4-3c219c63f667" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">基于路透社新闻语料构建预训练word2vec单词嵌入的文本情感分类器</h1>
                
            
            
                
<p class="mce-root">Word2vec是由Tomas Mikolov等人在2013年在谷歌开发的，作为使基于神经网络的嵌入训练更有效的回应，从那时起，它已经成为开发预训练单词嵌入的事实上的标准。</p>
<p class="mce-root">Word2vec介绍了以下两种不同的学习模型来学习单词嵌入:</p>
<ul class="calibre9">
<li class="calibre10"><strong class="calibre1"> CBOW </strong>:通过基于上下文预测当前单词来学习嵌入。</li>
<li class="calibre10"><strong class="calibre1">连续跳格</strong>:连续跳格模型通过预测给定当前单词的周围单词来学习。</li>
</ul>
<p class="mce-root">CBOW和Skip-Gram学习方法都集中在给定单词的本地使用上下文的情况下学习单词，其中单词本身的上下文由相邻单词的窗口来定义。该窗口是模型的可配置参数。</p>
<p class="mce-root">R中的<kbd class="calibre11">softmaxreg</kbd>库提供了预训练的<kbd class="calibre11">word2vec</kbd>单词嵌入，可以用来为亚马逊评论数据构建我们的情感分析引擎。预训练向量是使用<kbd class="calibre11">word2vec</kbd>模型构建的，它基于<kbd class="calibre11">Reuter_50_50</kbd>数据集，UCI机器学习库(<a href="https://archive.ics.uci.edu/ml/datasets/Reuter_50_50" class="calibre8">https://archive.ics.uci.edu/ml/datasets/Reuter_50_50</a>)。</p>
<p class="mce-root">让我们立即进入代码，并回顾代码中遵循的方法:</p>
<pre class="calibre16"># including the required library<br class="title-page-name"/>library(softmaxreg)<br class="title-page-name"/># importing the word2vec pretrained vector into memory<br class="title-page-name"/>data(word2vec)</pre>
<p class="mce-root">让我们检查一下<kbd class="calibre11">word2vec</kbd>的预训练程序。它只是另一个数据帧，因此可以通过常规的<kbd class="calibre11">dim</kbd>和<kbd class="calibre11">View</kbd>命令进行检查，如下所示:</p>
<pre class="calibre16">View(word2vec)</pre>
<p class="calibre23">这将导致以下输出:</p>
<p class="CDPAlignCenter1"><img class="aligncenter37" src="img/7a78e718-5842-47c2-ab0d-09a046f7ebe5.png"/></p>
<p class="mce-root">这里，让我们使用下面的<kbd class="calibre11">dim</kbd>命令:</p>
<pre class="calibre16">dim(word2vec)</pre>
<p class="mce-root">这将导致以下输出:</p>
<pre class="calibre16">[1] 12853 21</pre>
<p class="mce-root">从前面的输出中，我们可以观察到有<kbd class="calibre11">12853</kbd>个单词在预训练的向量中有单词向量。每个单词用20个维度来定义，这些维度定义了单词的上下文。在下一步中，我们可以为评论中的每个单词查找单词向量。因为在预训练单词嵌入中只有12，853个单词，所以我们有可能遇到预训练嵌入中不存在的单词。在这种情况下，未识别的单词用填充有零的20维向量来表示。</p>
<p class="mce-root">我们还需要理解，单词向量仅在单词级别可用，因此为了解码整个评论，我们取组成评论的单词的所有单词向量的平均值。让我们用一个例子来回顾一下从单个单词向量中获取句子的单词向量的概念。</p>
<p class="mce-root">假设我们想要得到单词矢量的句子是，<em class="calibre15">今天早上阳光明媚</em>。组成句子的个别词语有<em class="calibre15"> it </em>、<em class="calibre15"> is </em>、<em class="calibre15"> very </em>、<em class="calibre15"> bright </em>、<em class="calibre15"> and </em>、<em class="calibre15"> sunny </em>、<em class="calibre15"> this </em>和<em class="calibre15"> morning </em>。</p>
<p class="mce-root">现在，我们可以在预训练向量中查找这些单词中的每一个，并获得相应的单词向量，如下表所示:</p>
<table border="1" class="calibre17">
<tbody class="calibre18">
<tr class="calibre19">
<td class="calibre30">
<p class="CDPAlignCenter1"><strong class="calibre3">字</strong></p>
</td>
<td class="calibre31">
<p class="CDPAlignCenter1"><strong class="calibre3"> dim1 </strong></p>
</td>
<td class="calibre32">
<p class="CDPAlignCenter1"><strong class="calibre3"> dim2 </strong></p>
</td>
<td class="calibre32">
<p class="CDPAlignCenter1"><strong class="calibre3"> dim3 </strong></p>
</td>
<td class="calibre31">
<p class="mce-root"><strong class="calibre3">.....</strong></p>
</td>
<td class="calibre31">
<p class="mce-root"><strong class="calibre3">....</strong></p>
</td>
<td class="calibre33">
<p class="CDPAlignCenter1"><strong class="calibre3"> dim19 </strong></p>
</td>
<td class="calibre34">
<p class="CDPAlignCenter1"><strong class="calibre3"> dim20 </strong></p>
</td>
<td class="calibre35"/>
</tr>
<tr class="calibre19">
<td class="calibre30">
<p class="mce-root"><kbd class="calibre11">it</kbd></p>
</td>
<td class="calibre31">
<p class="mce-root">-2.25</p>
</td>
<td class="calibre32">
<p class="mce-root">0.75</p>
</td>
<td class="calibre32">
<p class="mce-root">1.75</p>
</td>
<td class="calibre31">
<p class="mce-root">-1.25</p>
</td>
<td class="calibre31">
<p class="mce-root">-0.25</p>
</td>
<td class="calibre33">
<p class="mce-root">-3.25</p>
</td>
<td class="calibre34">
<p class="mce-root">-2.25</p>
</td>
<td class="calibre35"/>
</tr>
<tr class="calibre19">
<td class="calibre30">
<p class="mce-root"><kbd class="calibre11">is</kbd></p>
</td>
<td class="calibre31">
<p class="mce-root">0.75</p>
</td>
<td class="calibre32">
<p class="mce-root">1.75</p>
</td>
<td class="calibre32">
<p class="mce-root">1.75</p>
</td>
<td class="calibre31">
<p class="mce-root">-2.25</p>
</td>
<td class="calibre31">
<p class="mce-root">-2.25</p>
</td>
<td class="calibre33">
<p class="mce-root">0.75</p>
</td>
<td class="calibre34">
<p class="mce-root">-0.25</p>
</td>
<td class="calibre35"/>
</tr>
<tr class="calibre19">
<td class="calibre30">
<p class="mce-root"><kbd class="calibre11">very</kbd></p>
</td>
<td class="calibre31">
<p class="mce-root">-2.25</p>
</td>
<td class="calibre32">
<p class="mce-root">2.75</p>
</td>
<td class="calibre32">
<p class="mce-root">1.75</p>
</td>
<td class="calibre31">
<p class="mce-root">-0.25</p>
</td>
<td class="calibre31">
<p class="mce-root">0.75</p>
</td>
<td class="calibre33">
<p class="mce-root">0.75</p>
</td>
<td class="calibre34">
<p class="mce-root">-2.25</p>
</td>
<td class="calibre35"/>
</tr>
<tr class="calibre19">
<td class="calibre30">
<p class="mce-root"><kbd class="calibre11">bright</kbd></p>
</td>
<td class="calibre31">
<p class="mce-root">-3.25</p>
</td>
<td class="calibre32">
<p class="mce-root">-3.25</p>
</td>
<td class="calibre32">
<p class="mce-root">-2.25</p>
</td>
<td class="calibre31">
<p class="mce-root">-1.25</p>
</td>
<td class="calibre31">
<p class="mce-root">0.75</p>
</td>
<td class="calibre33">
<p class="mce-root">1.75</p>
</td>
<td class="calibre34">
<p class="mce-root">-0.25</p>
</td>
<td class="calibre35"/>
</tr>
<tr class="calibre19">
<td class="calibre30">
<p class="mce-root"><kbd class="calibre11">and</kbd></p>
</td>
<td class="calibre31">
<p class="mce-root">-0.25</p>
</td>
<td class="calibre32">
<p class="mce-root">-1.25</p>
</td>
<td class="calibre32">
<p class="mce-root">-2.25</p>
</td>
<td class="calibre31">
<p class="mce-root">2.75</p>
</td>
<td class="calibre31">
<p class="mce-root">-3.25</p>
</td>
<td class="calibre33">
<p class="mce-root">-0.25</p>
</td>
<td class="calibre34">
<p class="mce-root">1.75</p>
</td>
<td class="calibre35"/>
</tr>
<tr class="calibre19">
<td class="calibre30">
<p class="mce-root"><kbd class="calibre11">sunny</kbd></p>
</td>
<td class="calibre31">
<p class="mce-root">0</p>
</td>
<td class="calibre32">
<p class="mce-root">0</p>
</td>
<td class="calibre32">
<p class="mce-root">0</p>
</td>
<td class="calibre31">
<p class="mce-root">0</p>
</td>
<td class="calibre31">
<p class="mce-root">0</p>
</td>
<td class="calibre33">
<p class="mce-root">0</p>
</td>
<td class="calibre34">
<p class="mce-root">0</p>
</td>
<td class="calibre35"/>
</tr>
<tr class="calibre19">
<td class="calibre30">
<p class="mce-root"><kbd class="calibre11">this</kbd></p>
</td>
<td class="calibre31">
<p class="mce-root">-2.25</p>
</td>
<td class="calibre32">
<p class="mce-root">-3.25</p>
</td>
<td class="calibre32">
<p class="mce-root">2.75</p>
</td>
<td class="calibre31">
<p class="mce-root">0.75</p>
</td>
<td class="calibre31">
<p class="mce-root">-0.25</p>
</td>
<td class="calibre33">
<p class="mce-root">-0.25</p>
</td>
<td class="calibre34">
<p class="mce-root">-0.25</p>
</td>
<td class="calibre35"/>
</tr>
<tr class="calibre19">
<td class="calibre30">
<p class="mce-root"><kbd class="calibre11">morning</kbd></p>
</td>
<td class="calibre31">
<p class="mce-root">-0.25</p>
</td>
<td class="calibre32">
<p class="mce-root">-3.25</p>
</td>
<td class="calibre32">
<p class="mce-root">-2.25</p>
</td>
<td class="calibre31">
<p class="mce-root">1.75</p>
</td>
<td class="calibre31">
<p class="mce-root">0.75</p>
</td>
<td class="calibre33">
<p class="mce-root">2.75</p>
</td>
<td class="calibre34">
<p class="mce-root">2.75</p>
</td>
<td class="calibre35"/>
</tr>
</tbody>
</table>
<p class="mce-root"> </p>
<p class="mce-root">现在，我们有了组成句子的词向量。请注意，这些不是实际的单词向量值，只是为了演示该方法而虚构的。此外，注意到单词<kbd class="calibre11">sunny</kbd>在维度上用零表示，以表示在预训练单词嵌入中没有找到该单词。为了得到句子的单词向量，我们只需计算每个维度的平均值。得到的向量是一个1 x 20的向量，表示句子，如下所示:</p>
<table border="1" class="calibre17">
<tbody class="calibre18">
<tr class="calibre19">
<td class="calibre36">
<p class="mce-root">句子</p>
</td>
<td class="calibre36">
<p class="mce-root">-1.21875</p>
</td>
<td class="calibre36">
<p class="mce-root">-0.71875</p>
</td>
<td class="calibre36">
<p class="mce-root">0.15625</p>
</td>
<td class="calibre36">
<p class="mce-root">0.03125</p>
</td>
<td class="calibre36">
<p class="mce-root">-0.46875</p>
</td>
<td class="calibre36">
<p class="mce-root">0.28125</p>
</td>
<td class="calibre36">
<p class="mce-root">-0.09375</p>
</td>
</tr>
</tbody>
</table>
<p class="mce-root"><kbd class="calibre11">softmaxreg</kbd>库提供了<kbd class="calibre11">wordEmbed</kbd>函数，我们可以传递一个句子，并要求它计算这个句子的<kbd class="calibre11">mean</kbd>单词向量。下面的代码是一个定制函数，创建它是为了将<kbd class="calibre11">wordEmbed</kbd>函数应用到我们手头的每个亚马逊评论上。在将这个函数应用于评论数据集的最后，我们期望得到一个<em class="calibre15"> n </em> x 20矩阵，这是我们的评论的词向量表示。<em class="calibre15"> n </em> x 20中的<em class="calibre15"> n </em>表示行数，20是表示每个审核的维度数，如以下代码所示:</p>
<pre class="calibre16"># function to get word vector for each review<br class="title-page-name"/>docVectors = function(x)<br class="title-page-name"/>{<br class="title-page-name"/>  wordEmbed(x, word2vec, meanVec = TRUE)<br class="title-page-name"/>}<br class="title-page-name"/># setting the working directory and reading the reviews dataset<br class="title-page-name"/>setwd('/home/sunil/Desktop/sentiment_analysis/')<br class="title-page-name"/>text = read.csv(file='Sentiment Analysis Dataset.csv', header = TRUE)<br class="title-page-name"/># applying the docVector function on each of the reviews<br class="title-page-name"/># storing the matrix of word vectors as temp<br class="title-page-name"/>temp=t(sapply(text$SentimentText, docVectors))<br class="title-page-name"/># visualizing the word vectors output<br class="title-page-name"/>View(temp)</pre>
<p class="mce-root">这将导致以下输出:</p>
<p class="CDPAlignCenter1"><img class="aligncenter38" src="img/af33d08a-c790-4859-ae29-5e9f48ab5d29.png"/></p>
<p class="mce-root">然后我们使用<kbd class="calibre11">dim</kbd>命令检查<kbd class="calibre11">temp</kbd>，如下所示:</p>
<pre class="calibre16">dim(temp)</pre>
<p class="mce-root">这将导致以下输出:</p>
<pre class="calibre16">1000 20</pre>
<p class="mce-root">我们可以从输出中看到，我们为语料库中的每个评论创建了词向量。该数据框现在可用于使用ML算法构建分类模型。以下实现分类的代码与我们为BoW方法所做的代码没有什么不同:</p>
<pre class="calibre16"># splitting the dataset into train and test<br class="title-page-name"/>temp_train=temp[1:800,]<br class="title-page-name"/>temp_test=temp[801:1000,]<br class="title-page-name"/>labels_train=as.factor(as.character(text[1:800,]$Sentiment))<br class="title-page-name"/>labels_test=as.factor(as.character(text[801:1000,]$Sentiment))<br class="title-page-name"/># including the random forest library<br class="title-page-name"/>library(randomForest)<br class="title-page-name"/># training a model using random forest classifier with training dataset<br class="title-page-name"/># observe that we are using 20 trees to create the model<br class="title-page-name"/>rf_senti_classifier=randomForest(temp_train, labels_train,ntree=20)<br class="title-page-name"/>print(rf_senti_classifier)</pre>
<p class="mce-root">这将导致以下输出:</p>
<pre class="calibre16">randomForest(x = temp_train, y = labels_train, ntree = 20)<br class="title-page-name"/>               Type of random forest: classification<br class="title-page-name"/>                     Number of trees: 20<br class="title-page-name"/>No. of variables tried at each split: 4<br class="title-page-name"/>        OOB estimate of  error rate: 44.25%<br class="title-page-name"/>Confusion matrix:<br class="title-page-name"/>    1   2 class.error<br class="title-page-name"/>1 238 172   0.4195122<br class="title-page-name"/>2 182 208   0.4666667</pre>
<p class="mce-root">前面的输出显示随机森林模型对象已成功创建。当然，模型还可以进一步改进；然而，我们不打算在这里这样做，因为重点是演示如何利用单词嵌入，而不是获得最佳性能的分类器。</p>
<p class="mce-root">接下来，通过下面的代码，我们利用随机森林模型对测试数据进行预测，然后报告性能:</p>
<pre class="calibre16"># making predictions on the dataset<br class="title-page-name"/>rf_predicts&lt;-predict(rf_senti_classifier, temp_test)<br class="title-page-name"/>library(rminer)<br class="title-page-name"/>print(mmetric(rf_predicts, labels_test, c("ACC")))</pre>
<p class="mce-root">这将导致以下输出:</p>
<pre class="calibre16">[1] 62.5</pre>
<p class="mce-root">我们看到，从路透社新闻组的数据集中使用预训练的<kbd class="calibre11">word2vec</kbd>嵌入，我们获得了62%的准确率。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Building a text sentiment classifier with GloVe word embedding</title>
    <meta content="urn:uuid:715f2a86-adaf-48a1-98a4-3c219c63f667" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">利用手套词嵌入构建文本情感分类器</h1>
                
            
            
                
<p class="mce-root">斯坦福大学的Pennington等人开发了一种对<kbd class="calibre11">word2vec</kbd>方法的扩展，称为用于单词表示的<strong class="calibre3">全局向量</strong> ( <strong class="calibre3">手套</strong>)，用于有效地学习单词向量。</p>
<p class="mce-root">GloVe将矩阵分解技术(如LSA)的全局统计与<kbd class="calibre11">word2vec</kbd>中基于局部上下文的学习相结合。此外，与<kbd class="calibre11">word2vec</kbd>不同，GloVe不使用窗口来定义本地上下文，而是使用整个文本语料库的统计数据来构建显式的单词上下文或单词共现矩阵。作为效果，学习模型通常产生更好的单词嵌入。</p>
<p class="mce-root">R中的<kbd class="calibre11">text2vec</kbd>库有一个GloVe实现，我们可以用它来训练从我们自己的训练语料库中获得单词嵌入。或者，预训练的手套单词嵌入可以被下载和重用，类似于我们在前面章节中的早期<kbd class="calibre11">word2vec</kbd>预训练嵌入项目中所做的。</p>
<p class="mce-root">下面的代码块演示了如何创建GloVe单词嵌入，并将其用于情感分析，或者任何文本分类任务。我们不打算明确讨论所涉及的步骤，因为代码中已经对每个步骤进行了详细的解释:</p>
<pre class="calibre16"># including the required library<br class="title-page-name"/>library(text2vec)<br class="title-page-name"/># setting the working directory<br class="title-page-name"/>setwd('/home/sunil/Desktop/sentiment_analysis/')<br class="title-page-name"/># reading the dataset<br class="title-page-name"/>text = read.csv(file='Sentiment Analysis Dataset.csv', header = TRUE)<br class="title-page-name"/># subsetting only the review text so as to create Glove word embedding<br class="title-page-name"/>wiki = as.character(text$SentimentText)<br class="title-page-name"/># Create iterator over tokens<br class="title-page-name"/>tokens = space_tokenizer(wiki)<br class="title-page-name"/># Create vocabulary. Terms will be unigrams (simple words).<br class="title-page-name"/>it = itoken(tokens, progressbar = FALSE)<br class="title-page-name"/>vocab = create_vocabulary(it)<br class="title-page-name"/># consider a term in the vocabulary if and only if the term has appeared aleast three times in the dataset<br class="title-page-name"/>vocab = prune_vocabulary(vocab, term_count_min = 3L)<br class="title-page-name"/># Use the filtered vocabulary<br class="title-page-name"/>vectorizer = vocab_vectorizer(vocab)<br class="title-page-name"/># use window of 5 for context words and create a term co-occurance matrix<br class="title-page-name"/>tcm = create_tcm(it, vectorizer, skip_grams_window = 5L)<br class="title-page-name"/># create the glove embedding for each each in the vocab and<br class="title-page-name"/># the dimension of the word embedding should set to 50<br class="title-page-name"/># x_max is the maximum number of co-occurrences to use in the weighting<br class="title-page-name"/># function<br class="title-page-name"/># note that training the word embedding is time consuming - be patient<br class="title-page-name"/>glove = GlobalVectors$new(word_vectors_size = 50, vocabulary = vocab, x_max = 100)<br class="title-page-name"/>wv_main = glove$fit_transform(tcm, n_iter = 10, convergence_tol = 0.01)</pre>
<p class="mce-root">这将导致以下输出:</p>
<pre class="calibre16">INFO [2018-10-30 06:58:14] 2018-10-30 06:58:14 - epoch 1, expected cost 0.0231<br class="title-page-name"/>INFO [2018-10-30 06:58:15] 2018-10-30 06:58:15 - epoch 2, expected cost 0.0139<br class="title-page-name"/>INFO [2018-10-30 06:58:15] 2018-10-30 06:58:15 - epoch 3, expected cost 0.0114<br class="title-page-name"/>INFO [2018-10-30 06:58:15] 2018-10-30 06:58:15 - epoch 4, expected cost 0.0100<br class="title-page-name"/>INFO [2018-10-30 06:58:15] 2018-10-30 06:58:15 - epoch 5, expected cost 0.0091<br class="title-page-name"/>INFO [2018-10-30 06:58:15] 2018-10-30 06:58:15 - epoch 6, expected cost 0.0084<br class="title-page-name"/>INFO [2018-10-30 06:58:16] 2018-10-30 06:58:16 - epoch 7, expected cost 0.0079<br class="title-page-name"/>INFO [2018-10-30 06:58:16] 2018-10-30 06:58:16 - epoch 8, expected cost 0.0074<br class="title-page-name"/>INFO [2018-10-30 06:58:16] 2018-10-30 06:58:16 - epoch 9, expected cost 0.0071<br class="title-page-name"/>INFO [2018-10-30 06:58:16] 2018-10-30 06:58:16 - epoch 10, expected cost 0.0068</pre>
<p class="mce-root">下面使用<kbd class="calibre11">glove</kbd>模型来获得组合单词向量:</p>
<pre class="calibre16"># Glove model learns two sets of word vectors - main and context.<br class="title-page-name"/># both matrices may be added to get the combined word vector<br class="title-page-name"/>wv_context = glove$components<br class="title-page-name"/>word_vectors = wv_main + t(wv_context)<br class="title-page-name"/># converting the word_vector to a dataframe for visualization<br class="title-page-name"/>word_vectors=data.frame(word_vectors)<br class="title-page-name"/># the word for each embedding is set as row name by default<br class="title-page-name"/># using the tibble library rownames_to_column function, the rownames is copied as first column of the dataframe<br class="title-page-name"/># we also name the first column of the dataframe as words<br class="title-page-name"/>library(tibble)<br class="title-page-name"/>word_vectors=rownames_to_column(word_vectors, var = "words")<br class="title-page-name"/>View(word_vectors)</pre>
<p class="mce-root">这将导致以下输出:</p>
<p class="CDPAlignCenter1"><img class="aligncenter39" src="img/644b36df-c202-4d9a-9433-2579473dd24a.png"/></p>
<p class="mce-root">我们利用<kbd class="calibre11">softmaxreg</kbd>库来获得每个评论的平均词向量。这类似于我们在上一节的<kbd class="calibre11">word2vec</kbd>预训练嵌入中所做的。注意，我们正在将我们自己的训练词嵌入<kbd class="calibre11">word_vectors</kbd>传递给<kbd class="calibre11">wordEmbed()</kbd>函数，如下所示:</p>
<pre class="calibre16">library(softmaxreg)<br class="title-page-name"/>docVectors = function(x)<br class="title-page-name"/>{<br class="title-page-name"/>  wordEmbed(x, word_vectors, meanVec = TRUE)<br class="title-page-name"/>}<br class="title-page-name"/># applying the function docVectors function on the entire reviews dataset<br class="title-page-name"/># this will result in word embedding representation of the entire reviews # dataset<br class="title-page-name"/>temp=t(sapply(text$SentimentText, docVectors))<br class="title-page-name"/>View(temp)</pre>
<p class="mce-root">这将导致以下输出:</p>
<p class="CDPAlignCenter1"><img class="aligncenter40" src="img/c48d11a0-df92-4dfa-8ee4-910afd3931bf.png"/></p>
<p class="mce-root">我们现在将数据集分成训练和测试部分，并使用<kbd class="calibre11">randomforest</kbd>库来构建一个模型进行训练，如以下代码行所示:</p>
<pre class="calibre16"># splitting the dataset into train and test portions<br class="title-page-name"/>temp_train=temp[1:800,]<br class="title-page-name"/>temp_test=temp[801:1000,]<br class="title-page-name"/>labels_train=as.factor(as.character(text[1:800,]$Sentiment))<br class="title-page-name"/>labels_test=as.factor(as.character(text[801:1000,]$Sentiment))<br class="title-page-name"/># using randomforest to build a model on train data<br class="title-page-name"/>library(randomForest)<br class="title-page-name"/>rf_senti_classifier=randomForest(temp_train, labels_train,ntree=20)<br class="title-page-name"/>print(rf_senti_classifier)</pre>
<p class="mce-root">这将导致以下输出:</p>
<pre class="calibre16">Call:<br class="title-page-name"/> randomForest(x = temp_train, y = labels_train, ntree = 20)<br class="title-page-name"/>               Type of random forest: classification<br class="title-page-name"/>                     Number of trees: 20<br class="title-page-name"/>No. of variables tried at each split: 7<br class="title-page-name"/><br class="title-page-name"/><br class="title-page-name"/>        OOB estimate of  error rate: 42.12%<br class="title-page-name"/>Confusion matrix:<br class="title-page-name"/>    1   2 class.error<br class="title-page-name"/>1 250 160   0.3902439<br class="title-page-name"/>2 177 213   0.4538462</pre>
<p class="mce-root">然后，我们使用创建的随机森林模型来预测标签，如下所示:</p>
<pre class="calibre16"># predicting labels using the randomforest model created<br class="title-page-name"/>rf_predicts&lt;-predict(rf_senti_classifier, temp_test)<br class="title-page-name"/># estimating the accuracy from the predictions<br class="title-page-name"/>library(rminer)<br class="title-page-name"/>print(mmetric(rf_predicts, labels_test, c("ACC")))</pre>
<p class="mce-root">这将导致以下输出:</p>
<pre class="calibre16">[1] 66.5</pre>
<p class="mce-root">通过这种方法，我们获得了66%的准确率。尽管事实上单词嵌入是从仅仅1000个文本样本中的单词中获得的。通过使用预训练嵌入，可以进一步改进该模型。使用预训练嵌入的总体框架与我们在上一节的<kbd class="calibre11">word2vec</kbd>项目中所做的保持一致。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Building a text sentiment classifier with fastText</title>
    <meta content="urn:uuid:715f2a86-adaf-48a1-98a4-3c219c63f667" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">用fastText构建文本情感分类器</h1>
                
            
            
                
<p class="mce-root"><kbd class="calibre11">fastText</kbd>是一个库，是<kbd class="calibre11">word2vec</kbd>的扩展，用于单词表示。它是由脸书研究团队在2016年创建的。虽然Word2vec和GloVe方法将单词作为训练的最小单位，但fastText将单词分成几个n元语法，即子单词。例如，单词apple的三元组是app、ppl和ple。单词apple的单词embedding是所有单词n-grams的总和。由于算法嵌入生成的性质，fastText需要更多的资源，并且需要额外的时间来训练。<kbd class="calibre11">fastText</kbd>的一些优势如下:</p>
<ul class="calibre9">
<li class="calibre10">它为罕见的单词(包括拼写错误的单词)生成更好的单词嵌入。</li>
<li class="calibre10">对于词汇之外的单词，fastText可以从单词的字符n-grams中构造单词的向量，即使单词没有出现在训练语料库中。这对于Word2vec和GloVe来说都是不可能的。</li>
</ul>
<p class="mce-root"><kbd class="calibre11">fastTextR</kbd>库提供了一个到fastText的接口。让我们利用项目中的<kbd class="calibre11">fastTextR</kbd>库来构建一个关于亚马逊评论的情感分析引擎。虽然可以下载预训练的fastText单词嵌入并将其用于我们的项目，但让我们尝试基于我们手头的评论数据集来训练单词嵌入。应该注意的是，利用fastText预训练单词嵌入的方法类似于我们之前处理的基于<kbd class="calibre11">word2vec</kbd>的项目中遵循的方法。</p>
<p class="mce-root">与上一节中介绍的项目类似，注释包含在代码中。这些评论解释了在这个项目中构建亚马逊评论情感分析器所采用的方法。现在让我们来看看下面的代码:</p>
<pre class="calibre16"># loading the required libary<br class="title-page-name"/>library(fastTextR)<br class="title-page-name"/># setting the working directory<br class="title-page-name"/>setwd('/home/sunil/Desktop/sentiment_analysis/')<br class="title-page-name"/># reading the input reviews file<br class="title-page-name"/># recollect that fastText needs the file in a specific format and we created one compatiable file in<br class="title-page-name"/># "Understanding the Amazon Reviews Dataset" section of this chaptertext = readLines("Sentiment Analysis Dataset_ft.txt")<br class="title-page-name"/># Viewing the text vector for conformation<br class="title-page-name"/>View(text)</pre>
<p class="mce-root">这将导致以下输出:</p>
<p class="CDPAlignCenter1"><img class="aligncenter41" src="img/26daddc5-2f6b-4dbf-b95a-0b13ec3705a7.png"/></p>
<p class="mce-root">现在，让我们将评论分为训练和测试数据集，并使用以下代码行查看它们:</p>
<pre class="calibre16"># dividing the reviews into training and test<br class="title-page-name"/>temp_train=text[1:800]temp_test=text[801:1000]<br class="title-page-name"/># Viewing the train datasets for confirmation<br class="title-page-name"/>View(temp_train)</pre>
<p class="mce-root">这将产生以下输出:</p>
<p class="CDPAlignCenter1"><img src="img/e27d1e8e-4ef3-48da-853a-807bf9c58c63.png" class="calibre37"/></p>
<p class="CDPAlignLeft1">使用以下代码查看测试数据集:</p>
<pre class="CDPAlignLeft2">View(temp_test)</pre>
<p class="mce-root">这将产生以下输出:</p>
<p class="CDPAlignCenter1"><img class="aligncenter42" src="img/eed25069-abad-4348-bac7-0b4b5b15f278.png"/></p>
<p class="mce-root">我们现在将使用以下代码为训练和测试数据集创建一个<kbd class="calibre11">.txt</kbd>文件:</p>
<pre class="calibre16"># creating txt file for train and test dataset<br class="title-page-name"/># the fasttext function expects files to be passed for training and testing<br class="title-page-name"/>fileConn&lt;-file("/home/sunil/Desktop/sentiment_analysis/train.ft.txt")<br class="title-page-name"/>writeLines(temp_train, fileConn)<br class="title-page-name"/>close(fileConn)<br class="title-page-name"/>fileConn&lt;-file("/home/sunil/Desktop/sentiment_analysis/test.ft.txt")<br class="title-page-name"/>writeLines(temp_test, fileConn)<br class="title-page-name"/>close(fileConn)<br class="title-page-name"/># creating a test file with no labels<br class="title-page-name"/># recollect the original test dataset has labels in it<br class="title-page-name"/># as the dataset is just a subset obtained from full dataset<br class="title-page-name"/>temp_test_nolabel&lt;- gsub("__label__1", "", temp_test, perl=TRUE)<br class="title-page-name"/>temp_test_nolabel&lt;- gsub("__label__2", "", temp_test_nolabel, perl=TRUE)</pre>
<p class="mce-root">现在，我们将使用以下命令查看无标签测试数据集以进行确认:</p>
<pre class="calibre16">View(temp_test_nolabel)</pre>
<p class="mce-root">这将导致以下输出:</p>
<p class="CDPAlignCenter1"><img class="aligncenter43" src="img/b70533eb-7e36-4f83-a262-00279dcf2f66.png"/></p>
<p class="mce-root">现在，让我们将无标签测试数据集写入一个文件，以便我们可以使用它进行测试，如下所示:</p>
<pre class="calibre16">fileConn&lt;-file("/home/sunil/Desktop/sentiment_analysis/test_nolabel.ft.txt")<br class="title-page-name"/>writeLines(temp_test_nolabel, fileConn)<br class="title-page-name"/>close(fileConn)<br class="title-page-name"/># training a supervised classification model with training dataset file<br class="title-page-name"/>model&lt;-fasttext("/home/sunil/Desktop/sentiment_analysis/train.ft.txt",<br class="title-page-name"/>method = "supervised", control = ft.control(nthreads = 3L))<br class="title-page-name"/># Obtain all the words from a previously trained model=<br class="title-page-name"/>words&lt;-get_words(model)<br class="title-page-name"/># viewing the words for confirmation. These are the set of words present  # in our training data<br class="title-page-name"/>View(words)</pre>
<p class="mce-root">这将导致以下输出:</p>
<p class="CDPAlignCenter1"><img class="aligncenter44" src="img/fa10b4e0-e95f-4b37-b32f-191a4f03d45f.png"/></p>
<p class="mce-root">现在，我们将从之前训练的模型中获取单词向量，并查看训练数据集中每个单词的单词向量，如下所示:</p>
<pre class="calibre16"># Obtain word vectors from a previously trained model.<br class="title-page-name"/>word_vec&lt;-get_word_vectors(model, words)<br class="title-page-name"/># Viewing the word vectors for each word in our training dataset<br class="title-page-name"/># observe that the word embedding dimension is 5<br class="title-page-name"/>View(word_vec)</pre>
<p class="mce-root">这将导致以下输出:</p>
<p class="CDPAlignCenter1"><img class="aligncenter45" src="img/7a2104e3-a082-4b1b-b99b-d0b9c33536ed.png"/></p>
<p class="mce-root">我们将预测无标签测试数据集中评论的标签，并将其写入文件以供将来参考。然后，我们会将预测放入数据框中，以计算性能，并使用以下代码行查看准确度的估计值:</p>
<pre class="calibre16"># predicting the labels for the reviews in the no labels test dataset<br class="title-page-name"/># and writing it to a file for future reference<br class="title-page-name"/>predict(model, newdata_file= "/home/sunil/Desktop/sentiment_analysis/test_nolabel.ft.txt",result_file="/home/sunil/Desktop/sentiment_analysis/fasttext_result.txt")<br class="title-page-name"/># getting the predictions into a dataframe so as to compute performance   # measurementft_preds&lt;-predict(model, newdata_file= "/home/sunil/Desktop/sentiment_analysis/test_nolabel.ft.txt")<br class="title-page-name"/># reading the test file to extract the actual labels<br class="title-page-name"/>reviewstestfile&lt;<br class="title-page-name"/>readLines("/home/sunil/Desktop/sentiment_analysis/test.ft.txt")<br class="title-page-name"/># extracting just the labels frm each line<br class="title-page-name"/>library(stringi)<br class="title-page-name"/>actlabels&lt;-stri_extract_first(reviewstestfile, regex="\\w+")<br class="title-page-name"/># converting the actual labels and predicted labels into factors<br class="title-page-name"/>actlabels&lt;-as.factor(as.character(actlabels))<br class="title-page-name"/>ft_preds&lt;-as.factor(as.character(ft_preds))<br class="title-page-name"/># getting the estimate of the accuracy<br class="title-page-name"/>library(rminer)<br class="title-page-name"/>print(mmetric(actlabels, ft_preds, c("ACC")))</pre>
<p class="mce-root">这将导致以下输出:</p>
<pre class="calibre16">[1] 58</pre>
<p class="mce-root">在我们的评论数据上，使用<kbd class="calibre11">fastText</kbd>方法，我们有58%的准确率。下一步，我们可以检查是否可以通过使用fastText预训练单词嵌入来进一步提高准确性。正如我们已经知道的，通过使用预训练嵌入来实现一个项目与我们在本章前面部分描述的<kbd class="calibre11">word2vec</kbd>项目中遵循的实现没有太大的不同。不同之处仅仅在于，需要丢弃获得单词嵌入的训练步骤，并且该项目代码中包含的代码中的模型变量应该用预训练的单词嵌入来初始化。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Summary</title>
    <meta content="urn:uuid:715f2a86-adaf-48a1-98a4-3c219c63f667" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">摘要</h1>
                
            
            
                
<p class="mce-root">在本章中，我们学习了各种NLP技术，即BoW、Word2vec、GloVe和fastText。我们构建了涉及这些技术的项目来对亚马逊评论数据集进行情感分析。构建的项目涉及两种方法，利用预训练的单词嵌入和从我们自己的数据集构建单词嵌入。我们尝试了这两种方法，以一种可以被ML算法使用的格式来表示文本，这种算法产生了能够执行情感分析的模型。</p>
<p class="mce-root">在下一章中，我们将通过使用批发数据集来了解客户细分。我们将客户细分视为一个无人监管的问题，并利用各种技术构建项目，这些技术可以识别电子商务公司客户群中的固有群体。来，我们一起探索用ML构建电商客户细分引擎的世界！</p>


            

            
        
    </body>

</html>
</body></html>