# 八、神经网络与深度学习

在这本书中，我们讨论了很多关于训练或教学机器来进行预测的问题。为此，我们采用了各种有用且有趣的算法，包括各种类型的回归、决策树和最近邻。然而，让我们后退一步，想想如果我们试图做出准确的预测和了解数据，我们想模仿什么样的实体。

这个问题最明显的答案是我们应该模仿自己的大脑。作为人类，我们有一种识别物体、预测数量、识别欺诈等的自然能力，而这些都是我们希望机器人工完成的事情。诚然，我们在这些活动上并不完美，但我们相当出色！

这种思维方式导致了**人工神经网络**（也称为**神经网络**或**神经网络**的发展）。这些模型试图大致模拟我们大脑中的某些结构，例如**神经元**。它们在各个行业都取得了广泛的成功，目前正被应用于解决各种有趣的问题。

近年来，越来越专业化和复杂化的神经网络引起了人们的兴趣和关注。这些神经网络属于**深度学习**的范畴，通常具有比常规神经网络更深的**结构。也就是说，它们有许多隐藏的结构层，可以使用数千万个参数或权重进行参数化。**

在本章中，我们将尝试介绍基于 Go 的神经网络和深度学习模型。这些主题非常广泛，而且有整本关于深度学习的书。因此，我们在这里只触及表面。也就是说，以下内容应该为您在 Go 中构建神经网络提供一个坚实的起点。

# 理解神经网络术语

有各种各样的神经网络口味，每种口味都有自己的行话。然而，不管我们使用的是哪种类型的神经网络，我们都应该知道一些常见的术语。以下几点介绍了这一术语：

*   **节点**、**感知器**或**神经元**：这些可互换的术语指的是神经网络的基本构建块。每个节点或神经元接收输入数据并对该数据执行操作。执行操作后，节点/神经元可能会也可能不会将操作结果传递给其他节点/神经元。
*   **激活**：与节点操作相关的输出或值。
*   **激活功能**：将节点的输入转换为输出或激活的功能定义。
*   **权重**或**偏差**：这些值定义激活函数中输入和输出数据之间的关系。
*   **输入层**：神经网络的输入层包括一系列将初始输入带入神经网络模型的节点（例如一系列特征或属性）。
*   **输出层**：神经网络的输出层包括一系列节点，这些节点接收神经网络内部传递的信息并将其转换为最终输出。
*   **隐藏层**：神经网络的这些层存在于输入和输出层之间，因此对外部输入或输出**隐藏**。
*   **前馈**或**前馈**：这是指将数据馈入神经网络的输入层，并向前传输到输出层（无任何循环）的场景。
*   **反向传播：**这是一种训练神经网络模型的方法，包括通过网络前馈值，计算产生的误差，然后将基于这些误差的变化传递回网络。
*   **架构**：神经元在神经网络中如何连接在一起的整体结构称为**架构**。

为了巩固这些概念，考虑以下神经网络的示意图：

![](img/00069.jpeg)

这是一个基本的前馈（即非循环或递归）神经网络。它有两个隐藏层，接受两个输入，并输出两个类值（或结果）。

如果这些行话现在看起来有点让人难以接受，别担心。接下来，我们将看到一个具体的例子，它将使所有这些碎片凝固。此外，如果你在本章中列举了各种各样的例子，并对术语感到困惑，请在这里打圈作为提醒。

# 构建一个简单的神经网络

许多神经网络包和神经网络应用程序将模型视为**黑箱**。也就是说，人们倾向于利用一些框架，允许他们使用一组默认值和自动化快速构建神经网络。他们通常能够产生一些结果，但这种便利通常不能建立关于模型实际如何工作的很多直觉。因此，当模型的行为不符合预期时，很难理解它们为什么会做出奇怪的预测或难以收敛。

在进入更复杂的神经网络之前，让我们先建立一些关于神经网络的基本直觉，这样我们就不会陷入这种模式。我们将从头开始构建一个简单的神经网络，以了解神经网络的基本组成部分以及它们如何协同工作。

**Note**: that even though we are going to build our neural net from scratch here (which you may also want to do in certain scenarios), there are a variety of Go packages that help you build, train, and make predictions with neural networks. These include `github.com/tleyden/neurgo`, `github.com/fxsjy/gonn`, `github.com/NOX73/go-neural`, `github.com/milosgajdos83/gosom`, `github.com/made2591/go-perceptron-go`, and `github.com/chewxy/gorgonia`.

在本章中，我们将利用神经网络进行分类。然而，神经网络也可以用来进行回归。您可以在此处了解有关该主题的更多信息：[https://heuristically.wordpress.com/2011/11/17/using-neural-network-for-regression/](https://heuristically.wordpress.com/2011/11/17/using-neural-network-for-regression/) 。

# 网络中的节点

我们的神经网络的节点或神经元本身具有相对简单的功能。每个神经元将接受一个或多个值（*x<sub class="calibre25">1</sub>*、*x<sub class="calibre25">2</sub>*等），根据激活函数组合这些值，并产生单个输出。以下是图中的输出：

![](img/00070.jpeg)

我们到底应该如何组合输入以获得输出？嗯，我们需要一种方法来组合可调整的输入（这样我们可以训练模型），我们已经看到，使用系数和截距组合变量是组合输入的一种可训练的方法。回想一下[第四章](04.html#2F4UM0-a5604e9f48ea4e63828d369cca8f0939)、*回归*。本着这种精神，我们将把输入与一些系数（**权重**和一个截距（**偏差**进行线性组合）：

![](img/00071.jpeg)

这里，*w<sub class="calibre25">1</sub>**w<sub class="calibre25">2</sub>*等是我们的权重，*b*是偏差。

这种输入组合是一个良好的开端，但在一天结束时是线性的，因此无法对输入和输出之间的非线性关系建模。为了引入一些非线性，我们将对输入的线性组合应用一个激活函数。我们在这里使用的激活函数类似于[第 5 章](05.html#2TEN40-a5604e9f48ea4e63828d369cca8f0939)、*分类*中介绍的逻辑函数。在神经网络的上下文中，逻辑函数以以下形式称为**乙状结肠****函数**：

![](img/00072.jpeg)

`sigmoid`函数在我们的节点中使用是一个很好的选择，因为它引入了非线性，但它也有一个有限的范围（介于*0*和*1*之间），有一个简单定义的导数（我们将在网络训练期间使用），并且它可以有一个概率解释（如中进一步讨论的）[第 5 章](05.html#2TEN40-a5604e9f48ea4e63828d369cca8f0939)、*分类*。

`sigmoid`函数绝不是神经网络中激活函数的唯一选择。其他流行的选择包括双曲正切函数、softmax 和校正线性单位。激活函数的选择及其优缺点将在[中进一步讨论 https://medium.com/towards-data-science/activation-functions-and-its-types-which-is-better-a9a5310cc8f](https://medium.com/towards-data-science/activation-functions-and-its-types-which-is-better-a9a5310cc8f) 。

让我们继续定义我们的激活函数及其导数。以下代码中显示了这些定义：

```go
// sigmoid implements the sigmoid function
// for use in activation functions.
func sigmoid(x float64) float64 {
    return 1.0 / (1.0 + math.Exp(-x))
}

// sigmoidPrime implements the derivative
// of the sigmoid function for backpropagation.
func sigmoidPrime(x float64) float64 {
    return x * (1.0 - x)
}
```

# 网络体系结构

我们将要建立的简单神经网络将包含一个输入和输出层（就像任何神经网络一样）。网络将在输入层和输出层之间包含一个隐藏层。该体系结构描述如下：

![](img/00073.jpeg)

特别是，我们将在输入层中包含四个节点，在隐藏层中包含三个节点，在输出层中包含三个节点。输入层中的四个节点对应于我们要输入到网络中的属性数。把这四个输入想象成我们在[第 5 章](05.html#2TEN40-a5604e9f48ea4e63828d369cca8f0939)、*分类*中用来分类鸢尾花的四个测量值。输出层将有三个节点，因为我们将建立我们的网络来对鸢尾花进行分类，这可能是三个类中的一个。

现在，关于隐藏层——为什么我们要使用一个包含三个节点的隐藏层？嗯，一个隐藏层对于大多数简单任务来说已经足够了。如果您的数据中存在大量非线性、大量输入和/或大量培训数据，则可能需要引入更多隐藏层（本章后面将进一步讨论深度学习）。隐藏层中三个节点的选择可以根据评估指标和少量尝试和错误进行调整。您还可以搜索隐藏层中的节点数，以自动进行选择。

请记住，您在隐藏层中引入的节点越多，您的网络就越能完美地学习您的训练集。换句话说，您将自己置于过度拟合模型的危险中，以至于模型无法概括。当添加这种复杂情况时，非常仔细地验证模型以确保其通用性是很重要的。

# 为什么我们希望这种架构能够工作？

让我们暂停片刻，思考一下为什么在前面的安排中设置一系列节点可以让我们预测一些事情。正如你们所看到的，我们所做的一切就是反复组合输入，以产生一些结果。我们怎么能期望这个结果在进行二元分类时有用呢？

那么，当我们定义一个二元分类问题，或者任何分类或回归问题时，我们到底是什么意思？我们基本上是说，我们期望在一系列输入（我们的属性）和输出（我们的标签或响应）之间存在一些规则或关系。本质上，我们是说存在一些简单或复杂的功能，能够将我们的属性转换为我们所追求的响应或标签。

我们可以选择一种函数类型，它可以模拟属性到输出的转换，就像我们在线性或逻辑回归中所做的那样。然而，我们也可以建立一系列链式和可调整的函数，我们可以通过算法训练来检测输入和输出之间的关系和规则。这就是我们用神经网络所做的！

神经网络的节点就像子函数一样，在模拟我们提供的输入和输出之间的规则和关系之前都会进行调整，而不管这些规则和关系实际上是什么（线性、非线性、动态等等）。如果输入和输出之间存在潜在的规则，则可能存在一些可以模拟这些规则的神经网络。

# 训练我们的神经网络

好了，现在我们有了一些很好的动机来解释为什么节点的组合可以帮助我们做出预测。我们实际上如何根据一些输入数据调整神经网络节点的所有子函数？答案称为**反向传播**。

反向传播是一种训练神经网络的方法，它涉及在一系列**时期**（或暴露于我们的训练数据集）重复进行以下操作：

*   通过神经网络将我们的训练数据向前传送，以计算输出
*   计算输出中的错误
*   使用梯度下降法（或其他相关方法）确定如何根据误差改变权重和偏差
*   将这些权重/偏差变化反向传播到网络中

我们将在稍后实施此过程，并讨论一些细节。然而，在[附录](08.html)、*与机器学习相关的算法/技术*中对梯度下降等某些内容进行了更详细的介绍。

这种训练神经网络的反向传播方法在建模世界中是普遍存在的，但是有很多独特的网络结构和方法，我们在这里没有足够的篇幅来介绍。神经网络是学术界和工业界研究的一个活跃领域。

首先，让我们定义一个结构`neuralNetConfig`，它将包含定义我们的网络体系结构的所有参数，以及我们将如何进行反向传播迭代。我们还要定义一个结构`neuralNet`，它将包含定义经过训练的神经网络的所有信息。稍后，我们将利用经过训练的`neuralNet`值进行预测。以下代码中显示了这些定义：

```go
// neuralNet contains all of the information
// that defines a trained neural network.
type neuralNet struct {
    config neuralNetConfig
    wHidden *mat.Dense
    bHidden *mat.Dense
    wOut *mat.Dense
    bOut *mat.Dense
}

// neuralNetConfig defines our neural network
// architecture and learning parameters.
type neuralNetConfig struct {
    inputNeurons int
    outputNeurons int
    hiddenNeurons int
    numEpochs int
    learningRate float64
}
```

这里，`wHidden`和`bHidden`分别是网络隐藏层的权重和偏差，`wOut`和`bOut`分别是网络输出层的权重和偏差。请注意，我们使用`gonum.org/v1/gonum/mat`矩阵表示所有权重和偏差，我们将使用类似矩阵表示输入和输出。这将使我们能够轻松地执行与反向传播相关的操作，并将我们的培训推广到输入层、隐藏层和输出层中的任意数量的节点。

接下来，让我们定义一个基于`neuralNetConfig`值初始化新神经网络的函数，以及一个基于输入矩阵（*x*和标签矩阵（*y*训练`neuralNet`值的方法：

```go
// NewNetwork initializes a new neural network.
func newNetwork(config neuralNetConfig) *neuralNet {
        return &neuralNet{config: config}
}

// Train trains a neural network using backpropagation.
func (nn *neuralNet) train(x, y *mat.Dense) error {

    // To be filled in...
}
```

在`train()`方法中，我们需要完成反向传播方法，并将得到的训练权重和偏差放入接收器。首先，我们在`train()`方法中随机初始化权重和偏差，如下代码所示：

```go
// Initialize biases/weights.
randSource := rand.NewSource(time.Now().UnixNano())
randGen := rand.New(randSource)

wHiddenRaw := make([]float64, nn.config.hiddenNeurons*nn.config.inputNeurons)
bHiddenRaw := make([]float64, nn.config.hiddenNeurons)
wOutRaw := make([]float64, nn.config.outputNeurons*nn.config.hiddenNeurons)
bOutRaw := make([]float64, nn.config.outputNeurons)

for _, param := range [][]float64{wHiddenRaw, bHiddenRaw, wOutRaw, bOutRaw} {
    for i := range param {
        param[i] = randGen.Float64()
    }
}

wHidden := mat.NewDense(nn.config.inputNeurons, nn.config.hiddenNeurons, wHiddenRaw)
bHidden := mat.NewDense(1, nn.config.hiddenNeurons, bHiddenRaw)
wOut := mat.NewDense(nn.config.hiddenNeurons, nn.config.outputNeurons, wOutRaw)
bOut := mat.NewDense(1, nn.config.outputNeurons, bOutRaw)
```

然后，我们需要在我们的每个时代进行循环，完成网络的反向传播。这同样涉及一个前馈阶段，在该阶段中计算输出，以及一个反向传播阶段，在该阶段中应用对权重和偏差的更改。如果您有兴趣深入研究，将在[附录](08.html)*与机器学习相关的算法/技术*中详细讨论反向传播过程。现在，让我们把重点放在实现上。循环周期如下所示，注释指示了反向传播过程的各个部分：

```go
// Define the output of the neural network.
output := mat.NewDense(0, 0, nil)

// Loop over the number of epochs utilizing
// backpropagation to train our model.
for i := 0; i < nn.config.numEpochs; i++ {

    // Complete the feed forward process.

    ...

    // Complete the backpropagation.

    ...

    // Adjust the parameters.

    ...
}
```

在该循环的前馈部分，输入通过我们的节点网络向前传播：

```go
// Complete the feed forward process.
hiddenLayerInput := mat.NewDense(0, 0, nil)
hiddenLayerInput.Mul(x, wHidden)
addBHidden := func(_, col int, v float64) float64 { return v + bHidden.At(0, col) }
hiddenLayerInput.Apply(addBHidden, hiddenLayerInput)

hiddenLayerActivations := mat.NewDense(0, 0, nil)
applySigmoid := func(_, _ int, v float64) float64 { return sigmoid(v) }
hiddenLayerActivations.Apply(applySigmoid, hiddenLayerInput)

outputLayerInput := mat.NewDense(0, 0, nil)
outputLayerInput.Mul(hiddenLayerActivations, wOut)
addBOut := func(_, col int, v float64) float64 { return v + bOut.At(0, col) }
outputLayerInput.Apply(addBOut, outputLayerInput)
output.Apply(applySigmoid, outputLayerInput)
```

然后，一旦我们有了前馈过程的输出，我们将通过网络反向计算输出层和隐藏层的增量（或更改），如以下代码所示：

```go
// Complete the backpropagation.
networkError := mat.NewDense(0, 0, nil)
networkError.Sub(y, output)

slopeOutputLayer := mat.NewDense(0, 0, nil)
applySigmoidPrime := func(_, _ int, v float64) float64 { return sigmoidPrime(v) }
slopeOutputLayer.Apply(applySigmoidPrime, output)
slopeHiddenLayer := mat.NewDense(0, 0, nil)
slopeHiddenLayer.Apply(applySigmoidPrime, hiddenLayerActivations)

dOutput := mat.NewDense(0, 0, nil)
dOutput.MulElem(networkError, slopeOutputLayer)
errorAtHiddenLayer := mat.NewDense(0, 0, nil)
errorAtHiddenLayer.Mul(dOutput, wOut.T())

dHiddenLayer := mat.NewDense(0, 0, nil)
dHiddenLayer.MulElem(errorAtHiddenLayer, slopeHiddenLayer)
```

然后利用增量更新网络的权重和偏差。一个**学习率**也被用来衡量这些变化，这有助于算法收敛。回溯循环的最后一部分在这里实现：

```go
// Adjust the parameters.
wOutAdj := mat.NewDense(0, 0, nil)
wOutAdj.Mul(hiddenLayerActivations.T(), dOutput)
wOutAdj.Scale(nn.config.learningRate, wOutAdj)
wOut.Add(wOut, wOutAdj)

bOutAdj, err := sumAlongAxis(0, dOutput)
if err != nil {
    return err
}
bOutAdj.Scale(nn.config.learningRate, bOutAdj)
bOut.Add(bOut, bOutAdj)

wHiddenAdj := mat.NewDense(0, 0, nil)
wHiddenAdj.Mul(x.T(), dHiddenLayer)
wHiddenAdj.Scale(nn.config.learningRate, wHiddenAdj)
wHidden.Add(wHidden, wHiddenAdj)

bHiddenAdj, err := sumAlongAxis(0, dHiddenLayer)
if err != nil {
    return err
}
bHiddenAdj.Scale(nn.config.learningRate, bHiddenAdj)
bHidden.Add(bHidden, bHiddenAdj)
```

注意，这里我们使用了另一个辅助函数，它允许我们沿着一个维度对矩阵求和，同时保持另一个维度不变。此`sumAlongAxis()`功能完整性如下代码所示：

```go
// sumAlongAxis sums a matrix along a
// particular dimension, preserving the
// other dimension.
func sumAlongAxis(axis int, m *mat.Dense) (*mat.Dense, error) {

    numRows, numCols := m.Dims()

    var output *mat.Dense

    switch axis {
    case 0:
        data := make([]float64, numCols)
        for i := 0; i < numCols; i++ {
            col := mat.Col(nil, i, m)
            data[i] = floats.Sum(col)
        }
        output = mat.NewDense(1, numCols, data)
    case 1:
        data := make([]float64, numRows)
        for i := 0; i < numRows; i++ {
            row := mat.Row(nil, i, m)
            data[i] = floats.Sum(row)
        }
        output = mat.NewDense(numRows, 1, data)
    default:
        return nil, errors.New("invalid axis, must be 0 or 1")
    }

    return output, nil
}
```

在`train()`方法中，我们要做的最后一件事是将经过训练的权重和偏差添加到接收器值并返回：

```go
// Define our trained neural network.
nn.wHidden = wHidden
nn.bHidden = bHidden
nn.wOut = wOut
nn.bOut = bOut

return nil
```

令人惊叹的那还不错。我们有一种用大约 100 行 Go 代码训练神经网络的方法。为了检查这段代码是否运行，并了解我们的权重和偏差可能是什么样子，让我们在一些简单的虚拟数据上训练一个神经网络。在下一节中，我们将对网络执行一个更现实的示例，但现在，让我们用一些虚拟数据检查我们自己的合理性，如以下代码所示：

```go
// Define our input attributes.
input := mat.NewDense(3, 4, []float64{
    1.0, 0.0, 1.0, 0.0,
    1.0, 0.0, 1.0, 1.0,
    0.0, 1.0, 0.0, 1.0,
})

// Define our labels.
labels := mat.NewDense(3, 1, []float64{1.0, 1.0, 0.0})

// Define our network architecture and
// learning parameters.
config := neuralNetConfig{
    inputNeurons: 4,
    outputNeurons: 1,
    hiddenNeurons: 3,
    numEpochs: 5000,
    learningRate: 0.3,
}

// Train the neural network.
network := newNetwork(config)
if err := network.train(input, labels); err != nil {
    log.Fatal(err)
}

// Output the weights that define our network!
f := mat.Formatted(network.wHidden, mat.Prefix(" "))
fmt.Printf("\nwHidden = % v\n\n", f)

f = mat.Formatted(network.bHidden, mat.Prefix(" "))
fmt.Printf("\nbHidden = % v\n\n", f)

f = mat.Formatted(network.wOut, mat.Prefix(" "))
fmt.Printf("\nwOut = % v\n\n", f)

f = mat.Formatted(network.bOut, mat.Prefix(" "))
fmt.Printf("\nbOut = % v\n\n", f)
```

编译并运行此神经网络训练代码会产生以下输出权重和偏差：

```go
bOut$ go build
$ ./myprogram 

wHidden = [ 2.105009524680073 2.022752980359344 2.5200192466310547]
 [ -2.033896626042324 -1.8652059633980662 -1.5861504822640748]
 [1.821046795894909 2.436963623058306 1.717510016887383]
 [-0.7400175664445425 -0.5800261988090052 -0.9277709997772002]

bHidden = [ 0.06850421921273529 -0.40252869229501825 -0.03392255287230178]

wOut = [ 2.321901257946553]
 [ 3.343178681830189]
 [1.7581701319375231]

bOut = [-3.471613333924047]
```

这些权重和偏差完全定义了我们训练的神经网络。也就是说，`wHidden`和`bHidden`允许我们将输入转化为输入到网络输出层的值，`wOut`和`bOut`允许我们将这些值转化为神经网络的最终输出。

由于我们使用随机数，您的程序返回的结果可能与前面描述的结果略有不同。但是，您应该看到类似的值范围。

# 利用简单神经网络

现在，我们已经有了一些神经网络训练功能，这些功能似乎正在发挥作用，让我们尝试在更真实的建模场景中利用这些功能。特别是，让我们带回我们最喜欢的分类数据集，鸢尾花数据集（在[第 5 章](05.html#2TEN40-a5604e9f48ea4e63828d369cca8f0939)、*分类*中使用）。

如果您还记得，在使用此数据集对鸢尾花进行分类时，我们试图将其分为三个物种之一（刚毛、弗吉尼亚或花色）。由于我们的神经网络需要浮点值矩阵，我们需要将这三个物种编码成数字列。一种方法是在我们的数据集中为每个物种创建一列。然后，我们将该列的值设置为*1.0*或*0.0*，这取决于对应行的测量值是对应于该物种（*1.0*）还是对应于另一物种（*0.0*）。

我们还将标准化我们的数据，原因类似于[第 5 章](05.html#2TEN40-a5604e9f48ea4e63828d369cca8f0939)、*分类*中关于逻辑回归的讨论。这使我们的数据集看起来与前面的示例略有不同，如您在此处所见：

```go
$ head train.csv 
sepal_length,sepal_width,petal_length,petal_width,setosa,virginica,versicolor
0.305555555556,0.583333333333,0.118644067797,0.0416666666667,1.0,0.0,0.0
0.25,0.291666666667,0.491525423729,0.541666666667,0.0,0.0,1.0
0.194444444444,0.5,0.0338983050847,0.0416666666667,1.0,0.0,0.0
0.833333333333,0.375,0.898305084746,0.708333333333,0.0,1.0,0.0
0.555555555556,0.208333333333,0.661016949153,0.583333333333,0.0,0.0,1.0
0.416666666667,0.25,0.508474576271,0.458333333333,0.0,0.0,1.0
0.666666666667,0.416666666667,0.677966101695,0.666666666667,0.0,0.0,1.0
0.416666666667,0.291666666667,0.491525423729,0.458333333333,0.0,0.0,1.0
0.5,0.416666666667,0.661016949153,0.708333333333,0.0,1.0,0.0
```

我们将使用 80/20 的训练和测试数据来评估模型。训练数据存储在`train.csv`中，测试数据存储在`test.csv`中，如下图：

```go
$ wc -l *.csv
 31 test.csv
 121 train.csv
 152 total
```

# 在真实数据上训练神经网络

为了在这个虹膜数据上训练我们的神经网络，我们需要读入训练数据并创建两个矩阵。第一个矩阵将保存所有属性（矩阵`inputs`），第二个矩阵将保存所有标签（矩阵`labels`）。我们将按如下方式构造这些矩阵：

```go
// Open the training dataset file.
f, err := os.Open("train.csv")
if err != nil {
    log.Fatal(err)
}
defer f.Close()

// Create a new CSV reader reading from the opened file.
reader := csv.NewReader(f)
reader.FieldsPerRecord = 7

// Read in all of the CSV records
rawCSVData, err := reader.ReadAll()
if err != nil {
    log.Fatal(err)
}

// inputsData and labelsData will hold all the
// float values that will eventually be
// used to form our matrices.
inputsData := make([]float64, 4*len(rawCSVData))
labelsData := make([]float64, 3*len(rawCSVData))

// inputsIndex will track the current index of
// inputs matrix values.
var inputsIndex int
var labelsIndex int

// Sequentially move the rows into a slice of floats.
for idx, record := range rawCSVData {

    // Skip the header row.
    if idx == 0 {
        continue
    }

    // Loop over the float columns.
    for i, val := range record {

        // Convert the value to a float.
        parsedVal, err := strconv.ParseFloat(val, 64)
        if err != nil {
            log.Fatal(err)
        }

        // Add to the labelsData if relevant.
        if i == 4 || i == 5 || i == 6 {
            labelsData[labelsIndex] = parsedVal
            labelsIndex++
            continue
        }

        // Add the float value to the slice of floats.
        inputsData[inputsIndex] = parsedVal
        inputsIndex++
    }
}

// Form the matrices.
inputs := mat.NewDense(len(rawCSVData), 4, inputsData)
labels := mat.NewDense(len(rawCSVData), 3, labelsData)
```

然后我们可以初始化和训练我们的神经网络，类似于我们处理虚拟数据的方式。唯一的区别是，我们将使用三个输出神经元，对应于我们的三个输出类。培训过程如下：

```go
// Define our network architecture and
// learning parameters.
config := neuralNetConfig{
    inputNeurons:  4,
    outputNeurons: 3,
    hiddenNeurons: 3,
    numEpochs:     5000,
    learningRate:  0.3,
}

// Train the neural network.
network := newNetwork(config)
if err := network.train(inputs, labels); err != nil {
    log.Fatal(err)
}
```

# 评价神经网络

为了使用经过训练的神经网络进行预测，我们将为`neuralNet`类型创建`predict()`方法。此`predict`方法将接收新的输入，并通过网络完成和反馈新的输入，以产生预测输出，如下所示：

```go
// predict makes a prediction based on a trained
// neural network.
func (nn *neuralNet) predict(x *mat.Dense) (*mat.Dense, error) {

    // Check to make sure that our neuralNet value
    // represents a trained model.
    if nn.wHidden == nil || nn.wOut == nil || nn.bHidden == nil || nn.bOut == nil {
        return nil, errors.New("the supplied neural net weights and biases are empty")
    }

    // Define the output of the neural network.
    output := mat.NewDense(0, 0, nil)
github.com/tensorflow/tensorflow/tensorflow/go
    // Complete the feed forward process.
    hiddenLayerInput := mat.NewDense(0, 0, nil)
    hiddenLayerInput.Mul(x, nn.wHidden)
    addBHidden := func(_, col int, v float64) float64 { return v + nn.bHidden.At(0, col) }
    hiddenLayerInput.Apply(addBHidden, hiddenLayerInput)

    hiddenLayerActivations := mat.NewDense(0, 0, nil)
    applySigmoid := func(_, _ int, v float64) float64 { return sigmoid(v) }
    hiddenLayerActivations.Apply(applySigmoid, hiddenLayerInput)

    outputLayerInput := mat.NewDense(0, 0, nil)
    outputLayerInput.Mul(hiddenLayerActivations, nn.wOut)
    addBOut := func(_, col int, v float64) float64 { return v + nn.bOut.At(0, col) }
    outputLayerInput.Apply(addBOut, outputLayerInput)
    output.Apply(applySigmoid, outputLayerInput)

    return output, nil
}
```

然后，我们可以在测试数据上使用这个`predict()`方法来评估我们训练的模型。具体来说，我们将把`test.csv`中的数据读入两个新矩阵`testInputs`和`testLabels`，类似于我们读入`train.csv`中的方式（因此，我们将不在这里包括细节）。`testInputs`可以提供给`predict()`方法来获得我们的预测，然后我们可以比较我们的预测和`testLabels`来计算评估指标。在这种情况下，我们将计算模型的精度。

在计算精度时，我们将注意的一个细节是根据我们的模型确定单个输出预测。该网络实际上为每个虹膜物种产生一个介于 0.0 和 1.0 之间的输出。我们将以其中最高的物种作为预测物种。

我们模型的精度计算如以下代码所示：

```go
// Make the predictions using the trained model.
predictions, err := network.predict(testInputs)
if err != nil {
    log.Fatal(err)
}

// Calculate the accuracy of our model.
var truePosNeg int
numPreds, _ := predictions.Dims()
for i := 0; i < numPreds; i++ {

    // Get the label.
    labelRow := mat.Row(nil, i, testLabels)
    var species int
    for idx, label := range labelRow {
        if label == 1.0 {
            species = idx
            break
        }
    }

    // Accumulate the true positive/negative count.
    if predictions.At(i, species) == floats.Max(mat.Row(nil, i, predictions)) {
        truePosNeg++
    }
}

// Calculate the accuracy (subset accuracy).
accuracy := float64(truePosNeg) / float64(numPreds)

// Output the Accuracy value to standard out.
fmt.Printf("\nAccuracy = %0.2f\n\n", accuracy)
```

编译和运行评估将产生类似于以下内容的结果：

```go
$ go build
$ ./myprogram 

Accuracy = 0.97
```

是 啊那很好。我们使用从头开始的神经网络对鸢尾花物种的预测准确率为 97%。如前所述，当涉及到大多数分类任务时，这些单隐层神经网络非常强大，并且您可以看到，基本原理并没有那么复杂。

# 引入深度学习

尽管简单的神经网络（如前一节中使用的）在许多情况下都非常强大，但近年来，深度神经网络体系结构已在不同行业中应用于各种类型的数据。这些更复杂的体系结构已被用于在棋盘/视频游戏、驾驶汽车、生成艺术、转换图像等方面击败冠军。看起来你可以在这些模型上投入任何东西，它们会做一些有趣的事情，但它们似乎特别适合计算机视觉、语音识别、文本推理和其他非常复杂且难以定义的任务。

我们将在这里引入深度学习，并在 Go 中运行深度学习模型。然而，深度学习模式的应用和多样性是巨大的，并且每天都在增长。

关于这一主题的书籍和教程很多，因此，如果这篇简要介绍引起您的兴趣，我们建议您参考以下资源之一：

*   使用 TensorFlow 进行动手深度学习：[https://www.packtpub.com/big-data-and-business-intelligence/hands-deep-learning-tensorflow](https://www.packtpub.com/big-data-and-business-intelligence/hands-deep-learning-tensorflow)
*   以身作则深度学习：[https://www.packtpub.com/big-data-and-business-intelligence/deep-learning-example](https://www.packtpub.com/big-data-and-business-intelligence/deep-learning-example)
*   计算机视觉深度学习：[https://www.packtpub.com/big-data-and-business-intelligence/deep-learning-computer-vision](https://www.packtpub.com/big-data-and-business-intelligence/deep-learning-computer-vision)

这些资源可能不会全部提及或认可 Go，但正如您在下面的示例中所看到的，Go 完全能够应用这些技术并与 TensorFlow 或 H2O 等设备进行交互。

# 什么是深度学习模式？

深度学习是指各种神经网络结构的连续组合和利用，形成一个庞大而复杂的体系结构。这些庞大而复杂的体系结构通常需要大量的数据进行训练，并且生成的结构很难解释。

为了举例说明现代深度学习模型的规模和复杂性，以谷歌的 LeNet（[为例）http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Szegedy_Going_Deeper_With_2015_CVPR_paper.pdf 以](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Szegedy_Going_Deeper_With_2015_CVPR_paper.pdf)为例。此模型可用于物体识别，如图所示（图片由[提供）https://adeshpande3.github.io/adeshpande3.github.io/The-9-Deep-Learning-Papers-You-Need-To-Know-About.html](https://adeshpande3.github.io/adeshpande3.github.io/The-9-Deep-Learning-Papers-You-Need-To-Know-About.html) ：

![](img/00074.jpeg)

这种结构本身很难消化。然而，当您意识到此图中的每个块本身都可能是一个复杂的神经网络原语（如图例所示）时，它就更令人印象深刻了。

通常，深度学习模型是通过将以下一个或多个结构链接在一起，并在某些情况下重新链接在一起来构建的：

*   一个完全连接的神经网络架构：这个构建块可能与我们在本章前面构建的虹膜花检测类似。它包括许多排列在完全连接层中的神经网络节点。也就是说，层从一层流向另一层，所有节点从一层连接到下一层。
*   **卷积神经网络**（**ConvNet**或**CNN**）：这是实现至少一个**卷积层**的神经网络。卷积层包含由一组仅部分连接到输入数据的权重（也称为卷积核或滤波器）参数化的神经元。大多数 ConvNet 包含这些卷积层的分层组合，允许 ConvNet 响应输入数据中的低级特征。
*   **递归神经网络**和/或**长短期记忆**（**LSTM**）**细胞**：这些组件试图将类似记忆的东西纳入模型。递归神经网络使其输出依赖于输入序列，而不是假设每个输入都是独立的。LSTM 细胞与递归神经网络有关，但也试图将长期记忆因素考虑在内。

虽然我们将在本章中利用图像数据来说明深度学习，但使用递归神经网络和 LSTM 的深度学习模型特别适合于解决基于文本和其他 NLP 问题。例如，内置于这些网络中的记忆使他们能够理解句子中接下来可能出现的单词。如果您对运行基于文本数据的深度学习模型感兴趣，我们建议您看看这个使用`github.com/chewxy/gorgonia`包的示例：
[https://github.com/chewxy/gorgonia/tree/master/examples/charRNN.](https://github.com/chewxy/gorgonia/tree/master/examples/charRNN)

深度学习模式非常强大！特别是对于像计算机视觉这样的任务。然而，您还应该记住，这些神经网络组件的复杂组合也极难解释。也就是说，确定模型做出某个预测的原因几乎是不可能的。当您需要在某些行业和司法管辖区维护法规遵从性时，这可能会成为一个问题，并且可能会妨碍应用程序的调试或维护。尽管如此，仍有一些重大努力来提高深度学习模型的可解释性。其中值得注意的是石灰项目：
[https://github.com/marcotcr/lime.](https://github.com/marcotcr/lime)

# 围棋深度学习

当您希望从 Go 构建或利用深度学习模型时，有多种选择。与深度学习本身一样，这是一个不断变化的局面。然而，在 Go 中构建、培训和利用深度学习模型的选项通常如下所示：

*   **使用围棋软件包**：有围棋软件包可以让你使用围棋作为主要界面来构建和训练深度学习模型。这些软件包中最具特色和发展的是`github.com/chewxy/gorgonia`。`github.com/chewxy/gorgonia`将 Go 视为一等公民，并使用 Go 编写，即使它确实大量使用`cgo`与数字库接口。
*   **将 API 或 Go 客户端用于非 Go DL 框架**：您可以与 Go 流行的深度学习服务和框架交互，包括 TensorFlow、MachineBox、H2O 以及各种云提供商或第三方 API 产品（如 IBM Watson）。TensorFlow 和 Machine Box 实际上有 Go 绑定或 SDK，它们正在不断改进。对于其他服务，您可能需要通过 REST 进行交互，甚至需要使用`exec`调用二进制文件。
*   **使用 cgo**：当然，Go 可以与 C/C++库进行对话和集成，以进行深入学习，包括 TensorFlow 库和 Intel 的各种库。然而，这是一条艰难的道路，只有在绝对必要时才建议这样做。

由于 TensorFlow 是目前最流行的深度学习框架，我们将简要探讨这里列出的第二类。然而，Tensorflow Go 绑定正在积极开发中，目前有些功能还相当粗糙。TensorFlow 团队建议，如果要在 Go 中使用 TensorFlow 模型，首先使用 Python 训练和导出该模型。正如我们将在下一节中演示的那样，可以从 Go 使用预先训练好的模型。

社区中有许多成员非常努力地让 Go 成为 TensorFlow 的一等公民。因此，TensorFlow 绑定的粗糙边缘很可能在未来一年内得到平滑。为了保持这方面的最新信息，请确保并加入 Gophers Slack 上的#数据科学频道（[https://invite.slack.golangbridge.org/](https://invite.slack.golangbridge.org/) ）。这是一个经常讨论的话题，也是一个提问和参与的好地方。

尽管我们将在此探索一个快速 TensorFlow 示例，但我们强烈建议您研究`github.com/chewxy/gorgonia`，尤其是如果您考虑在 Go 中进行更多自定义或扩展建模。该包装功能强大，用于生产。

# 设置 TensorFlow 以用于 Go

TensorFlow 团队提供了一些很好的文档来安装 TensorFlow 并准备好与 Go 一起使用。这些文件可在[找到 https://www.tensorflow.org/install/install_go](https://www.tensorflow.org/install/install_go) 。有几个初步步骤，但一旦安装了 TensorFlow C 库，就可以获得以下 Go 包：

```go
$ go get github.com/tensorflow/tensorflow/tensorflow/go
```

如果您能够无误地获得`github.com/tensorflow/tensorflow/tensorflow/go`，那么一切都应该很好，但是您可以通过执行以下测试来确保您已经准备好使用 TensorFlow：

```go
$ go test github.com/tensorflow/tensorflow/tensorflow/go
ok github.com/tensorflow/tensorflow/tensorflow/go 0.045s
```

# 检索和调用预训练的 TensorFlow 模型

我们将要使用的模型是一个用于图像中对象识别的谷歌模型，称为 Inception。可按如下方式检索模型：

```go
$ mkdir model
$ cd model
$ wget https://storage.googleapis.com/download.tensorflow.org/models/inception5h.zip
--2017-09-09 18:29:03-- https://storage.googleapis.com/download.tensorflow.org/models/inception5h.zip
Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.6.112, 2607:f8b0:4009:812::2010
Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.6.112|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 49937555 (48M) [application/zip]
Saving to: ‘inception5h.zip’

inception5h.zip 100%[=========================================================================================================================>] 47.62M 19.0MB/s in 2.5s 

2017-09-09 18:29:06 (19.0 MB/s) - ‘inception5h.zip’ saved [49937555/49937555]

$ unzip inception5h.zip
Archive: inception5h.zip
 inflating: imagenet_comp_graph_label_strings.txt 
 inflating: tensorflow_inception_graph.pb 
 inflating: LICENSE
```

解压压缩模型后，应该会看到一个`*.pb`文件。这是一个表示模型冻结状态的`protobuf`文件。回想一下我们的简单神经网络。网络完全由一系列权重和偏差定义。虽然更复杂，但是这个模型可以用类似的方式定义，并且这些定义存储在这个`protobuf`文件中。

为了调用这个模型，我们将使用 TensorFlow Go 绑定文档中的一些示例代码--[https://godoc.org/github.com/tensorflow/tensorflow/tensorflow/go](https://godoc.org/github.com/tensorflow/tensorflow/tensorflow/go) 。此代码加载模型，并使用模型检测和标记`*.jpg`图像的内容。

由于该代码包含在 TensorFlow 文档中，因此我将省去细节，只突出显示几个片段。要加载模型，我们执行以下操作：

```go
// Load the serialized GraphDef from a file.
modelfile, labelsfile, err := modelFiles(*modeldir)
if err != nil {
    log.Fatal(err)
}
model, err := ioutil.ReadFile(modelfile)
if err != nil {
    log.Fatal(err)
} 
```

然后，我们加载深度学习模型的图形定义，并使用该图形创建一个新的 TensorFlow 会话，如以下代码所示：

```go
// Construct an in-memory graph from the serialized form.
graph := tf.NewGraph()
if err := graph.Import(model, ""); err != nil {
    log.Fatal(err)
}

// Create a session for inference over graph.
session, err := tf.NewSession(graph, nil)
if err != nil {
    log.Fatal(err)
}
defer session.Close()
```

最后，我们可以使用以下模型进行推断：

```go
// Run inference on *imageFile.
// For multiple images, session.Run() can be called in a loop (and
// concurrently). Alternatively, images can be batched since the model
// accepts batches of image data as input.
tensor, err := makeTensorFromImage(*imagefile)
if err != nil {
    log.Fatal(err)
}
output, err := session.Run(
    map[tf.Output]*tf.Tensor{
        graph.Operation("input").Output(0): tensor,
    },
    []tf.Output{
        graph.Operation("output").Output(0),
    },
    nil)
if err != nil {
    log.Fatal(err)
}

// output[0].Value() is a vector containing probabilities of
// labels for each image in the "batch". The batch size was 1.
// Find the most probable label index.
probabilities := output[0].Value().([][]float32)[0]
printBestLabel(probabilities, labelsfile)
```

# 基于 Go 的 TensorFlow 目标检测

TensorFlow GoDocs 中规定的目标检测 Go 程序可调用如下：

```go
$ ./myprogram -dir=<path/to/the/model/dir> -image=<path/to/a/jpg/image>
```

调用程序时，它将利用预训练和加载的模型来推断指定图像的内容。然后，它将输出该图像最可能的内容及其计算出的概率。

为了说明这一点，让我们尝试在保存为`airplane.jpg`的以下飞机图像上执行对象检测：

![](img/00075.jpeg)

从 Go 运行 TensorFlow 模型得出以下结果：

```go
$ go build
$ ./myprogram -dir=model -image=airplane.jpg
2017-09-09 20:17:30.655757: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-09-09 20:17:30.655807: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-09-09 20:17:30.655814: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-09-09 20:17:30.655818: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-09-09 20:17:30.655822: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
BEST MATCH: (86% likely) airliner
```

在提出了一些加速 CPU 计算的建议之后，我们得到了一个结果：`airliner`。哇！那很酷。我们刚刚用 TensorFlow 在 Go 程序中执行了对象识别！

让我们试试另一个。这次我们将使用`pug.jpg`，如下所示：

![](img/00076.jpeg)

使用此图像再次运行我们的程序会得到以下结果：

```go
$ ./myprogram -dir=model -image=pug.jpg 
2017-09-09 20:20:32.323855: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-09-09 20:20:32.323896: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-09-09 20:20:32.323902: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-09-09 20:20:32.323906: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-09-09 20:20:32.323911: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
BEST MATCH: (84% likely) pug
```

成功模型不仅检测到图片中有一只狗，还正确地识别出图片中有一只哈巴狗。

让我们再试一次。由于这是一本围棋书，我们忍不住尝试`gopher.jpg`，它看起来如下所示（非常感谢围棋地鼠背后的艺术家蕾妮·弗伦奇）：

![](img/00077.jpeg)

运行模型会得到以下结果：

```go
$ ./myprogram -dir=model -image=gopher.jpg 
2017-09-09 20:25:57.967753: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-09-09 20:25:57.967801: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-09-09 20:25:57.967808: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-09-09 20:25:57.967812: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-09-09 20:25:57.967817: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
BEST MATCH: (12% likely) safety pin
```

嗯，我想我们不可能把他们都赢了。看来我们需要重构我们的模型来识别 Go Gopher。更具体地说，我们应该向我们的训练数据集中添加一堆 Go gopher，因为 Go gopher 绝对不是安全别针！

# 工具书类

基本神经网络：

*   神经网络简介：[https://ujjwalkarn.me/2016/08/09/quick-intro-neural-networks/](https://ujjwalkarn.me/2016/08/09/quick-intro-neural-networks/)
*   深度学习和神经网络的友好介绍：[https://youtu.be/BR9h47Jtqyw](https://youtu.be/BR9h47Jtqyw)
*   `github.com/tleyden/neurgo`文件：[https://godoc.org/github.com/tleyden/neurgo](https://godoc.org/github.com/tleyden/neurgo)
*   `github.com/fxsjy/gonn/gonn`文件：[https://godoc.org/github.com/fxsjy/gonn/gonn](https://godoc.org/github.com/fxsjy/gonn/gonn)

更详细的深度学习资源：

*   使用 TensorFlow 进行动手深度学习-[T0]https://www.packtpub.com/big-data-and-business-intelligence/hands-deep-learning-tensorflow
*   通过实例深入学习-[T0]https://www.packtpub.com/big-data-and-business-intelligence/deep-learning-example
*   计算机视觉深度学习-[https://www.packtpub.com/big-data-and-business-intelligence/deep-learning-computer-vision](https://www.packtpub.com/big-data-and-business-intelligence/deep-learning-computer-vision)

围棋深度学习：

*   TensorFlow Go 绑定文档：[https://godoc.org/github.com/tensorflow/tensorflow/tensorflow/go](https://godoc.org/github.com/tensorflow/tensorflow/tensorflow/go)
*   文件：T1。https://godoc.org/github.com/chewxy/gorgonia （众笑）
*   machinebox go sdk docs:【t0【https://godoc.org/github.com/machinebox/sdk-go
*   使用`cgo`示例[调用预训练模型 https://github.com/gopherdata/dlinfer](https://github.com/gopherdata/dlinfer)

# 总结

祝贺我们已经从使用 Go 解析数据到调用 Go 的深度学习模型。现在，您了解了神经网络的基础知识，可以在 Go 程序中实现并使用它们。在下一章中，我们将讨论如何从笔记本电脑上获取这些模型和应用程序，并在数据管道中以生产规模运行它们。